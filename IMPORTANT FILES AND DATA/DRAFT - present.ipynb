{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining II Final Project ~ Jurgen Xhafaj\n",
    "\n",
    "### Using Python to get predictions on soccer matches\n",
    "\n",
    "#### * Total goals 0-2 or 3+\n",
    "#### * 1 X 2\n",
    "#### * Home team wins or not\n",
    "#### * Which lineup works best (Home) or (Away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>league_id</th>\n",
       "      <th>season</th>\n",
       "      <th>stage</th>\n",
       "      <th>date</th>\n",
       "      <th>match_api_id</th>\n",
       "      <th>home_team_api_id</th>\n",
       "      <th>away_team_api_id</th>\n",
       "      <th>home_team_goal</th>\n",
       "      <th>...</th>\n",
       "      <th>IWA</th>\n",
       "      <th>LBH</th>\n",
       "      <th>LBD</th>\n",
       "      <th>LBA</th>\n",
       "      <th>WHH</th>\n",
       "      <th>WHD</th>\n",
       "      <th>WHA</th>\n",
       "      <th>VCH</th>\n",
       "      <th>VCD</th>\n",
       "      <th>VCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19694</td>\n",
       "      <td>19694</td>\n",
       "      <td>19694</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>9-Aug-08</td>\n",
       "      <td>489981</td>\n",
       "      <td>8596</td>\n",
       "      <td>8548</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.50</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.44</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.44</td>\n",
       "      <td>6.50</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19696</td>\n",
       "      <td>19694</td>\n",
       "      <td>19694</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>9-Aug-08</td>\n",
       "      <td>489983</td>\n",
       "      <td>8597</td>\n",
       "      <td>10251</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.38</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4776</td>\n",
       "      <td>4769</td>\n",
       "      <td>4769</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>9-Aug-08</td>\n",
       "      <td>483136</td>\n",
       "      <td>9851</td>\n",
       "      <td>8592</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4774</td>\n",
       "      <td>4769</td>\n",
       "      <td>4769</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>9-Aug-08</td>\n",
       "      <td>483134</td>\n",
       "      <td>9829</td>\n",
       "      <td>9847</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.87</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4778</td>\n",
       "      <td>4769</td>\n",
       "      <td>4769</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>9-Aug-08</td>\n",
       "      <td>483138</td>\n",
       "      <td>9873</td>\n",
       "      <td>9853</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.37</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.87</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  country_id  league_id     season  stage      date  match_api_id  \\\n",
       "0  19694       19694      19694  2008/2009      1  9-Aug-08        489981   \n",
       "1  19696       19694      19694  2008/2009      1  9-Aug-08        489983   \n",
       "2   4776        4769       4769  2008/2009      1  9-Aug-08        483136   \n",
       "3   4774        4769       4769  2008/2009      1  9-Aug-08        483134   \n",
       "4   4778        4769       4769  2008/2009      1  9-Aug-08        483138   \n",
       "\n",
       "   home_team_api_id  away_team_api_id  home_team_goal  ...   IWA   LBH  LBD  \\\n",
       "0              8596              8548               0  ...   1.5  6.50  3.6   \n",
       "1              8597             10251               1  ...   2.4  2.38  3.2   \n",
       "2              9851              8592               4  ...   2.6  2.60  2.8   \n",
       "3              9829              9847               1  ...   3.0  2.25  3.0   \n",
       "4              9873              9853               1  ...   3.1  2.37  2.8   \n",
       "\n",
       "    LBA   WHH   WHD   WHA   VCH   VCD   VCA  \n",
       "0  1.44  6.00  3.75  1.44  6.50  3.75  1.45  \n",
       "1  2.60  2.50  3.10  2.50  2.40  3.20  2.60  \n",
       "2  2.60  2.60  2.80  2.60  2.65  2.90  2.65  \n",
       "3  2.87  2.30  2.90  2.90  2.25  3.00  3.00  \n",
       "4  2.87  2.38  2.80  2.88  2.25  2.90  3.10  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "df=pd.read_csv(\"edited match table.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000020A81584588>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAFZRJREFUeJzt3X+QXWd93/H3BxuDkcE2Nd4xkoKcWKUGHH5UY9ww0y6Y2AIDcmegNeWHoM6o03FSaNUSOc3U4VcwSQwBmtDRYMUCHBzXgdrBENAYdphMY7AN1LIxVAKELVuxAdkCQTGIfPvHPdsu8q537/64d/c+79fMzr3nOc85z/PVXt3PPeeeezdVhSSpPY8Z9gQkScNhAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKaR5Kok7xji+PuSvHhY46sNBoBWrH6eJH1ClR7JAJCkRhkAWpGSfAT4JeCvkhxO8pYkr0hyZ5KHkkwkOXOmvl37f0/yd0kOJflCkmfOYx5vSXIgyX1JfiNJJTmjW3dikg8n+W6S7yT53SSP6db9SpLPJfl+ku8luTrJSTOMcXaSW5P8IMn9Sd4zv3816RcZAFqRqup1wN3Ay6vqBOB/AB8D3gw8BfgUvSf8447uW1V/0O3m08B64FTgy8DV/cwhyUbgPwAvBs4A/tlRXT4AnAj8crfu9cAbJzcH3gU8FTgTWAv83gxDvQ94X1U9CfgV4Np+5inNxADQqPiXwI1Vtauqfgb8EXA88GszbVBVO6rqh1X1ML0n32cnObGPMf8F8GdVdWdV/Rh46+SKJMd0c7q0G2MfcAXwum7svd1cH66q7wLv4ZEBMulnwBlJTqmqw1V1cx9zlGZkAGhUPBX4zuRCVf09cA+werrOSY5JcnmSbyb5AbCvW3VKn2PeM2V56v1TgOOmzqm7v7ob/9Qk1yS5txv/o48y9sXAPwS+nuSWJC/rY47SjAwArWRTv8r2PuBpkwtJQu+0yr3T9AX4V8AmeqdvTgTWTW7ax/gHgDVTltdOuf89eq/cnzal7ZemzOdd3Zx+tTu189qZxq6qPVX1anqnqt4NXJdkVR/zlKZlAGglu5/e+XXonRe/IMm5SR4LbAUeBv7nNH0Bntit/z7wBOD35zH+tcAbk5yZ5AnAf5lcUVU/79a/M8kTkzyN3vsFH50y/mHgoSSrgf800yBJXpvkKd1RzUNd88/nMV/pFxgAWsneBfxukoeAl9N7Ff0Beq++X07vTd+fHt03yX8EPkzvlMy9wNeAvs+rV9WngfcDnwf2An/brXq4u/0t4EfAt4C/Af4c2NGteyvwPOAQcCPw8UcZaiNwZ5LD9N4QvqiqftLvfKWjxT8IIy2O7rLTO4DHVdWRYc9Hmo1HANICJPnnSY5LcjK98/N/5ZO/VgoDQHoUSX6n+/DY0T+f7rr8G+C7wDfpnZf/t0ObrNQnTwFJUqM8ApCkRh077Ak8mlNOOaXWrVs37+1/9KMfsWrVyr9celTqAGtZjkalDrCWSbfddtv3quops/Vb1gGwbt06br311nlvPzExwfj4+OJNaEhGpQ6wluVoVOoAa5mU5Duz9/IUkCQ1ywCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNWpZfxJYPbvvPcQbtt245OPsu/yCJR9D0vLhEYAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJatScAiDJviS7k3w1ya1d25OT7Eqyp7s9uWtPkvcn2Zvk9iTPm7KfzV3/PUk2L01JkqS56OcI4IVV9Zyq2tAtbwNuqqr1wE3dMsBLgPXdzxbgg9ALDOAy4PnA2cBlk6EhSRq8hZwC2gTs7O7vBC6c0v7h6rkZOCnJacD5wK6qOlhVDwK7gI0LGF+StABzDYACPpvktiRburaxqjoA0N2e2rWvBu6Zsu3+rm2mdknSEMz1T0K+oKruS3IqsCvJ1x+lb6Zpq0dp/8WNewGzBWBsbIyJiYk5TvGRDh8+vKDtl4ux42HrWUeWfJxB/FuNyu8ERqeWUakDrKVfcwqAqrqvu30gySfoncO/P8lpVXWgO8XzQNd9P7B2yuZrgPu69vGj2iemGWs7sB1gw4YNNT4+fnSXOZuYmGAh2y8XH7j6eq7YvfR/vnnfa8aXfIxR+Z3A6NQyKnWAtfRr1lNASVYleeLkfeA84A7gBmDySp7NwPXd/RuA13dXA50DHOpOEX0GOC/Jyd2bv+d1bZKkIZjLy8ox4BNJJvv/eVX9dZJbgGuTXAzcDbyq6/8p4KXAXuDHwBsBqupgkrcDt3T93lZVBxetEklSX2YNgKr6FvDsadq/D5w7TXsBl8ywrx3Ajv6nKUlabH4SWJIaZQBIUqOW/tISrRjrtt245GNctXHVko8haW48ApCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktSoOQdAkmOSfCXJJ7vl05N8McmeJH+R5Liu/XHd8t5u/bop+7i0a/9GkvMXuxhJ0tz1cwTwJuCuKcvvBt5bVeuBB4GLu/aLgQer6gzgvV0/kjwDuAh4JrAR+NMkxyxs+pKk+ZpTACRZA1wAfKhbDvAi4Lquy07gwu7+pm6Zbv25Xf9NwDVV9XBVfRvYC5y9GEVIkvp37Bz7/THwFuCJ3fI/AB6qqiPd8n5gdXd/NXAPQFUdSXKo678auHnKPqdu8/8k2QJsARgbG2NiYmKutTzC4cOHF7T9cjF2PGw968jsHVeAUfmdwOjUMip1gLX0a9YASPIy4IGqui3J+GTzNF1rlnWPts3/b6jaDmwH2LBhQ42Pjx/dZc4mJiZYyPbLxQeuvp4rds81q5e3qzauGonfCYzO42tU6gBr6ddcnlVeALwiyUuBxwNPondEcFKSY7ujgDXAfV3//cBaYH+SY4ETgYNT2idN3UaSNGCzvgdQVZdW1ZqqWkfvTdzPVdVrgM8Dr+y6bQau7+7f0C3Trf9cVVXXflF3ldDpwHrgS4tWiSSpLws5r/DbwDVJ3gF8Bbiya78S+EiSvfRe+V8EUFV3JrkW+BpwBLikqn6+gPElSQvQVwBU1QQw0d3/FtNcxVNVPwFeNcP27wTe2e8kl7N1225c8jG2nrXkQ0hqkJ8ElqRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNGo2/M6gVY/e9h3jDEn+F9r7LL1jS/UujwiMASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktSoWQMgyeOTfCnJ/0pyZ5K3du2nJ/likj1J/iLJcV3747rlvd36dVP2dWnX/o0k5y9VUZKk2c3lCOBh4EVV9WzgOcDGJOcA7wbeW1XrgQeBi7v+FwMPVtUZwHu7fiR5BnAR8ExgI/CnSY5ZzGIkSXM3awBUz+Fu8bHdTwEvAq7r2ncCF3b3N3XLdOvPTZKu/Zqqeriqvg3sBc5elCokSX1LVc3eqfdK/TbgDOBPgD8Ebu5e5ZNkLfDpqnpWkjuAjVW1v1v3TeD5wO9123y0a7+y2+a6o8baAmwBGBsb+8fXXHPNvIs7fPgwJ5xwwry3n4vd9x5a0v0DjB0P9/+fJR9mIAZRy1mrT1zaATqDeHwNwqjUAdYy6YUvfOFtVbVhtn5z+pOQVfVz4DlJTgI+AZw5XbfuNjOsm6n96LG2A9sBNmzYUOPj43OZ4rQmJiZYyPZzsdR/3hBg61lHuGL3aPz1zkHUsu8140u6/0mDeHwNwqjUAdbSr76uAqqqh4AJ4BzgpCST/5PXAPd19/cDawG69ScCB6e2T7ONJGnA5nIV0FO6V/4kOR54MXAX8HnglV23zcD13f0bumW69Z+r3nmmG4CLuquETgfWA19arEIkSf2Zy7H4acDO7n2AxwDXVtUnk3wNuCbJO4CvAFd2/a8EPpJkL71X/hcBVNWdSa4FvgYcAS7pTi1JkoZg1gCoqtuB507T/i2muYqnqn4CvGqGfb0TeGf/05QkLTY/CSxJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGzRoASdYm+XySu5LcmeRNXfuTk+xKsqe7PblrT5L3J9mb5PYkz5uyr81d/z1JNi9dWZKk2czlCOAIsLWqzgTOAS5J8gxgG3BTVa0HbuqWAV4CrO9+tgAfhF5gAJcBzwfOBi6bDA1J0uDNGgBVdaCqvtzd/yFwF7Aa2ATs7LrtBC7s7m8CPlw9NwMnJTkNOB/YVVUHq+pBYBewcVGrkSTNWV/vASRZBzwX+CIwVlUHoBcSwKldt9XAPVM229+1zdQuSRqCY+faMckJwF8Cb66qHySZses0bfUo7UePs4XeqSPGxsaYmJiY6xQf4fDhwwvafi62nnVkSfcPMHb8YMYZhEHUstS/80mDeHwNwqjUAdbSrzkFQJLH0nvyv7qqPt4135/ktKo60J3ieaBr3w+snbL5GuC+rn38qPaJo8eqqu3AdoANGzbU+Pj40V3mbGJigoVsPxdv2Hbjku4fek+YV+yec1Yva4OoZd9rxpd0/5MG8fgahFGpA6ylX3O5CijAlcBdVfWeKatuACav5NkMXD+l/fXd1UDnAIe6U0SfAc5LcnL35u95XZskaQjm8lLsBcDrgN1Jvtq1/Q5wOXBtkouBu4FXdes+BbwU2Av8GHgjQFUdTPJ24Jau39uq6uCiVCFJ6tusAVBVf8P05+8Bzp2mfwGXzLCvHcCOfiYoSVoafhJYkhplAEhSo0bj0hJpinUDuDIL4KqNqwYyjrRUPAKQpEYZAJLUKANAkho10u8B7L730EA+qStJK5FHAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjDABJapQBIEmNMgAkqVGzBkCSHUkeSHLHlLYnJ9mVZE93e3LXniTvT7I3ye1Jnjdlm81d/z1JNi9NOZKkuZrLEcBVwMaj2rYBN1XVeuCmbhngJcD67mcL8EHoBQZwGfB84GzgssnQkCQNx6wBUFVfAA4e1bwJ2Nnd3wlcOKX9w9VzM3BSktOA84FdVXWwqh4EdvHIUJEkDdCx89xurKoOAFTVgSSndu2rgXum9Nvftc3U/ghJttA7emBsbIyJiYl5ThHGjoetZx2Z9/bLxajUAaNVy+HDhxf0+FwuRqUOsJZ+zTcAZpJp2upR2h/ZWLUd2A6wYcOGGh8fn/dkPnD19Vyxe7FLHLytZx0ZiTpgtGq5auMqFvL4XC4mJiZGog6wln7N9yqg+7tTO3S3D3Tt+4G1U/qtAe57lHZJ0pDMNwBuACav5NkMXD+l/fXd1UDnAIe6U0WfAc5LcnL35u95XZskaUhmPRZP8jFgHDglyX56V/NcDlyb5GLgbuBVXfdPAS8F9gI/Bt4IUFUHk7wduKXr97aqOvqNZWlF2X3vId6w7cYlHWPf5Rcs6f7VtlkDoKpePcOqc6fpW8AlM+xnB7Cjr9lJkpaMnwSWpEYZAJLUKANAkhplAEhSowwASWqUASBJjTIAJKlRBoAkNcoAkKRGGQCS1CgDQJIaZQBIUqMMAElqlAEgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGmUASFKjZv2j8JKGZ922G5d8jKs2rlryMbQ8eQQgSY0yACSpUQaAJDXKAJCkRhkAktQoA0CSGuVloFLjdt97iDcM4HLTfZdfsORjqD8eAUhSowYeAEk2JvlGkr1Jtg16fElSz0ADIMkxwJ8ALwGeAbw6yTMGOQdJUs+g3wM4G9hbVd8CSHINsAn42oDnIWnABvG1FlvPOuL7GX1IVQ1usOSVwMaq+o1u+XXA86vqN6f02QJs6RafDnxjAUOeAnxvAdsvF6NSB1jLcjQqdYC1THpaVT1ltk6DPgLING2/kEBVtR3YviiDJbdW1YbF2NcwjUodYC3L0ajUAdbSr0G/CbwfWDtleQ1w34DnIEli8AFwC7A+yelJjgMuAm4Y8BwkSQz4FFBVHUnym8BngGOAHVV15xIOuSinkpaBUakDrGU5GpU6wFr6MtA3gSVJy4efBJakRhkAktSokQyAUfm6iSRrk3w+yV1J7kzypmHPaSGSHJPkK0k+Oey5LESSk5Jcl+Tr3e/mnwx7TvOV5N93j607knwsyeOHPae5SrIjyQNJ7pjS9uQku5Ls6W5PHuYc52qGWv6we4zdnuQTSU5a7HFHLgBG7OsmjgBbq+pM4BzgkhVcC8CbgLuGPYlF8D7gr6vqHwHPZoXWlGQ18O+ADVX1LHoXZlw03Fn15Spg41Ft24Cbqmo9cFO3vBJcxSNr2QU8q6p+FfjfwKWLPejIBQBTvm6iqn4KTH7dxIpTVQeq6svd/R/Se6JZPdxZzU+SNcAFwIeGPZeFSPIk4J8CVwJU1U+r6qHhzmpBjgWOT3Is8ARW0OdyquoLwMGjmjcBO7v7O4ELBzqpeZqulqr6bFUd6RZvpve5qUU1igGwGrhnyvJ+VuiT5lRJ1gHPBb443JnM2x8DbwH+ftgTWaBfBr4L/Fl3OutDSVYNe1LzUVX3An8E3A0cAA5V1WeHO6sFG6uqA9B7AQWcOuT5LJZ/DXx6sXc6igEw69dNrDRJTgD+EnhzVf1g2PPpV5KXAQ9U1W3DnssiOBZ4HvDBqnou8CNWzmmGX9CdH98EnA48FViV5LXDnZWOluQ/0zsdfPVi73sUA2Ckvm4iyWPpPflfXVUfH/Z85ukFwCuS7KN3Su5FST463CnN235gf1VNHoldRy8QVqIXA9+uqu9W1c+AjwO/NuQ5LdT9SU4D6G4fGPJ8FiTJZuBlwGtqCT60NYoBMDJfN5Ek9M4131VV7xn2fOarqi6tqjVVtY7e7+NzVbUiX2lW1d8B9yR5etd0Liv368zvBs5J8oTusXYuK/QN7SluADZ39zcD1w9xLguSZCPw28ArqurHSzHGyAVA96bJ5NdN3AVcu8RfN7GUXgC8jt4r5q92Py8d9qTEbwFXJ7kdeA7w+0Oez7x0RzHXAV8GdtN7PlgxX6WQ5GPA3wJPT7I/ycXA5cCvJ9kD/Hq3vOzNUMt/BZ4I7Or+7/+3RR/Xr4KQpDaN3BGAJGluDABJapQBIEmNMgAkqVEGgCQ1ygCQpEYZAJLUqP8LG9GW5GOgyOEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20a8143f470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['total_goals']=df['home_team_goal']+df['away_team_goal']\n",
    "df.hist(column='total_goals', bins=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total_goals'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total_goals'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>league_id</th>\n",
       "      <th>season</th>\n",
       "      <th>stage</th>\n",
       "      <th>date</th>\n",
       "      <th>match_api_id</th>\n",
       "      <th>home_team_api_id</th>\n",
       "      <th>away_team_api_id</th>\n",
       "      <th>home_team_goal</th>\n",
       "      <th>...</th>\n",
       "      <th>LBA</th>\n",
       "      <th>WHH</th>\n",
       "      <th>WHD</th>\n",
       "      <th>WHA</th>\n",
       "      <th>VCH</th>\n",
       "      <th>VCD</th>\n",
       "      <th>VCA</th>\n",
       "      <th>other_column</th>\n",
       "      <th>total_goals</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19694</td>\n",
       "      <td>19694</td>\n",
       "      <td>19694</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>9-Aug-08</td>\n",
       "      <td>489981</td>\n",
       "      <td>8596</td>\n",
       "      <td>8548</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.44</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.44</td>\n",
       "      <td>6.50</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19696</td>\n",
       "      <td>19694</td>\n",
       "      <td>19694</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>9-Aug-08</td>\n",
       "      <td>489983</td>\n",
       "      <td>8597</td>\n",
       "      <td>10251</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.40</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4776</td>\n",
       "      <td>4769</td>\n",
       "      <td>4769</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>9-Aug-08</td>\n",
       "      <td>483136</td>\n",
       "      <td>9851</td>\n",
       "      <td>8592</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.65</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4774</td>\n",
       "      <td>4769</td>\n",
       "      <td>4769</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>9-Aug-08</td>\n",
       "      <td>483134</td>\n",
       "      <td>9829</td>\n",
       "      <td>9847</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.87</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4778</td>\n",
       "      <td>4769</td>\n",
       "      <td>4769</td>\n",
       "      <td>2008/2009</td>\n",
       "      <td>1</td>\n",
       "      <td>9-Aug-08</td>\n",
       "      <td>483138</td>\n",
       "      <td>9873</td>\n",
       "      <td>9853</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.87</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.88</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  country_id  league_id     season  stage      date  match_api_id  \\\n",
       "0  19694       19694      19694  2008/2009      1  9-Aug-08        489981   \n",
       "1  19696       19694      19694  2008/2009      1  9-Aug-08        489983   \n",
       "2   4776        4769       4769  2008/2009      1  9-Aug-08        483136   \n",
       "3   4774        4769       4769  2008/2009      1  9-Aug-08        483134   \n",
       "4   4778        4769       4769  2008/2009      1  9-Aug-08        483138   \n",
       "\n",
       "   home_team_api_id  away_team_api_id  home_team_goal   ...     LBA   WHH  \\\n",
       "0              8596              8548               0   ...    1.44  6.00   \n",
       "1              8597             10251               1   ...    2.60  2.50   \n",
       "2              9851              8592               4   ...    2.60  2.60   \n",
       "3              9829              9847               1   ...    2.87  2.30   \n",
       "4              9873              9853               1   ...    2.87  2.38   \n",
       "\n",
       "    WHD   WHA   VCH   VCD   VCA  other_column  total_goals  output  \n",
       "0  3.75  1.44  6.50  3.75  1.45             1            1       0  \n",
       "1  3.10  2.50  2.40  3.20  2.60             1            1       0  \n",
       "2  2.80  2.60  2.65  2.90  2.65             8            8       1  \n",
       "3  2.90  2.90  2.25  3.00  3.00             1            1       0  \n",
       "4  2.80  2.88  2.25  2.90  3.10             1            1       0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def betting(dl):\n",
    "    if dl > 2.5: return 1\n",
    "    else: return 0\n",
    "df[\"output\"] = df['total_goals'].map(betting)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([df['stage'], df['B365H'], df['B365D'], df['B365A']])\n",
    "y=np.array([df['output']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the units\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x=scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "new_df=df[['home_team_api_id','away_team_api_id','stage','B365H', 'B365D', 'B365A', 'output']]\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(new_df, test_size=0.2)\n",
    "\n",
    "x_train=train.iloc[:, 2:6]\n",
    "x_test=test.iloc[:, 2:6]\n",
    "y_train=train.iloc[:, 6]\n",
    "y_test=test.iloc[:, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 2s 136us/step - loss: 0.6903 - acc: 0.5114\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 2s 121us/step - loss: 0.6882 - acc: 0.5280\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 2s 123us/step - loss: 0.6875 - acc: 0.5389\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 2s 124us/step - loss: 0.6874 - acc: 0.5366\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 2s 121us/step - loss: 0.6872 - acc: 0.5378\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 2s 122us/step - loss: 0.6870 - acc: 0.5402\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 2s 123us/step - loss: 0.6868 - acc: 0.5422\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 2s 122us/step - loss: 0.6868 - acc: 0.5409\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 2s 124us/step - loss: 0.6868 - acc: 0.5413\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 2s 123us/step - loss: 0.6867 - acc: 0.5410\n",
      "1806/1806 [==============================] - 0s 86us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 2s 138us/step - loss: 0.6906 - acc: 0.5117\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 2s 123us/step - loss: 0.6887 - acc: 0.5256\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 2s 127us/step - loss: 0.6883 - acc: 0.5321\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 2s 124us/step - loss: 0.6881 - acc: 0.5290\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 2s 121us/step - loss: 0.6880 - acc: 0.5328\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 2s 122us/step - loss: 0.6877 - acc: 0.5347\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 2s 125us/step - loss: 0.6877 - acc: 0.5382\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 2s 124us/step - loss: 0.6875 - acc: 0.5355\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 2s 123us/step - loss: 0.6875 - acc: 0.5368\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 2s 121us/step - loss: 0.6874 - acc: 0.5374\n",
      "1806/1806 [==============================] - 0s 91us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 2s 138us/step - loss: 0.6897 - acc: 0.5204\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 2s 122us/step - loss: 0.6883 - acc: 0.5298\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 2s 125us/step - loss: 0.6885 - acc: 0.5314\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 2s 123us/step - loss: 0.6883 - acc: 0.5309\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 2s 124us/step - loss: 0.6883 - acc: 0.5324\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 2s 127us/step - loss: 0.6882 - acc: 0.5321\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 2s 129us/step - loss: 0.6882 - acc: 0.5284\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 2s 126us/step - loss: 0.6881 - acc: 0.5323\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 2s 123us/step - loss: 0.6883 - acc: 0.5308\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 2s 121us/step - loss: 0.6884 - acc: 0.5323\n",
      "1806/1806 [==============================] - 0s 99us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 2s 143us/step - loss: 0.6902 - acc: 0.5233\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 2s 126us/step - loss: 0.6884 - acc: 0.5315\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 2s 123us/step - loss: 0.6881 - acc: 0.5314\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 2s 123us/step - loss: 0.6878 - acc: 0.5350\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 2s 123us/step - loss: 0.6877 - acc: 0.5352\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 2s 122us/step - loss: 0.6876 - acc: 0.5372\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 2s 122us/step - loss: 0.6875 - acc: 0.5387\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 2s 122us/step - loss: 0.6875 - acc: 0.5365\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 2s 122us/step - loss: 0.6877 - acc: 0.5358\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 2s 122us/step - loss: 0.6872 - acc: 0.5379\n",
      "1806/1806 [==============================] - 0s 108us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 2s 144us/step - loss: 0.6900 - acc: 0.5166\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 2s 124us/step - loss: 0.6886 - acc: 0.5300\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 2s 124us/step - loss: 0.6881 - acc: 0.5368\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 2s 123us/step - loss: 0.6877 - acc: 0.5358\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 2s 124us/step - loss: 0.6875 - acc: 0.5342\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 2s 124us/step - loss: 0.6875 - acc: 0.5397\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 2s 122us/step - loss: 0.6874 - acc: 0.5426\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 2s 122us/step - loss: 0.6876 - acc: 0.5360\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 2s 123us/step - loss: 0.6875 - acc: 0.5392\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 2s 124us/step - loss: 0.6874 - acc: 0.5406\n",
      "1806/1806 [==============================] - 0s 111us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 2s 149us/step - loss: 0.6899 - acc: 0.5153\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 2s 126us/step - loss: 0.6886 - acc: 0.5302\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 2s 128us/step - loss: 0.6882 - acc: 0.5358\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 2s 125us/step - loss: 0.6881 - acc: 0.5389\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 2s 122us/step - loss: 0.6879 - acc: 0.5381\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 2s 138us/step - loss: 0.6879 - acc: 0.5371\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 2s 130us/step - loss: 0.6877 - acc: 0.5361\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 2s 134us/step - loss: 0.6878 - acc: 0.5374\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 2s 129us/step - loss: 0.6877 - acc: 0.5374\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 2s 130us/step - loss: 0.6875 - acc: 0.5401\n",
      "1806/1806 [==============================] - 0s 130us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 2s 149us/step - loss: 0.6903 - acc: 0.5169\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 2s 127us/step - loss: 0.6885 - acc: 0.5307\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 2s 126us/step - loss: 0.6881 - acc: 0.5307\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 2s 126us/step - loss: 0.6882 - acc: 0.5321\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 2s 125us/step - loss: 0.6879 - acc: 0.5364\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 2s 127us/step - loss: 0.6880 - acc: 0.5367\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 2s 128us/step - loss: 0.6880 - acc: 0.5357\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 2s 125us/step - loss: 0.6879 - acc: 0.5348\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 2s 127us/step - loss: 0.6879 - acc: 0.5348\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 2s 125us/step - loss: 0.6880 - acc: 0.5361\n",
      "1805/1805 [==============================] - 0s 126us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 3s 155us/step - loss: 0.6902 - acc: 0.5188\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 2s 127us/step - loss: 0.6888 - acc: 0.5313\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 2s 128us/step - loss: 0.6886 - acc: 0.5311\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 2s 127us/step - loss: 0.6884 - acc: 0.5352\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 2s 126us/step - loss: 0.6882 - acc: 0.5338\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 2s 127us/step - loss: 0.6880 - acc: 0.5401\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 2s 126us/step - loss: 0.6882 - acc: 0.5376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 2s 128us/step - loss: 0.6879 - acc: 0.5363\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 2s 128us/step - loss: 0.6878 - acc: 0.5362\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 2s 128us/step - loss: 0.6878 - acc: 0.5385\n",
      "1805/1805 [==============================] - 0s 131us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 2s 150us/step - loss: 0.6903 - acc: 0.5195\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 2s 130us/step - loss: 0.6887 - acc: 0.5332\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 2s 128us/step - loss: 0.6885 - acc: 0.5340\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 2s 128us/step - loss: 0.6883 - acc: 0.5346\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 2s 128us/step - loss: 0.6879 - acc: 0.5363\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 2s 128us/step - loss: 0.6879 - acc: 0.5391\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 2s 126us/step - loss: 0.6875 - acc: 0.5407\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 2s 127us/step - loss: 0.6877 - acc: 0.5400\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 2s 130us/step - loss: 0.6876 - acc: 0.5390\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 2s 125us/step - loss: 0.6875 - acc: 0.5406\n",
      "1805/1805 [==============================] - 0s 137us/step\n",
      "Epoch 1/10\n",
      "16251/16251 [==============================] - 2s 152us/step - loss: 0.6903 - acc: 0.5131\n",
      "Epoch 2/10\n",
      "16251/16251 [==============================] - 2s 125us/step - loss: 0.6888 - acc: 0.5261\n",
      "Epoch 3/10\n",
      "16251/16251 [==============================] - 2s 127us/step - loss: 0.6884 - acc: 0.5350\n",
      "Epoch 4/10\n",
      "16251/16251 [==============================] - 2s 126us/step - loss: 0.6881 - acc: 0.5356\n",
      "Epoch 5/10\n",
      "16251/16251 [==============================] - 2s 127us/step - loss: 0.6878 - acc: 0.5377\n",
      "Epoch 6/10\n",
      "16251/16251 [==============================] - 2s 134us/step - loss: 0.6879 - acc: 0.5378\n",
      "Epoch 7/10\n",
      "16251/16251 [==============================] - 2s 128us/step - loss: 0.6880 - acc: 0.5354\n",
      "Epoch 8/10\n",
      "16251/16251 [==============================] - 2s 128us/step - loss: 0.6877 - acc: 0.5363\n",
      "Epoch 9/10\n",
      "16251/16251 [==============================] - 2s 127us/step - loss: 0.6879 - acc: 0.5370\n",
      "Epoch 10/10\n",
      "16251/16251 [==============================] - 2s 127us/step - loss: 0.6880 - acc: 0.5378\n",
      "1804/1804 [==============================] - 0s 143us/step\n",
      "0.5353101327278367\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=4, activation='relu', kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=\"uniform\"))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=10, verbose=1)\n",
    "\n",
    "# evaluate using 10-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, x_train, y_train, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "16249/16249 [==============================] - 3s 187us/step - loss: 0.6899 - acc: 0.5180\n",
      "Epoch 2/8\n",
      "16249/16249 [==============================] - 3s 163us/step - loss: 0.6883 - acc: 0.5301\n",
      "Epoch 3/8\n",
      "16249/16249 [==============================] - 3s 164us/step - loss: 0.6877 - acc: 0.5318\n",
      "Epoch 4/8\n",
      "16249/16249 [==============================] - 3s 163us/step - loss: 0.6878 - acc: 0.5323\n",
      "Epoch 5/8\n",
      "16249/16249 [==============================] - 3s 163us/step - loss: 0.6875 - acc: 0.5340\n",
      "Epoch 6/8\n",
      "16249/16249 [==============================] - 3s 163us/step - loss: 0.6875 - acc: 0.5362\n",
      "Epoch 7/8\n",
      "16249/16249 [==============================] - 3s 167us/step - loss: 0.6877 - acc: 0.5361\n",
      "Epoch 8/8\n",
      "16249/16249 [==============================] - 3s 166us/step - loss: 0.6873 - acc: 0.5390\n",
      "1806/1806 [==============================] - 0s 175us/step\n",
      "16249/16249 [==============================] - 2s 98us/step\n",
      "Epoch 1/8\n",
      "16249/16249 [==============================] - 4s 217us/step - loss: 0.6908 - acc: 0.5157\n",
      "Epoch 2/8\n",
      "16249/16249 [==============================] - 3s 162us/step - loss: 0.6891 - acc: 0.5245\n",
      "Epoch 3/8\n",
      "16249/16249 [==============================] - 3s 167us/step - loss: 0.6886 - acc: 0.5334\n",
      "Epoch 4/8\n",
      "16249/16249 [==============================] - 3s 163us/step - loss: 0.6884 - acc: 0.5342\n",
      "Epoch 5/8\n",
      "16249/16249 [==============================] - 3s 163us/step - loss: 0.6881 - acc: 0.5373\n",
      "Epoch 6/8\n",
      "16249/16249 [==============================] - 3s 165us/step - loss: 0.6882 - acc: 0.5394\n",
      "Epoch 7/8\n",
      "16249/16249 [==============================] - 3s 162us/step - loss: 0.6879 - acc: 0.5400\n",
      "Epoch 8/8\n",
      "16249/16249 [==============================] - 3s 170us/step - loss: 0.6881 - acc: 0.5375\n",
      "1806/1806 [==============================] - 0s 174us/step\n",
      "16249/16249 [==============================] - 2s 97us/step\n",
      "Epoch 1/8\n",
      "16249/16249 [==============================] - 3s 195us/step - loss: 0.6901 - acc: 0.5190\n",
      "Epoch 2/8\n",
      "16249/16249 [==============================] - 3s 196us/step - loss: 0.6887 - acc: 0.5263 0s - loss: 0.6887 - \n",
      "Epoch 3/8\n",
      "16249/16249 [==============================] - 3s 191us/step - loss: 0.6885 - acc: 0.5326\n",
      "Epoch 4/8\n",
      "16249/16249 [==============================] - 3s 193us/step - loss: 0.6883 - acc: 0.5283\n",
      "Epoch 5/8\n",
      "16249/16249 [==============================] - 3s 170us/step - loss: 0.6882 - acc: 0.5327\n",
      "Epoch 6/8\n",
      "16249/16249 [==============================] - 3s 182us/step - loss: 0.6883 - acc: 0.5300\n",
      "Epoch 7/8\n",
      "16249/16249 [==============================] - 3s 171us/step - loss: 0.6881 - acc: 0.5334\n",
      "Epoch 8/8\n",
      "16249/16249 [==============================] - 3s 169us/step - loss: 0.6882 - acc: 0.5353\n",
      "1806/1806 [==============================] - 0s 190us/step\n",
      "16249/16249 [==============================] - 2s 98us/step\n",
      "Epoch 1/8\n",
      "16249/16249 [==============================] - 3s 200us/step - loss: 0.6902 - acc: 0.5173\n",
      "Epoch 2/8\n",
      "16249/16249 [==============================] - 3s 167us/step - loss: 0.6882 - acc: 0.5358\n",
      "Epoch 3/8\n",
      "16249/16249 [==============================] - 3s 166us/step - loss: 0.6874 - acc: 0.5397\n",
      "Epoch 4/8\n",
      "16249/16249 [==============================] - 3s 165us/step - loss: 0.6874 - acc: 0.5373\n",
      "Epoch 5/8\n",
      "16249/16249 [==============================] - 3s 164us/step - loss: 0.6872 - acc: 0.5383\n",
      "Epoch 6/8\n",
      "16249/16249 [==============================] - 3s 162us/step - loss: 0.6875 - acc: 0.5401\n",
      "Epoch 7/8\n",
      "16249/16249 [==============================] - 3s 173us/step - loss: 0.6874 - acc: 0.5363\n",
      "Epoch 8/8\n",
      "16249/16249 [==============================] - 3s 165us/step - loss: 0.6873 - acc: 0.5365\n",
      "1806/1806 [==============================] - 0s 194us/step\n",
      "16249/16249 [==============================] - 2s 97us/step\n",
      "Epoch 1/8\n",
      "16249/16249 [==============================] - 3s 201us/step - loss: 0.6903 - acc: 0.5168\n",
      "Epoch 2/8\n",
      "16249/16249 [==============================] - 3s 169us/step - loss: 0.6886 - acc: 0.5338\n",
      "Epoch 3/8\n",
      "16249/16249 [==============================] - 3s 166us/step - loss: 0.6881 - acc: 0.5383\n",
      "Epoch 4/8\n",
      "16249/16249 [==============================] - 3s 166us/step - loss: 0.6879 - acc: 0.5375\n",
      "Epoch 5/8\n",
      "16249/16249 [==============================] - 3s 163us/step - loss: 0.6879 - acc: 0.5406\n",
      "Epoch 6/8\n",
      "16249/16249 [==============================] - 3s 165us/step - loss: 0.6880 - acc: 0.5388\n",
      "Epoch 7/8\n",
      "16249/16249 [==============================] - 3s 163us/step - loss: 0.6878 - acc: 0.5370\n",
      "Epoch 8/8\n",
      "16249/16249 [==============================] - 3s 170us/step - loss: 0.6880 - acc: 0.5367\n",
      "1806/1806 [==============================] - 0s 206us/step\n",
      "16249/16249 [==============================] - 2s 97us/step\n",
      "Epoch 1/8\n",
      "16250/16250 [==============================] - 3s 202us/step - loss: 0.6905 - acc: 0.5158\n",
      "Epoch 2/8\n",
      "16250/16250 [==============================] - 3s 165us/step - loss: 0.6888 - acc: 0.5268\n",
      "Epoch 3/8\n",
      "16250/16250 [==============================] - 3s 163us/step - loss: 0.6887 - acc: 0.5295\n",
      "Epoch 4/8\n",
      "16250/16250 [==============================] - 3s 169us/step - loss: 0.6887 - acc: 0.5337\n",
      "Epoch 5/8\n",
      "16250/16250 [==============================] - 3s 178us/step - loss: 0.6882 - acc: 0.5326\n",
      "Epoch 6/8\n",
      "16250/16250 [==============================] - 3s 169us/step - loss: 0.6882 - acc: 0.5358\n",
      "Epoch 7/8\n",
      "16250/16250 [==============================] - 3s 166us/step - loss: 0.6880 - acc: 0.5320\n",
      "Epoch 8/8\n",
      "16250/16250 [==============================] - 3s 168us/step - loss: 0.6881 - acc: 0.5372\n",
      "1805/1805 [==============================] - 0s 204us/step\n",
      "16250/16250 [==============================] - 2s 96us/step\n",
      "Epoch 1/8\n",
      "16250/16250 [==============================] - 3s 206us/step - loss: 0.6901 - acc: 0.5150\n",
      "Epoch 2/8\n",
      "16250/16250 [==============================] - 3s 169us/step - loss: 0.6889 - acc: 0.5268\n",
      "Epoch 3/8\n",
      "16250/16250 [==============================] - 3s 165us/step - loss: 0.6883 - acc: 0.5284\n",
      "Epoch 4/8\n",
      "16250/16250 [==============================] - 3s 164us/step - loss: 0.6881 - acc: 0.5347\n",
      "Epoch 5/8\n",
      "16250/16250 [==============================] - 3s 167us/step - loss: 0.6880 - acc: 0.5332\n",
      "Epoch 6/8\n",
      "16250/16250 [==============================] - 3s 166us/step - loss: 0.6879 - acc: 0.5353\n",
      "Epoch 7/8\n",
      "16250/16250 [==============================] - 3s 166us/step - loss: 0.6882 - acc: 0.5333\n",
      "Epoch 8/8\n",
      "16250/16250 [==============================] - 3s 165us/step - loss: 0.6879 - acc: 0.5362\n",
      "1805/1805 [==============================] - 0s 209us/step\n",
      "16250/16250 [==============================] - 2s 97us/step\n",
      "Epoch 1/8\n",
      "16250/16250 [==============================] - 3s 206us/step - loss: 0.6907 - acc: 0.5155\n",
      "Epoch 2/8\n",
      "16250/16250 [==============================] - 3s 169us/step - loss: 0.6890 - acc: 0.5204\n",
      "Epoch 3/8\n",
      "16250/16250 [==============================] - 3s 166us/step - loss: 0.6884 - acc: 0.5312\n",
      "Epoch 4/8\n",
      "16250/16250 [==============================] - 3s 166us/step - loss: 0.6882 - acc: 0.5335\n",
      "Epoch 5/8\n",
      "16250/16250 [==============================] - 3s 167us/step - loss: 0.6882 - acc: 0.5329\n",
      "Epoch 6/8\n",
      "16250/16250 [==============================] - 3s 168us/step - loss: 0.6876 - acc: 0.5354\n",
      "Epoch 7/8\n",
      "16250/16250 [==============================] - 3s 166us/step - loss: 0.6878 - acc: 0.5416\n",
      "Epoch 8/8\n",
      "16250/16250 [==============================] - 3s 168us/step - loss: 0.6875 - acc: 0.5335\n",
      "1805/1805 [==============================] - 0s 221us/step\n",
      "16250/16250 [==============================] - 2s 100us/step\n",
      "Epoch 1/8\n",
      "16250/16250 [==============================] - 4s 217us/step - loss: 0.6895 - acc: 0.5202\n",
      "Epoch 2/8\n",
      "16250/16250 [==============================] - 3s 167us/step - loss: 0.6883 - acc: 0.5327\n",
      "Epoch 3/8\n",
      "16250/16250 [==============================] - 3s 171us/step - loss: 0.6877 - acc: 0.5373\n",
      "Epoch 4/8\n",
      "16250/16250 [==============================] - 3s 166us/step - loss: 0.6873 - acc: 0.5416\n",
      "Epoch 5/8\n",
      "16250/16250 [==============================] - 3s 172us/step - loss: 0.6874 - acc: 0.5395\n",
      "Epoch 6/8\n",
      "16250/16250 [==============================] - 3s 173us/step - loss: 0.6872 - acc: 0.5417\n",
      "Epoch 7/8\n",
      "16250/16250 [==============================] - 3s 172us/step - loss: 0.6872 - acc: 0.5402\n",
      "Epoch 8/8\n",
      "16250/16250 [==============================] - 3s 177us/step - loss: 0.6873 - acc: 0.5422\n",
      "1805/1805 [==============================] - 0s 238us/step\n",
      "16250/16250 [==============================] - 2s 105us/step\n",
      "Epoch 1/8\n",
      "16250/16250 [==============================] - 4s 220us/step - loss: 0.6905 - acc: 0.5174\n",
      "Epoch 2/8\n",
      "16250/16250 [==============================] - 3s 176us/step - loss: 0.6887 - acc: 0.5278\n",
      "Epoch 3/8\n",
      "16250/16250 [==============================] - 3s 172us/step - loss: 0.6881 - acc: 0.5338\n",
      "Epoch 4/8\n",
      "16250/16250 [==============================] - 3s 174us/step - loss: 0.6880 - acc: 0.5380\n",
      "Epoch 5/8\n",
      "16250/16250 [==============================] - 3s 180us/step - loss: 0.6880 - acc: 0.5389\n",
      "Epoch 6/8\n",
      "16250/16250 [==============================] - 3s 171us/step - loss: 0.6878 - acc: 0.5364\n",
      "Epoch 7/8\n",
      "16250/16250 [==============================] - 3s 177us/step - loss: 0.6875 - acc: 0.5408\n",
      "Epoch 8/8\n",
      "16250/16250 [==============================] - 3s 173us/step - loss: 0.6875 - acc: 0.5382\n",
      "1805/1805 [==============================] - 0s 238us/step\n",
      "16250/16250 [==============================] - 2s 101us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 4s 218us/step - loss: 0.6901 - acc: 0.5178\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 3s 175us/step - loss: 0.6883 - acc: 0.5290\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 3s 177us/step - loss: 0.6880 - acc: 0.5315\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 3s 172us/step - loss: 0.6877 - acc: 0.5336\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 3s 175us/step - loss: 0.6878 - acc: 0.5327\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 3s 173us/step - loss: 0.6875 - acc: 0.5354\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 3s 176us/step - loss: 0.6876 - acc: 0.5361\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 3s 174us/step - loss: 0.6875 - acc: 0.5350\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 3s 174us/step - loss: 0.6873 - acc: 0.5406\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 3s 173us/step - loss: 0.6871 - acc: 0.5410\n",
      "1806/1806 [==============================] - 0s 244us/step\n",
      "16249/16249 [==============================] - 2s 103us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 4s 217us/step - loss: 0.6903 - acc: 0.5149\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 3s 175us/step - loss: 0.6889 - acc: 0.5259\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 3s 174us/step - loss: 0.6890 - acc: 0.5296\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 3s 181us/step - loss: 0.6887 - acc: 0.5333\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 3s 185us/step - loss: 0.6885 - acc: 0.5344\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 3s 182us/step - loss: 0.6883 - acc: 0.5357\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 3s 177us/step - loss: 0.6879 - acc: 0.5346\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 3s 174us/step - loss: 0.6880 - acc: 0.5382\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 3s 183us/step - loss: 0.6876 - acc: 0.5413 0s - loss: 0.6879\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 3s 178us/step - loss: 0.6881 - acc: 0.5382\n",
      "1806/1806 [==============================] - 0s 254us/step\n",
      "16249/16249 [==============================] - 2s 104us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 4s 220us/step - loss: 0.6910 - acc: 0.5083\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 3s 182us/step - loss: 0.6883 - acc: 0.5319\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 3s 174us/step - loss: 0.6880 - acc: 0.5346\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 3s 175us/step - loss: 0.6878 - acc: 0.5357\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 3s 187us/step - loss: 0.6877 - acc: 0.5383\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 3s 176us/step - loss: 0.6875 - acc: 0.5394\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 3s 173us/step - loss: 0.6877 - acc: 0.5373\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 3s 176us/step - loss: 0.6874 - acc: 0.5412\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 3s 174us/step - loss: 0.6877 - acc: 0.5406\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 3s 185us/step - loss: 0.6876 - acc: 0.5391\n",
      "1806/1806 [==============================] - 0s 262us/step\n",
      "16249/16249 [==============================] - 2s 103us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 4s 222us/step - loss: 0.6903 - acc: 0.5142\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 3s 180us/step - loss: 0.6886 - acc: 0.5298\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 3s 172us/step - loss: 0.6879 - acc: 0.5366\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 3s 175us/step - loss: 0.6876 - acc: 0.5389\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 3s 183us/step - loss: 0.6873 - acc: 0.5405\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 3s 178us/step - loss: 0.6873 - acc: 0.5370\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 3s 175us/step - loss: 0.6872 - acc: 0.5367\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 3s 181us/step - loss: 0.6870 - acc: 0.5412\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 3s 187us/step - loss: 0.6873 - acc: 0.5410\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 3s 179us/step - loss: 0.6873 - acc: 0.5394\n",
      "1806/1806 [==============================] - 0s 267us/step\n",
      "16249/16249 [==============================] - 2s 107us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 4s 232us/step - loss: 0.6908 - acc: 0.5143\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 3s 184us/step - loss: 0.6891 - acc: 0.5254\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 3s 184us/step - loss: 0.6887 - acc: 0.5298\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 3s 185us/step - loss: 0.6887 - acc: 0.5327\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 3s 177us/step - loss: 0.6882 - acc: 0.5365\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 3s 178us/step - loss: 0.6880 - acc: 0.5389\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 3s 185us/step - loss: 0.6880 - acc: 0.5383\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 3s 183us/step - loss: 0.6881 - acc: 0.5374\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 3s 185us/step - loss: 0.6879 - acc: 0.5397\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 3s 183us/step - loss: 0.6878 - acc: 0.5379\n",
      "1806/1806 [==============================] - 0s 275us/step\n",
      "16249/16249 [==============================] - 2s 103us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 4s 233us/step - loss: 0.6901 - acc: 0.5235\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 3s 183us/step - loss: 0.6887 - acc: 0.5308\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 3s 180us/step - loss: 0.6885 - acc: 0.5315\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 3s 185us/step - loss: 0.6884 - acc: 0.5370\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 3s 189us/step - loss: 0.6878 - acc: 0.5329\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 3s 186us/step - loss: 0.6880 - acc: 0.5364\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 3s 185us/step - loss: 0.6879 - acc: 0.5371\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 3s 183us/step - loss: 0.6879 - acc: 0.5395\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 3s 187us/step - loss: 0.6876 - acc: 0.5414\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 3s 184us/step - loss: 0.6876 - acc: 0.5363\n",
      "1805/1805 [==============================] - 1s 406us/step\n",
      "16250/16250 [==============================] - 2s 126us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 4s 235us/step - loss: 0.6901 - acc: 0.5200\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 3s 184us/step - loss: 0.6884 - acc: 0.5330\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 3s 188us/step - loss: 0.6881 - acc: 0.5370\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16250/16250 [==============================] - 3s 181us/step - loss: 0.6881 - acc: 0.5326\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 3s 182us/step - loss: 0.6879 - acc: 0.5330\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 3s 182us/step - loss: 0.6878 - acc: 0.5375\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 3s 181us/step - loss: 0.6874 - acc: 0.5385\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 3s 190us/step - loss: 0.6874 - acc: 0.5395\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 3s 182us/step - loss: 0.6873 - acc: 0.5407\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 3s 181us/step - loss: 0.6873 - acc: 0.5407\n",
      "1805/1805 [==============================] - 1s 295us/step\n",
      "16250/16250 [==============================] - 2s 108us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 4s 234us/step - loss: 0.6901 - acc: 0.5167\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 3s 179us/step - loss: 0.6884 - acc: 0.5298\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 3s 183us/step - loss: 0.6883 - acc: 0.5312\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 3s 187us/step - loss: 0.6882 - acc: 0.5311\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 3s 183us/step - loss: 0.6882 - acc: 0.5336\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 3s 183us/step - loss: 0.6881 - acc: 0.5358\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 3s 183us/step - loss: 0.6880 - acc: 0.5338\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 3s 188us/step - loss: 0.6881 - acc: 0.5335\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 3s 184us/step - loss: 0.6881 - acc: 0.5330\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 3s 180us/step - loss: 0.6880 - acc: 0.5326\n",
      "1805/1805 [==============================] - 1s 300us/step\n",
      "16250/16250 [==============================] - 2s 109us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 4s 240us/step - loss: 0.6906 - acc: 0.5082\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 3s 182us/step - loss: 0.6882 - acc: 0.5311\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 3s 190us/step - loss: 0.6881 - acc: 0.5336\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 3s 192us/step - loss: 0.6879 - acc: 0.5342\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 3s 188us/step - loss: 0.6879 - acc: 0.5370\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 3s 184us/step - loss: 0.6879 - acc: 0.5346\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 3s 187us/step - loss: 0.6880 - acc: 0.5364\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 3s 181us/step - loss: 0.6877 - acc: 0.5362\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 3s 181us/step - loss: 0.6878 - acc: 0.5332\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 3s 188us/step - loss: 0.6877 - acc: 0.5358\n",
      "1805/1805 [==============================] - 1s 341us/step\n",
      "16250/16250 [==============================] - 2s 110us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 4s 249us/step - loss: 0.6904 - acc: 0.5158\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 3s 181us/step - loss: 0.6887 - acc: 0.5296\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 3s 182us/step - loss: 0.6883 - acc: 0.5372\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 3s 183us/step - loss: 0.6879 - acc: 0.5348\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 3s 183us/step - loss: 0.6878 - acc: 0.5364\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 3s 189us/step - loss: 0.6876 - acc: 0.5406\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 3s 184us/step - loss: 0.6874 - acc: 0.5411\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 3s 182us/step - loss: 0.6876 - acc: 0.5377\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 3s 183us/step - loss: 0.6876 - acc: 0.5374\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 3s 185us/step - loss: 0.6876 - acc: 0.5386\n",
      "1805/1805 [==============================] - 1s 311us/step\n",
      "16250/16250 [==============================] - 2s 110us/step\n",
      "Epoch 1/12\n",
      "16249/16249 [==============================] - 4s 242us/step - loss: 0.6902 - acc: 0.5197\n",
      "Epoch 2/12\n",
      "16249/16249 [==============================] - 3s 182us/step - loss: 0.6886 - acc: 0.5288\n",
      "Epoch 3/12\n",
      "16249/16249 [==============================] - 3s 184us/step - loss: 0.6879 - acc: 0.5358\n",
      "Epoch 4/12\n",
      "16249/16249 [==============================] - 3s 183us/step - loss: 0.6878 - acc: 0.5348\n",
      "Epoch 5/12\n",
      "16249/16249 [==============================] - 3s 183us/step - loss: 0.6876 - acc: 0.5394\n",
      "Epoch 6/12\n",
      "16249/16249 [==============================] - 3s 194us/step - loss: 0.6874 - acc: 0.5373\n",
      "Epoch 7/12\n",
      "16249/16249 [==============================] - 3s 191us/step - loss: 0.6875 - acc: 0.5378\n",
      "Epoch 8/12\n",
      "16249/16249 [==============================] - 4s 226us/step - loss: 0.6874 - acc: 0.5358 0s - loss: 0\n",
      "Epoch 9/12\n",
      "16249/16249 [==============================] - 4s 256us/step - loss: 0.6869 - acc: 0.5438\n",
      "Epoch 10/12\n",
      "16249/16249 [==============================] - 4s 232us/step - loss: 0.6870 - acc: 0.5393\n",
      "Epoch 11/12\n",
      "16249/16249 [==============================] - 3s 189us/step - loss: 0.6871 - acc: 0.5411\n",
      "Epoch 12/12\n",
      "16249/16249 [==============================] - 4s 224us/step - loss: 0.6872 - acc: 0.5392\n",
      "1806/1806 [==============================] - 1s 342us/step\n",
      "16249/16249 [==============================] - 2s 115us/step\n",
      "Epoch 1/12\n",
      "16249/16249 [==============================] - 4s 271us/step - loss: 0.6902 - acc: 0.5186\n",
      "Epoch 2/12\n",
      "16249/16249 [==============================] - 4s 236us/step - loss: 0.6888 - acc: 0.5284\n",
      "Epoch 3/12\n",
      "16249/16249 [==============================] - 3s 206us/step - loss: 0.6887 - acc: 0.5296\n",
      "Epoch 4/12\n",
      "16249/16249 [==============================] - 3s 202us/step - loss: 0.6885 - acc: 0.5315\n",
      "Epoch 5/12\n",
      "16249/16249 [==============================] - 3s 210us/step - loss: 0.6883 - acc: 0.5349\n",
      "Epoch 6/12\n",
      "16249/16249 [==============================] - 3s 197us/step - loss: 0.6880 - acc: 0.5338\n",
      "Epoch 7/12\n",
      "16249/16249 [==============================] - 3s 210us/step - loss: 0.6880 - acc: 0.5360\n",
      "Epoch 8/12\n",
      "16249/16249 [==============================] - 3s 188us/step - loss: 0.6881 - acc: 0.5366\n",
      "Epoch 9/12\n",
      "16249/16249 [==============================] - 3s 200us/step - loss: 0.6880 - acc: 0.5361\n",
      "Epoch 10/12\n",
      "16249/16249 [==============================] - 3s 201us/step - loss: 0.6879 - acc: 0.5369\n",
      "Epoch 11/12\n",
      "16249/16249 [==============================] - 3s 184us/step - loss: 0.6876 - acc: 0.5387\n",
      "Epoch 12/12\n",
      "16249/16249 [==============================] - 3s 188us/step - loss: 0.6878 - acc: 0.5376\n",
      "1806/1806 [==============================] - 1s 330us/step\n",
      "16249/16249 [==============================] - 2s 119us/step\n",
      "Epoch 1/12\n",
      "16249/16249 [==============================] - 4s 268us/step - loss: 0.6902 - acc: 0.5131\n",
      "Epoch 2/12\n",
      "16249/16249 [==============================] - 3s 191us/step - loss: 0.6886 - acc: 0.5319\n",
      "Epoch 3/12\n",
      "16249/16249 [==============================] - 3s 202us/step - loss: 0.6882 - acc: 0.5352\n",
      "Epoch 4/12\n",
      "16249/16249 [==============================] - 3s 199us/step - loss: 0.6879 - acc: 0.5365\n",
      "Epoch 5/12\n",
      "16249/16249 [==============================] - 3s 191us/step - loss: 0.6877 - acc: 0.5370\n",
      "Epoch 6/12\n",
      "16249/16249 [==============================] - 3s 194us/step - loss: 0.6875 - acc: 0.5396\n",
      "Epoch 7/12\n",
      "16249/16249 [==============================] - 3s 190us/step - loss: 0.6875 - acc: 0.5383\n",
      "Epoch 8/12\n",
      "16249/16249 [==============================] - 3s 207us/step - loss: 0.6874 - acc: 0.5363\n",
      "Epoch 9/12\n",
      "16249/16249 [==============================] - 4s 254us/step - loss: 0.6874 - acc: 0.5413 1s - loss\n",
      "Epoch 10/12\n",
      "16249/16249 [==============================] - 3s 186us/step - loss: 0.6875 - acc: 0.5371\n",
      "Epoch 11/12\n",
      "16249/16249 [==============================] - 3s 188us/step - loss: 0.6875 - acc: 0.5420\n",
      "Epoch 12/12\n",
      "16249/16249 [==============================] - 3s 187us/step - loss: 0.6874 - acc: 0.5375\n",
      "1806/1806 [==============================] - 1s 345us/step\n",
      "16249/16249 [==============================] - 2s 111us/step\n",
      "Epoch 1/12\n",
      "16249/16249 [==============================] - 4s 253us/step - loss: 0.6904 - acc: 0.5136\n",
      "Epoch 2/12\n",
      "16249/16249 [==============================] - 3s 192us/step - loss: 0.6885 - acc: 0.5300\n",
      "Epoch 3/12\n",
      "16249/16249 [==============================] - 3s 186us/step - loss: 0.6878 - acc: 0.5362\n",
      "Epoch 4/12\n",
      "16249/16249 [==============================] - 3s 185us/step - loss: 0.6874 - acc: 0.5379\n",
      "Epoch 5/12\n",
      "16249/16249 [==============================] - 3s 200us/step - loss: 0.6875 - acc: 0.5385\n",
      "Epoch 6/12\n",
      "16249/16249 [==============================] - 3s 211us/step - loss: 0.6871 - acc: 0.5429\n",
      "Epoch 7/12\n",
      "16249/16249 [==============================] - 3s 199us/step - loss: 0.6874 - acc: 0.5416\n",
      "Epoch 8/12\n",
      "16249/16249 [==============================] - 4s 225us/step - loss: 0.6873 - acc: 0.5397\n",
      "Epoch 9/12\n",
      "16249/16249 [==============================] - 3s 210us/step - loss: 0.6872 - acc: 0.5410\n",
      "Epoch 10/12\n",
      "16249/16249 [==============================] - 3s 195us/step - loss: 0.6872 - acc: 0.5417\n",
      "Epoch 11/12\n",
      "16249/16249 [==============================] - 4s 245us/step - loss: 0.6873 - acc: 0.5413\n",
      "Epoch 12/12\n",
      "16249/16249 [==============================] - 3s 215us/step - loss: 0.6871 - acc: 0.5426\n",
      "1806/1806 [==============================] - 1s 351us/step\n",
      "16249/16249 [==============================] - 2s 116us/step\n",
      "Epoch 1/12\n",
      "16249/16249 [==============================] - 4s 267us/step - loss: 0.6913 - acc: 0.5120\n",
      "Epoch 2/12\n",
      "16249/16249 [==============================] - 3s 206us/step - loss: 0.6892 - acc: 0.5240\n",
      "Epoch 3/12\n",
      "16249/16249 [==============================] - 3s 203us/step - loss: 0.6886 - acc: 0.5313\n",
      "Epoch 4/12\n",
      "16249/16249 [==============================] - 3s 199us/step - loss: 0.6884 - acc: 0.5338\n",
      "Epoch 5/12\n",
      "16249/16249 [==============================] - 3s 203us/step - loss: 0.6881 - acc: 0.5334\n",
      "Epoch 6/12\n",
      "16249/16249 [==============================] - 3s 203us/step - loss: 0.6880 - acc: 0.5347\n",
      "Epoch 7/12\n",
      "16249/16249 [==============================] - 3s 191us/step - loss: 0.6880 - acc: 0.5378\n",
      "Epoch 8/12\n",
      "16249/16249 [==============================] - 3s 198us/step - loss: 0.6878 - acc: 0.5352\n",
      "Epoch 9/12\n",
      "16249/16249 [==============================] - 3s 193us/step - loss: 0.6878 - acc: 0.5370\n",
      "Epoch 10/12\n",
      "16249/16249 [==============================] - 3s 197us/step - loss: 0.6878 - acc: 0.5408\n",
      "Epoch 11/12\n",
      "16249/16249 [==============================] - 3s 192us/step - loss: 0.6877 - acc: 0.5401\n",
      "Epoch 12/12\n",
      "16249/16249 [==============================] - 3s 195us/step - loss: 0.6876 - acc: 0.5386\n",
      "1806/1806 [==============================] - 1s 356us/step\n",
      "16249/16249 [==============================] - 2s 118us/step\n",
      "Epoch 1/12\n",
      "16250/16250 [==============================] - 4s 260us/step - loss: 0.6903 - acc: 0.5131\n",
      "Epoch 2/12\n",
      "16250/16250 [==============================] - 3s 191us/step - loss: 0.6886 - acc: 0.5309\n",
      "Epoch 3/12\n",
      "16250/16250 [==============================] - 3s 192us/step - loss: 0.6884 - acc: 0.5310\n",
      "Epoch 4/12\n",
      "16250/16250 [==============================] - 3s 194us/step - loss: 0.6883 - acc: 0.5358\n",
      "Epoch 5/12\n",
      "16250/16250 [==============================] - 3s 190us/step - loss: 0.6879 - acc: 0.5380\n",
      "Epoch 6/12\n",
      "16250/16250 [==============================] - 3s 191us/step - loss: 0.6880 - acc: 0.5344\n",
      "Epoch 7/12\n",
      "16250/16250 [==============================] - 3s 192us/step - loss: 0.6880 - acc: 0.5379\n",
      "Epoch 8/12\n",
      "16250/16250 [==============================] - 3s 190us/step - loss: 0.6876 - acc: 0.5353\n",
      "Epoch 9/12\n",
      "16250/16250 [==============================] - 3s 191us/step - loss: 0.6879 - acc: 0.5415\n",
      "Epoch 10/12\n",
      "16250/16250 [==============================] - 3s 193us/step - loss: 0.6877 - acc: 0.5382\n",
      "Epoch 11/12\n",
      "16250/16250 [==============================] - 3s 189us/step - loss: 0.6877 - acc: 0.5364\n",
      "Epoch 12/12\n",
      "16250/16250 [==============================] - 3s 189us/step - loss: 0.6875 - acc: 0.5362\n",
      "1805/1805 [==============================] - 1s 360us/step\n",
      "16250/16250 [==============================] - 2s 114us/step\n",
      "Epoch 1/12\n",
      "16250/16250 [==============================] - 4s 271us/step - loss: 0.6901 - acc: 0.5191\n",
      "Epoch 2/12\n",
      "16250/16250 [==============================] - 3s 193us/step - loss: 0.6881 - acc: 0.5335\n",
      "Epoch 3/12\n",
      "16250/16250 [==============================] - 3s 191us/step - loss: 0.6878 - acc: 0.5410\n",
      "Epoch 4/12\n",
      "16250/16250 [==============================] - 3s 188us/step - loss: 0.6878 - acc: 0.5385\n",
      "Epoch 5/12\n",
      "16250/16250 [==============================] - 3s 193us/step - loss: 0.6875 - acc: 0.5375\n",
      "Epoch 6/12\n",
      "16250/16250 [==============================] - 3s 197us/step - loss: 0.6873 - acc: 0.5394\n",
      "Epoch 7/12\n",
      "16250/16250 [==============================] - 3s 191us/step - loss: 0.6874 - acc: 0.5402\n",
      "Epoch 8/12\n",
      "16250/16250 [==============================] - 3s 193us/step - loss: 0.6874 - acc: 0.5389\n",
      "Epoch 9/12\n",
      "16250/16250 [==============================] - 3s 191us/step - loss: 0.6873 - acc: 0.5411\n",
      "Epoch 10/12\n",
      "16250/16250 [==============================] - 3s 192us/step - loss: 0.6873 - acc: 0.5394\n",
      "Epoch 11/12\n",
      "16250/16250 [==============================] - 3s 193us/step - loss: 0.6872 - acc: 0.5388\n",
      "Epoch 12/12\n",
      "16250/16250 [==============================] - 3s 190us/step - loss: 0.6871 - acc: 0.5386\n",
      "1805/1805 [==============================] - 1s 377us/step\n",
      "16250/16250 [==============================] - 2s 116us/step\n",
      "Epoch 1/12\n",
      "16250/16250 [==============================] - 4s 264us/step - loss: 0.6906 - acc: 0.5205\n",
      "Epoch 2/12\n",
      "16250/16250 [==============================] - 3s 191us/step - loss: 0.6890 - acc: 0.5222\n",
      "Epoch 3/12\n",
      "16250/16250 [==============================] - 3s 191us/step - loss: 0.6884 - acc: 0.5294\n",
      "Epoch 4/12\n",
      "16250/16250 [==============================] - 3s 192us/step - loss: 0.6881 - acc: 0.5287\n",
      "Epoch 5/12\n",
      "16250/16250 [==============================] - 3s 191us/step - loss: 0.6879 - acc: 0.5297\n",
      "Epoch 6/12\n",
      "16250/16250 [==============================] - 3s 205us/step - loss: 0.6877 - acc: 0.5382\n",
      "Epoch 7/12\n",
      "16250/16250 [==============================] - 3s 193us/step - loss: 0.6880 - acc: 0.5335\n",
      "Epoch 8/12\n",
      "16250/16250 [==============================] - 3s 199us/step - loss: 0.6878 - acc: 0.5351\n",
      "Epoch 9/12\n",
      "16250/16250 [==============================] - 3s 189us/step - loss: 0.6877 - acc: 0.5359\n",
      "Epoch 10/12\n",
      "16250/16250 [==============================] - 3s 191us/step - loss: 0.6875 - acc: 0.5386\n",
      "Epoch 11/12\n",
      "16250/16250 [==============================] - 3s 193us/step - loss: 0.6875 - acc: 0.5407\n",
      "Epoch 12/12\n",
      "16250/16250 [==============================] - 3s 191us/step - loss: 0.6875 - acc: 0.5401\n",
      "1805/1805 [==============================] - 1s 377us/step\n",
      "16250/16250 [==============================] - 2s 117us/step\n",
      "Epoch 1/12\n",
      "16250/16250 [==============================] - 4s 266us/step - loss: 0.6901 - acc: 0.5224\n",
      "Epoch 2/12\n",
      "16250/16250 [==============================] - 3s 193us/step - loss: 0.6885 - acc: 0.5306\n",
      "Epoch 3/12\n",
      "16250/16250 [==============================] - 3s 193us/step - loss: 0.6880 - acc: 0.5321\n",
      "Epoch 4/12\n",
      "16250/16250 [==============================] - 3s 192us/step - loss: 0.6877 - acc: 0.5346\n",
      "Epoch 5/12\n",
      "16250/16250 [==============================] - 3s 193us/step - loss: 0.6879 - acc: 0.5376\n",
      "Epoch 6/12\n",
      "16250/16250 [==============================] - 3s 192us/step - loss: 0.6874 - acc: 0.5375\n",
      "Epoch 7/12\n",
      "16250/16250 [==============================] - 3s 191us/step - loss: 0.6875 - acc: 0.5387\n",
      "Epoch 8/12\n",
      "16250/16250 [==============================] - 3s 191us/step - loss: 0.6872 - acc: 0.5415\n",
      "Epoch 9/12\n",
      "16250/16250 [==============================] - 3s 192us/step - loss: 0.6869 - acc: 0.5423\n",
      "Epoch 10/12\n",
      "16250/16250 [==============================] - 3s 193us/step - loss: 0.6871 - acc: 0.5429\n",
      "Epoch 11/12\n",
      "16250/16250 [==============================] - 3s 192us/step - loss: 0.6873 - acc: 0.5403\n",
      "Epoch 12/12\n",
      "16250/16250 [==============================] - 3s 193us/step - loss: 0.6871 - acc: 0.5432\n",
      "1805/1805 [==============================] - 1s 384us/step\n",
      "16250/16250 [==============================] - 2s 116us/step\n",
      "Epoch 1/12\n",
      "16250/16250 [==============================] - 4s 269us/step - loss: 0.6901 - acc: 0.5193\n",
      "Epoch 2/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16250/16250 [==============================] - 3s 190us/step - loss: 0.6886 - acc: 0.5338\n",
      "Epoch 3/12\n",
      "16250/16250 [==============================] - 3s 190us/step - loss: 0.6881 - acc: 0.5369\n",
      "Epoch 4/12\n",
      "16250/16250 [==============================] - 3s 188us/step - loss: 0.6877 - acc: 0.5350\n",
      "Epoch 5/12\n",
      "16250/16250 [==============================] - 3s 191us/step - loss: 0.6880 - acc: 0.5350\n",
      "Epoch 6/12\n",
      "16250/16250 [==============================] - 3s 190us/step - loss: 0.6878 - acc: 0.5359\n",
      "Epoch 7/12\n",
      "16250/16250 [==============================] - 3s 190us/step - loss: 0.6877 - acc: 0.5319\n",
      "Epoch 8/12\n",
      "16250/16250 [==============================] - 3s 189us/step - loss: 0.6875 - acc: 0.5390\n",
      "Epoch 9/12\n",
      "16250/16250 [==============================] - 3s 190us/step - loss: 0.6876 - acc: 0.5386\n",
      "Epoch 10/12\n",
      "16250/16250 [==============================] - 3s 191us/step - loss: 0.6876 - acc: 0.5417\n",
      "Epoch 11/12\n",
      "16250/16250 [==============================] - 3s 193us/step - loss: 0.6877 - acc: 0.5373\n",
      "Epoch 12/12\n",
      "16250/16250 [==============================] - 3s 195us/step - loss: 0.6875 - acc: 0.5386\n",
      "1805/1805 [==============================] - 1s 393us/step\n",
      "16250/16250 [==============================] - 2s 118us/step\n",
      "Epoch 1/8\n",
      "16249/16249 [==============================] - 4s 230us/step - loss: 0.6902 - acc: 0.5221\n",
      "Epoch 2/8\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6884 - acc: 0.5269\n",
      "Epoch 3/8\n",
      "16249/16249 [==============================] - 3s 162us/step - loss: 0.6880 - acc: 0.5323\n",
      "Epoch 4/8\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6875 - acc: 0.5378\n",
      "Epoch 5/8\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6876 - acc: 0.5385\n",
      "Epoch 6/8\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6875 - acc: 0.5348\n",
      "Epoch 7/8\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6876 - acc: 0.5350\n",
      "Epoch 8/8\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6874 - acc: 0.5382\n",
      "1806/1806 [==============================] - 1s 380us/step\n",
      "16249/16249 [==============================] - 2s 95us/step\n",
      "Epoch 1/8\n",
      "16249/16249 [==============================] - 4s 233us/step - loss: 0.6899 - acc: 0.5190\n",
      "Epoch 2/8\n",
      "16249/16249 [==============================] - 2s 154us/step - loss: 0.6887 - acc: 0.5304\n",
      "Epoch 3/8\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6886 - acc: 0.5293\n",
      "Epoch 4/8\n",
      "16249/16249 [==============================] - 3s 164us/step - loss: 0.6885 - acc: 0.5306\n",
      "Epoch 5/8\n",
      "16249/16249 [==============================] - 2s 154us/step - loss: 0.6884 - acc: 0.5328\n",
      "Epoch 6/8\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6883 - acc: 0.5352\n",
      "Epoch 7/8\n",
      "16249/16249 [==============================] - 3s 158us/step - loss: 0.6882 - acc: 0.5357\n",
      "Epoch 8/8\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6880 - acc: 0.5324\n",
      "1806/1806 [==============================] - 1s 393us/step\n",
      "16249/16249 [==============================] - 2s 94us/step\n",
      "Epoch 1/8\n",
      "16249/16249 [==============================] - 4s 235us/step - loss: 0.6906 - acc: 0.5168\n",
      "Epoch 2/8\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6891 - acc: 0.5254\n",
      "Epoch 3/8\n",
      "16249/16249 [==============================] - 3s 157us/step - loss: 0.6884 - acc: 0.5309\n",
      "Epoch 4/8\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6879 - acc: 0.5333\n",
      "Epoch 5/8\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6880 - acc: 0.5415\n",
      "Epoch 6/8\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6877 - acc: 0.5372\n",
      "Epoch 7/8\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6876 - acc: 0.5385\n",
      "Epoch 8/8\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6876 - acc: 0.5395\n",
      "1806/1806 [==============================] - 1s 389us/step\n",
      "16249/16249 [==============================] - 2s 93us/step\n",
      "Epoch 1/8\n",
      "16249/16249 [==============================] - 4s 239us/step - loss: 0.6905 - acc: 0.5200\n",
      "Epoch 2/8\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6884 - acc: 0.5332\n",
      "Epoch 3/8\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6881 - acc: 0.5326\n",
      "Epoch 4/8\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6880 - acc: 0.5339\n",
      "Epoch 5/8\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6879 - acc: 0.5344\n",
      "Epoch 6/8\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6879 - acc: 0.5373\n",
      "Epoch 7/8\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6879 - acc: 0.5373\n",
      "Epoch 8/8\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6877 - acc: 0.5347\n",
      "1806/1806 [==============================] - 1s 392us/step\n",
      "16249/16249 [==============================] - 2s 94us/step\n",
      "Epoch 1/8\n",
      "16249/16249 [==============================] - 4s 239us/step - loss: 0.6912 - acc: 0.5102\n",
      "Epoch 2/8\n",
      "16249/16249 [==============================] - 3s 158us/step - loss: 0.6894 - acc: 0.5233\n",
      "Epoch 3/8\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6887 - acc: 0.5307\n",
      "Epoch 4/8\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6885 - acc: 0.5314\n",
      "Epoch 5/8\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6881 - acc: 0.5357\n",
      "Epoch 6/8\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6880 - acc: 0.5348\n",
      "Epoch 7/8\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6880 - acc: 0.5352\n",
      "Epoch 8/8\n",
      "16249/16249 [==============================] - 2s 154us/step - loss: 0.6879 - acc: 0.5370\n",
      "1806/1806 [==============================] - 1s 407us/step\n",
      "16249/16249 [==============================] - 2s 97us/step\n",
      "Epoch 1/8\n",
      "16250/16250 [==============================] - 4s 242us/step - loss: 0.6907 - acc: 0.5122\n",
      "Epoch 2/8\n",
      "16250/16250 [==============================] - 3s 157us/step - loss: 0.6889 - acc: 0.5281\n",
      "Epoch 3/8\n",
      "16250/16250 [==============================] - 3s 155us/step - loss: 0.6886 - acc: 0.5286\n",
      "Epoch 4/8\n",
      "16250/16250 [==============================] - 3s 155us/step - loss: 0.6885 - acc: 0.5353\n",
      "Epoch 5/8\n",
      "16250/16250 [==============================] - 3s 157us/step - loss: 0.6882 - acc: 0.5327\n",
      "Epoch 6/8\n",
      "16250/16250 [==============================] - 3s 155us/step - loss: 0.6884 - acc: 0.5332\n",
      "Epoch 7/8\n",
      "16250/16250 [==============================] - 3s 157us/step - loss: 0.6885 - acc: 0.5321\n",
      "Epoch 8/8\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6884 - acc: 0.5324\n",
      "1805/1805 [==============================] - 1s 412us/step\n",
      "16250/16250 [==============================] - 2s 101us/step\n",
      "Epoch 1/8\n",
      "16250/16250 [==============================] - 4s 254us/step - loss: 0.6914 - acc: 0.5096\n",
      "Epoch 2/8\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6893 - acc: 0.5129\n",
      "Epoch 3/8\n",
      "16250/16250 [==============================] - 3s 160us/step - loss: 0.6887 - acc: 0.5247\n",
      "Epoch 4/8\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6886 - acc: 0.5223\n",
      "Epoch 5/8\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6882 - acc: 0.5347\n",
      "Epoch 6/8\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6879 - acc: 0.5369\n",
      "Epoch 7/8\n",
      "16250/16250 [==============================] - 3s 162us/step - loss: 0.6879 - acc: 0.5311\n",
      "Epoch 8/8\n",
      "16250/16250 [==============================] - 3s 157us/step - loss: 0.6877 - acc: 0.5385\n",
      "1805/1805 [==============================] - 1s 425us/step\n",
      "16250/16250 [==============================] - 2s 97us/step\n",
      "Epoch 1/8\n",
      "16250/16250 [==============================] - 4s 250us/step - loss: 0.6908 - acc: 0.5117\n",
      "Epoch 2/8\n",
      "16250/16250 [==============================] - 3s 175us/step - loss: 0.6890 - acc: 0.5274\n",
      "Epoch 3/8\n",
      "16250/16250 [==============================] - 3s 161us/step - loss: 0.6885 - acc: 0.5303\n",
      "Epoch 4/8\n",
      "16250/16250 [==============================] - 3s 160us/step - loss: 0.6881 - acc: 0.5315\n",
      "Epoch 5/8\n",
      "16250/16250 [==============================] - 3s 160us/step - loss: 0.6879 - acc: 0.5354\n",
      "Epoch 6/8\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6879 - acc: 0.5356\n",
      "Epoch 7/8\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6880 - acc: 0.5366\n",
      "Epoch 8/8\n",
      "16250/16250 [==============================] - 3s 160us/step - loss: 0.6879 - acc: 0.5337\n",
      "1805/1805 [==============================] - 1s 427us/step\n",
      "16250/16250 [==============================] - 2s 98us/step\n",
      "Epoch 1/8\n",
      "16250/16250 [==============================] - 4s 253us/step - loss: 0.6903 - acc: 0.5196\n",
      "Epoch 2/8\n",
      "16250/16250 [==============================] - 3s 163us/step - loss: 0.6883 - acc: 0.5339\n",
      "Epoch 3/8\n",
      "16250/16250 [==============================] - 3s 157us/step - loss: 0.6876 - acc: 0.5398\n",
      "Epoch 4/8\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6876 - acc: 0.5394\n",
      "Epoch 5/8\n",
      "16250/16250 [==============================] - 3s 163us/step - loss: 0.6872 - acc: 0.5423\n",
      "Epoch 6/8\n",
      "16250/16250 [==============================] - 3s 160us/step - loss: 0.6872 - acc: 0.5378\n",
      "Epoch 7/8\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6873 - acc: 0.5425\n",
      "Epoch 8/8\n",
      "16250/16250 [==============================] - 3s 160us/step - loss: 0.6873 - acc: 0.5402\n",
      "1805/1805 [==============================] - 1s 447us/step\n",
      "16250/16250 [==============================] - 2s 99us/step\n",
      "Epoch 1/8\n",
      "16250/16250 [==============================] - 4s 258us/step - loss: 0.6906 - acc: 0.5096\n",
      "Epoch 2/8\n",
      "16250/16250 [==============================] - 3s 162us/step - loss: 0.6890 - acc: 0.5250\n",
      "Epoch 3/8\n",
      "16250/16250 [==============================] - 3s 182us/step - loss: 0.6882 - acc: 0.5334\n",
      "Epoch 4/8\n",
      "16250/16250 [==============================] - 3s 189us/step - loss: 0.6877 - acc: 0.5351\n",
      "Epoch 5/8\n",
      "16250/16250 [==============================] - 3s 188us/step - loss: 0.6877 - acc: 0.5348\n",
      "Epoch 6/8\n",
      "16250/16250 [==============================] - 3s 192us/step - loss: 0.6879 - acc: 0.5351\n",
      "Epoch 7/8\n",
      "16250/16250 [==============================] - 3s 191us/step - loss: 0.6876 - acc: 0.5399\n",
      "Epoch 8/8\n",
      "16250/16250 [==============================] - 3s 188us/step - loss: 0.6878 - acc: 0.5370\n",
      "1805/1805 [==============================] - 1s 489us/step\n",
      "16250/16250 [==============================] - 2s 117us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 5s 289us/step - loss: 0.6897 - acc: 0.5198\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 3s 190us/step - loss: 0.6882 - acc: 0.5283\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 3s 193us/step - loss: 0.6879 - acc: 0.5298\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 3s 193us/step - loss: 0.6881 - acc: 0.5312\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 3s 199us/step - loss: 0.6878 - acc: 0.5342\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 3s 193us/step - loss: 0.6880 - acc: 0.5313\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 3s 195us/step - loss: 0.6878 - acc: 0.5325\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 3s 192us/step - loss: 0.6879 - acc: 0.5339\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 3s 192us/step - loss: 0.6878 - acc: 0.5324\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 3s 192us/step - loss: 0.6879 - acc: 0.5360\n",
      "1806/1806 [==============================] - 1s 499us/step\n",
      "16249/16249 [==============================] - 2s 122us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 5s 292us/step - loss: 0.6907 - acc: 0.5158\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 3s 199us/step - loss: 0.6886 - acc: 0.5296\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 3s 196us/step - loss: 0.6887 - acc: 0.5304\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 3s 195us/step - loss: 0.6884 - acc: 0.5347\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 3s 193us/step - loss: 0.6887 - acc: 0.5307\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 3s 192us/step - loss: 0.6886 - acc: 0.5295\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 3s 193us/step - loss: 0.6886 - acc: 0.5333\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 3s 194us/step - loss: 0.6884 - acc: 0.5328\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 3s 192us/step - loss: 0.6886 - acc: 0.5288\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 3s 194us/step - loss: 0.6883 - acc: 0.5321\n",
      "1806/1806 [==============================] - 1s 490us/step\n",
      "16249/16249 [==============================] - 2s 123us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 5s 302us/step - loss: 0.6901 - acc: 0.5181\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 3s 198us/step - loss: 0.6888 - acc: 0.5298\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 3s 196us/step - loss: 0.6883 - acc: 0.5314\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 3s 206us/step - loss: 0.6883 - acc: 0.5366\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 3s 195us/step - loss: 0.6882 - acc: 0.5370\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 3s 199us/step - loss: 0.6883 - acc: 0.5329\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 3s 197us/step - loss: 0.6882 - acc: 0.5346\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 3s 197us/step - loss: 0.6882 - acc: 0.5369\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 3s 197us/step - loss: 0.6882 - acc: 0.5390\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 3s 197us/step - loss: 0.6881 - acc: 0.5354\n",
      "1806/1806 [==============================] - 1s 505us/step\n",
      "16249/16249 [==============================] - 2s 122us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 5s 300us/step - loss: 0.6903 - acc: 0.5152\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 3s 197us/step - loss: 0.6885 - acc: 0.5307\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 3s 197us/step - loss: 0.6877 - acc: 0.5365\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 3s 197us/step - loss: 0.6874 - acc: 0.5376\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 3s 193us/step - loss: 0.6871 - acc: 0.5413\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 3s 169us/step - loss: 0.6870 - acc: 0.5399\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 3s 161us/step - loss: 0.6871 - acc: 0.5400\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 3s 162us/step - loss: 0.6872 - acc: 0.5414\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 3s 161us/step - loss: 0.6870 - acc: 0.5396\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 3s 162us/step - loss: 0.6872 - acc: 0.5395\n",
      "1806/1806 [==============================] - 1s 469us/step\n",
      "16249/16249 [==============================] - 2s 101us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 4s 275us/step - loss: 0.6906 - acc: 0.5149\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 3s 168us/step - loss: 0.6888 - acc: 0.5288\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 3s 170us/step - loss: 0.6883 - acc: 0.5332\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 3s 169us/step - loss: 0.6883 - acc: 0.5360\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 3s 169us/step - loss: 0.6875 - acc: 0.5371\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 3s 166us/step - loss: 0.6876 - acc: 0.5387\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 3s 165us/step - loss: 0.6879 - acc: 0.5362\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 3s 164us/step - loss: 0.6876 - acc: 0.5374\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 3s 164us/step - loss: 0.6875 - acc: 0.5392\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 3s 165us/step - loss: 0.6878 - acc: 0.5408\n",
      "1806/1806 [==============================] - 1s 480us/step\n",
      "16249/16249 [==============================] - 2s 102us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 4s 267us/step - loss: 0.6902 - acc: 0.5149\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 3s 168us/step - loss: 0.6887 - acc: 0.5288\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16250/16250 [==============================] - 3s 167us/step - loss: 0.6887 - acc: 0.5293\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 3s 166us/step - loss: 0.6886 - acc: 0.5305\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 3s 166us/step - loss: 0.6884 - acc: 0.5325\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 3s 167us/step - loss: 0.6885 - acc: 0.5327\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 3s 165us/step - loss: 0.6883 - acc: 0.5338\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 3s 177us/step - loss: 0.6883 - acc: 0.5330\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 3s 182us/step - loss: 0.6883 - acc: 0.5351\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 2s 153us/step - loss: 0.6884 - acc: 0.5340\n",
      "1805/1805 [==============================] - 1s 485us/step\n",
      "16250/16250 [==============================] - 2s 95us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 4s 255us/step - loss: 0.6907 - acc: 0.5158\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6890 - acc: 0.5258\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6885 - acc: 0.5273\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 2s 151us/step - loss: 0.6880 - acc: 0.5359\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 2s 153us/step - loss: 0.6877 - acc: 0.5356\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 2s 151us/step - loss: 0.6877 - acc: 0.5369\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6876 - acc: 0.5391\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6875 - acc: 0.5397\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 2s 151us/step - loss: 0.6875 - acc: 0.5374\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 2s 151us/step - loss: 0.6873 - acc: 0.5384\n",
      "1805/1805 [==============================] - 1s 479us/step\n",
      "16250/16250 [==============================] - 2s 96us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 4s 255us/step - loss: 0.6905 - acc: 0.5108\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6885 - acc: 0.5286\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6883 - acc: 0.5326\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 3s 156us/step - loss: 0.6883 - acc: 0.5308\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6881 - acc: 0.5334\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 3s 157us/step - loss: 0.6881 - acc: 0.5326\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 2s 153us/step - loss: 0.6882 - acc: 0.5318\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6881 - acc: 0.5316\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6882 - acc: 0.5346\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6880 - acc: 0.5334\n",
      "1805/1805 [==============================] - 1s 483us/step\n",
      "16250/16250 [==============================] - 2s 96us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 4s 272us/step - loss: 0.6903 - acc: 0.5106 2s -\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 3s 171us/step - loss: 0.6883 - acc: 0.5348\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 2s 153us/step - loss: 0.6874 - acc: 0.5380\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6873 - acc: 0.5418\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 3s 155us/step - loss: 0.6874 - acc: 0.5387\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 3s 155us/step - loss: 0.6873 - acc: 0.5412\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6872 - acc: 0.5392\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6872 - acc: 0.5402\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6871 - acc: 0.5433\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6870 - acc: 0.5427\n",
      "1805/1805 [==============================] - 1s 491us/step\n",
      "16250/16250 [==============================] - 2s 98us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 4s 259us/step - loss: 0.6913 - acc: 0.5108\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 2s 153us/step - loss: 0.6891 - acc: 0.5251\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 2s 153us/step - loss: 0.6884 - acc: 0.5301\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6882 - acc: 0.5311\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 2s 153us/step - loss: 0.6882 - acc: 0.5338\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6882 - acc: 0.5324\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 2s 153us/step - loss: 0.6883 - acc: 0.5350\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 2s 153us/step - loss: 0.6882 - acc: 0.5329\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 2s 153us/step - loss: 0.6882 - acc: 0.5366\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 2s 153us/step - loss: 0.6881 - acc: 0.5362\n",
      "1805/1805 [==============================] - 1s 496us/step\n",
      "16250/16250 [==============================] - 2s 98us/step\n",
      "Epoch 1/12\n",
      "16249/16249 [==============================] - 4s 261us/step - loss: 0.6899 - acc: 0.5174\n",
      "Epoch 2/12\n",
      "16249/16249 [==============================] - 2s 154us/step - loss: 0.6882 - acc: 0.5299\n",
      "Epoch 3/12\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6882 - acc: 0.5309\n",
      "Epoch 4/12\n",
      "16249/16249 [==============================] - 2s 154us/step - loss: 0.6879 - acc: 0.5327\n",
      "Epoch 5/12\n",
      "16249/16249 [==============================] - 2s 154us/step - loss: 0.6878 - acc: 0.5374\n",
      "Epoch 6/12\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6875 - acc: 0.5346\n",
      "Epoch 7/12\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6876 - acc: 0.5375\n",
      "Epoch 8/12\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6874 - acc: 0.5381\n",
      "Epoch 9/12\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6872 - acc: 0.5373\n",
      "Epoch 10/12\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6871 - acc: 0.5395\n",
      "Epoch 11/12\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6871 - acc: 0.5400\n",
      "Epoch 12/12\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6873 - acc: 0.5382\n",
      "1806/1806 [==============================] - 1s 506us/step\n",
      "16249/16249 [==============================] - 2s 98us/step\n",
      "Epoch 1/12\n",
      "16249/16249 [==============================] - 4s 264us/step - loss: 0.6908 - acc: 0.5185\n",
      "Epoch 2/12\n",
      "16249/16249 [==============================] - 3s 157us/step - loss: 0.6894 - acc: 0.5186\n",
      "Epoch 3/12\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6891 - acc: 0.5258\n",
      "Epoch 4/12\n",
      "16249/16249 [==============================] - 3s 157us/step - loss: 0.6889 - acc: 0.5276\n",
      "Epoch 5/12\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6886 - acc: 0.5315\n",
      "Epoch 6/12\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6882 - acc: 0.5389\n",
      "Epoch 7/12\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6884 - acc: 0.5332\n",
      "Epoch 8/12\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6879 - acc: 0.5384\n",
      "Epoch 9/12\n",
      "16249/16249 [==============================] - 2s 154us/step - loss: 0.6879 - acc: 0.5374\n",
      "Epoch 10/12\n",
      "16249/16249 [==============================] - 3s 161us/step - loss: 0.6879 - acc: 0.5395\n",
      "Epoch 11/12\n",
      "16249/16249 [==============================] - 3s 157us/step - loss: 0.6880 - acc: 0.5370\n",
      "Epoch 12/12\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6878 - acc: 0.5377\n",
      "1806/1806 [==============================] - 1s 511us/step\n",
      "16249/16249 [==============================] - 2s 98us/step\n",
      "Epoch 1/12\n",
      "16249/16249 [==============================] - 4s 266us/step - loss: 0.6906 - acc: 0.5116\n",
      "Epoch 2/12\n",
      "16249/16249 [==============================] - 3s 157us/step - loss: 0.6893 - acc: 0.5189\n",
      "Epoch 3/12\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6889 - acc: 0.5260\n",
      "Epoch 4/12\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6885 - acc: 0.5301\n",
      "Epoch 5/12\n",
      "16249/16249 [==============================] - 3s 158us/step - loss: 0.6882 - acc: 0.5283\n",
      "Epoch 6/12\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6882 - acc: 0.5362\n",
      "Epoch 7/12\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6879 - acc: 0.5392\n",
      "Epoch 8/12\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6880 - acc: 0.5347\n",
      "Epoch 9/12\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6878 - acc: 0.5368\n",
      "Epoch 10/12\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6876 - acc: 0.5404\n",
      "Epoch 11/12\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6880 - acc: 0.5365\n",
      "Epoch 12/12\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6878 - acc: 0.5363\n",
      "1806/1806 [==============================] - 1s 522us/step\n",
      "16249/16249 [==============================] - 2s 98us/step\n",
      "Epoch 1/12\n",
      "16249/16249 [==============================] - 4s 269us/step - loss: 0.6896 - acc: 0.5189\n",
      "Epoch 2/12\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6883 - acc: 0.5298\n",
      "Epoch 3/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6882 - acc: 0.5316\n",
      "Epoch 4/12\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6877 - acc: 0.5364\n",
      "Epoch 5/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6877 - acc: 0.5394\n",
      "Epoch 6/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6874 - acc: 0.5395\n",
      "Epoch 7/12\n",
      "16249/16249 [==============================] - 3s 157us/step - loss: 0.6872 - acc: 0.5397\n",
      "Epoch 8/12\n",
      "16249/16249 [==============================] - 3s 157us/step - loss: 0.6873 - acc: 0.5389\n",
      "Epoch 9/12\n",
      "16249/16249 [==============================] - 3s 158us/step - loss: 0.6872 - acc: 0.5390\n",
      "Epoch 10/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6872 - acc: 0.5425\n",
      "Epoch 11/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6873 - acc: 0.5408\n",
      "Epoch 12/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6872 - acc: 0.5405\n",
      "1806/1806 [==============================] - 1s 530us/step\n",
      "16249/16249 [==============================] - 2s 99us/step\n",
      "Epoch 1/12\n",
      "16249/16249 [==============================] - 4s 270us/step - loss: 0.6912 - acc: 0.5108\n",
      "Epoch 2/12\n",
      "16249/16249 [==============================] - 3s 157us/step - loss: 0.6894 - acc: 0.5176\n",
      "Epoch 3/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6886 - acc: 0.5324\n",
      "Epoch 4/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6884 - acc: 0.5356\n",
      "Epoch 5/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6882 - acc: 0.5362\n",
      "Epoch 6/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6881 - acc: 0.5388\n",
      "Epoch 7/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6880 - acc: 0.5390\n",
      "Epoch 8/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6877 - acc: 0.5390\n",
      "Epoch 9/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6880 - acc: 0.5372\n",
      "Epoch 10/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6877 - acc: 0.5407\n",
      "Epoch 11/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6876 - acc: 0.5381\n",
      "Epoch 12/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6874 - acc: 0.5406\n",
      "1806/1806 [==============================] - 1s 533us/step\n",
      "16249/16249 [==============================] - 2s 100us/step\n",
      "Epoch 1/12\n",
      "16250/16250 [==============================] - 4s 275us/step - loss: 0.6902 - acc: 0.5110\n",
      "Epoch 2/12\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6888 - acc: 0.5274\n",
      "Epoch 3/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6886 - acc: 0.5332\n",
      "Epoch 4/12\n",
      "16250/16250 [==============================] - 3s 157us/step - loss: 0.6883 - acc: 0.5324\n",
      "Epoch 5/12\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6885 - acc: 0.5318\n",
      "Epoch 6/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6882 - acc: 0.5329\n",
      "Epoch 7/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6883 - acc: 0.5337\n",
      "Epoch 8/12\n",
      "16250/16250 [==============================] - 3s 157us/step - loss: 0.6881 - acc: 0.5353\n",
      "Epoch 9/12\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6881 - acc: 0.5334\n",
      "Epoch 10/12\n",
      "16250/16250 [==============================] - 3s 157us/step - loss: 0.6881 - acc: 0.5334\n",
      "Epoch 11/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6884 - acc: 0.5318\n",
      "Epoch 12/12\n",
      "16250/16250 [==============================] - 3s 157us/step - loss: 0.6883 - acc: 0.5326\n",
      "1805/1805 [==============================] - 1s 545us/step\n",
      "16250/16250 [==============================] - 2s 100us/step\n",
      "Epoch 1/12\n",
      "16250/16250 [==============================] - 4s 275us/step - loss: 0.6905 - acc: 0.5151\n",
      "Epoch 2/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6888 - acc: 0.5263\n",
      "Epoch 3/12\n",
      "16250/16250 [==============================] - 3s 172us/step - loss: 0.6885 - acc: 0.5289\n",
      "Epoch 4/12\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6881 - acc: 0.5298\n",
      "Epoch 5/12\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6877 - acc: 0.5354\n",
      "Epoch 6/12\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6876 - acc: 0.5372\n",
      "Epoch 7/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6876 - acc: 0.5383\n",
      "Epoch 8/12\n",
      "16250/16250 [==============================] - 3s 157us/step - loss: 0.6875 - acc: 0.5403\n",
      "Epoch 9/12\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6873 - acc: 0.5383\n",
      "Epoch 10/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6874 - acc: 0.5406\n",
      "Epoch 11/12\n",
      "16250/16250 [==============================] - 3s 161us/step - loss: 0.6872 - acc: 0.5419\n",
      "Epoch 12/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6872 - acc: 0.5376\n",
      "1805/1805 [==============================] - 1s 550us/step\n",
      "16250/16250 [==============================] - 2s 100us/step\n",
      "Epoch 1/12\n",
      "16250/16250 [==============================] - 5s 290us/step - loss: 0.6898 - acc: 0.5155\n",
      "Epoch 2/12\n",
      "16250/16250 [==============================] - 3s 162us/step - loss: 0.6883 - acc: 0.5335\n",
      "Epoch 3/12\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6880 - acc: 0.5358\n",
      "Epoch 4/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6876 - acc: 0.5385\n",
      "Epoch 5/12\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6877 - acc: 0.5332\n",
      "Epoch 6/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6873 - acc: 0.5343\n",
      "Epoch 7/12\n",
      "16250/16250 [==============================] - 3s 160us/step - loss: 0.6877 - acc: 0.5371\n",
      "Epoch 8/12\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6876 - acc: 0.5372\n",
      "Epoch 9/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6875 - acc: 0.5398\n",
      "Epoch 10/12\n",
      "16250/16250 [==============================] - 3s 160us/step - loss: 0.6875 - acc: 0.5389\n",
      "Epoch 11/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6872 - acc: 0.5380\n",
      "Epoch 12/12\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6875 - acc: 0.5381\n",
      "1805/1805 [==============================] - 1s 554us/step\n",
      "16250/16250 [==============================] - 2s 101us/step\n",
      "Epoch 1/12\n",
      "16250/16250 [==============================] - 5s 279us/step - loss: 0.6899 - acc: 0.5206\n",
      "Epoch 2/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6884 - acc: 0.5302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6880 - acc: 0.5309\n",
      "Epoch 4/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6877 - acc: 0.5361\n",
      "Epoch 5/12\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6879 - acc: 0.5351\n",
      "Epoch 6/12\n",
      "16250/16250 [==============================] - 3s 160us/step - loss: 0.6876 - acc: 0.5358\n",
      "Epoch 7/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6877 - acc: 0.5345\n",
      "Epoch 8/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6877 - acc: 0.5356\n",
      "Epoch 9/12\n",
      "16250/16250 [==============================] - 3s 170us/step - loss: 0.6878 - acc: 0.5354\n",
      "Epoch 10/12\n",
      "16250/16250 [==============================] - 3s 187us/step - loss: 0.6877 - acc: 0.5394\n",
      "Epoch 11/12\n",
      "16250/16250 [==============================] - 3s 174us/step - loss: 0.6877 - acc: 0.5346\n",
      "Epoch 12/12\n",
      "16250/16250 [==============================] - 3s 188us/step - loss: 0.6876 - acc: 0.5372\n",
      "1805/1805 [==============================] - 1s 629us/step\n",
      "16250/16250 [==============================] - 2s 109us/step\n",
      "Epoch 1/12\n",
      "16250/16250 [==============================] - 5s 301us/step - loss: 0.6906 - acc: 0.5151\n",
      "Epoch 2/12\n",
      "16250/16250 [==============================] - 3s 170us/step - loss: 0.6888 - acc: 0.5269\n",
      "Epoch 3/12\n",
      "16250/16250 [==============================] - 3s 165us/step - loss: 0.6880 - acc: 0.5329\n",
      "Epoch 4/12\n",
      "16250/16250 [==============================] - 3s 178us/step - loss: 0.6882 - acc: 0.5353\n",
      "Epoch 5/12\n",
      "16250/16250 [==============================] - 3s 168us/step - loss: 0.6878 - acc: 0.5370\n",
      "Epoch 6/12\n",
      "16250/16250 [==============================] - 3s 168us/step - loss: 0.6876 - acc: 0.5367\n",
      "Epoch 7/12\n",
      "16250/16250 [==============================] - 3s 165us/step - loss: 0.6876 - acc: 0.5370\n",
      "Epoch 8/12\n",
      "16250/16250 [==============================] - 3s 168us/step - loss: 0.6876 - acc: 0.5378\n",
      "Epoch 9/12\n",
      "16250/16250 [==============================] - 3s 162us/step - loss: 0.6875 - acc: 0.5370\n",
      "Epoch 10/12\n",
      "16250/16250 [==============================] - 3s 163us/step - loss: 0.6876 - acc: 0.5407\n",
      "Epoch 11/12\n",
      "16250/16250 [==============================] - 3s 161us/step - loss: 0.6876 - acc: 0.5395\n",
      "Epoch 12/12\n",
      "16250/16250 [==============================] - 3s 161us/step - loss: 0.6873 - acc: 0.5413\n",
      "1805/1805 [==============================] - 1s 587us/step\n",
      "16250/16250 [==============================] - 2s 103us/step\n",
      "Epoch 1/8\n",
      "16249/16249 [==============================] - 4s 267us/step - loss: 0.6893 - acc: 0.5202\n",
      "Epoch 2/8\n",
      "16249/16249 [==============================] - 2s 135us/step - loss: 0.6884 - acc: 0.5328\n",
      "Epoch 3/8\n",
      "16249/16249 [==============================] - 2s 136us/step - loss: 0.6882 - acc: 0.5327\n",
      "Epoch 4/8\n",
      "16249/16249 [==============================] - 2s 138us/step - loss: 0.6878 - acc: 0.5332\n",
      "Epoch 5/8\n",
      "16249/16249 [==============================] - 2s 139us/step - loss: 0.6878 - acc: 0.5320\n",
      "Epoch 6/8\n",
      "16249/16249 [==============================] - 2s 140us/step - loss: 0.6880 - acc: 0.5338\n",
      "Epoch 7/8\n",
      "16249/16249 [==============================] - 2s 139us/step - loss: 0.6878 - acc: 0.5365\n",
      "Epoch 8/8\n",
      "16249/16249 [==============================] - 2s 136us/step - loss: 0.6878 - acc: 0.5346\n",
      "1806/1806 [==============================] - 1s 595us/step\n",
      "16249/16249 [==============================] - 1s 89us/step\n",
      "Epoch 1/8\n",
      "16249/16249 [==============================] - 4s 264us/step - loss: 0.6912 - acc: 0.5106\n",
      "Epoch 2/8\n",
      "16249/16249 [==============================] - 2s 137us/step - loss: 0.6890 - acc: 0.5237\n",
      "Epoch 3/8\n",
      "16249/16249 [==============================] - 2s 136us/step - loss: 0.6882 - acc: 0.5307\n",
      "Epoch 4/8\n",
      "16249/16249 [==============================] - 2s 136us/step - loss: 0.6883 - acc: 0.5365\n",
      "Epoch 5/8\n",
      "16249/16249 [==============================] - 2s 136us/step - loss: 0.6880 - acc: 0.5374\n",
      "Epoch 6/8\n",
      "16249/16249 [==============================] - 2s 136us/step - loss: 0.6880 - acc: 0.5402\n",
      "Epoch 7/8\n",
      "16249/16249 [==============================] - 2s 139us/step - loss: 0.6879 - acc: 0.5352\n",
      "Epoch 8/8\n",
      "16249/16249 [==============================] - 2s 137us/step - loss: 0.6878 - acc: 0.5375\n",
      "1806/1806 [==============================] - 1s 578us/step\n",
      "16249/16249 [==============================] - 1s 90us/step\n",
      "Epoch 1/8\n",
      "16249/16249 [==============================] - 4s 277us/step - loss: 0.6903 - acc: 0.5129\n",
      "Epoch 2/8\n",
      "16249/16249 [==============================] - 2s 142us/step - loss: 0.6887 - acc: 0.5282\n",
      "Epoch 3/8\n",
      "16249/16249 [==============================] - 2s 150us/step - loss: 0.6880 - acc: 0.5374\n",
      "Epoch 4/8\n",
      "16249/16249 [==============================] - 2s 146us/step - loss: 0.6878 - acc: 0.5385\n",
      "Epoch 5/8\n",
      "16249/16249 [==============================] - 2s 152us/step - loss: 0.6877 - acc: 0.5382\n",
      "Epoch 6/8\n",
      "16249/16249 [==============================] - 2s 138us/step - loss: 0.6876 - acc: 0.5395\n",
      "Epoch 7/8\n",
      "16249/16249 [==============================] - 2s 137us/step - loss: 0.6875 - acc: 0.5395\n",
      "Epoch 8/8\n",
      "16249/16249 [==============================] - 2s 139us/step - loss: 0.6875 - acc: 0.5394\n",
      "1806/1806 [==============================] - 1s 593us/step\n",
      "16249/16249 [==============================] - 1s 88us/step\n",
      "Epoch 1/8\n",
      "16249/16249 [==============================] - 4s 270us/step - loss: 0.6902 - acc: 0.5139\n",
      "Epoch 2/8\n",
      "16249/16249 [==============================] - 2s 137us/step - loss: 0.6883 - acc: 0.5295\n",
      "Epoch 3/8\n",
      "16249/16249 [==============================] - 2s 139us/step - loss: 0.6881 - acc: 0.5330\n",
      "Epoch 4/8\n",
      "16249/16249 [==============================] - 2s 142us/step - loss: 0.6876 - acc: 0.5389\n",
      "Epoch 5/8\n",
      "16249/16249 [==============================] - 2s 145us/step - loss: 0.6872 - acc: 0.5428\n",
      "Epoch 6/8\n",
      "16249/16249 [==============================] - 2s 148us/step - loss: 0.6873 - acc: 0.5422\n",
      "Epoch 7/8\n",
      "16249/16249 [==============================] - 2s 141us/step - loss: 0.6872 - acc: 0.5411\n",
      "Epoch 8/8\n",
      "16249/16249 [==============================] - 3s 169us/step - loss: 0.6874 - acc: 0.5370\n",
      "1806/1806 [==============================] - 1s 633us/step\n",
      "16249/16249 [==============================] - 2s 96us/step\n",
      "Epoch 1/8\n",
      "16249/16249 [==============================] - 5s 303us/step - loss: 0.6901 - acc: 0.5182\n",
      "Epoch 2/8\n",
      "16249/16249 [==============================] - 2s 142us/step - loss: 0.6887 - acc: 0.5343\n",
      "Epoch 3/8\n",
      "16249/16249 [==============================] - 2s 139us/step - loss: 0.6881 - acc: 0.5370\n",
      "Epoch 4/8\n",
      "16249/16249 [==============================] - 2s 141us/step - loss: 0.6881 - acc: 0.5347\n",
      "Epoch 5/8\n",
      "16249/16249 [==============================] - 2s 149us/step - loss: 0.6879 - acc: 0.5357\n",
      "Epoch 6/8\n",
      "16249/16249 [==============================] - 2s 143us/step - loss: 0.6877 - acc: 0.5413\n",
      "Epoch 7/8\n",
      "16249/16249 [==============================] - 2s 146us/step - loss: 0.6876 - acc: 0.5407\n",
      "Epoch 8/8\n",
      "16249/16249 [==============================] - 2s 140us/step - loss: 0.6879 - acc: 0.5386\n",
      "1806/1806 [==============================] - 1s 610us/step\n",
      "16249/16249 [==============================] - 1s 90us/step\n",
      "Epoch 1/8\n",
      "16250/16250 [==============================] - 5s 283us/step - loss: 0.6905 - acc: 0.5121\n",
      "Epoch 2/8\n",
      "16250/16250 [==============================] - 2s 138us/step - loss: 0.6889 - acc: 0.5270\n",
      "Epoch 3/8\n",
      "16250/16250 [==============================] - 2s 146us/step - loss: 0.6883 - acc: 0.5336\n",
      "Epoch 4/8\n",
      "16250/16250 [==============================] - 2s 141us/step - loss: 0.6880 - acc: 0.5343\n",
      "Epoch 5/8\n",
      "16250/16250 [==============================] - 2s 144us/step - loss: 0.6881 - acc: 0.5353\n",
      "Epoch 6/8\n",
      "16250/16250 [==============================] - 2s 144us/step - loss: 0.6880 - acc: 0.5401\n",
      "Epoch 7/8\n",
      "16250/16250 [==============================] - 3s 160us/step - loss: 0.6880 - acc: 0.5349\n",
      "Epoch 8/8\n",
      "16250/16250 [==============================] - 2s 139us/step - loss: 0.6878 - acc: 0.5400\n",
      "1805/1805 [==============================] - 1s 695us/step\n",
      "16250/16250 [==============================] - 2s 98us/step\n",
      "Epoch 1/8\n",
      "16250/16250 [==============================] - 5s 285us/step - loss: 0.6906 - acc: 0.5137\n",
      "Epoch 2/8\n",
      "16250/16250 [==============================] - 3s 154us/step - loss: 0.6887 - acc: 0.5262\n",
      "Epoch 3/8\n",
      "16250/16250 [==============================] - 2s 143us/step - loss: 0.6882 - acc: 0.5321\n",
      "Epoch 4/8\n",
      "16250/16250 [==============================] - 2s 140us/step - loss: 0.6881 - acc: 0.5388\n",
      "Epoch 5/8\n",
      "16250/16250 [==============================] - 2s 140us/step - loss: 0.6879 - acc: 0.5370\n",
      "Epoch 6/8\n",
      "16250/16250 [==============================] - 2s 140us/step - loss: 0.6876 - acc: 0.5366\n",
      "Epoch 7/8\n",
      "16250/16250 [==============================] - 2s 139us/step - loss: 0.6873 - acc: 0.5381\n",
      "Epoch 8/8\n",
      "16250/16250 [==============================] - 2s 141us/step - loss: 0.6876 - acc: 0.5404\n",
      "1805/1805 [==============================] - 1s 625us/step\n",
      "16250/16250 [==============================] - 1s 92us/step\n",
      "Epoch 1/8\n",
      "16250/16250 [==============================] - 5s 299us/step - loss: 0.6906 - acc: 0.5190\n",
      "Epoch 2/8\n",
      "16250/16250 [==============================] - 2s 145us/step - loss: 0.6889 - acc: 0.5263\n",
      "Epoch 3/8\n",
      "16250/16250 [==============================] - 2s 140us/step - loss: 0.6883 - acc: 0.5308\n",
      "Epoch 4/8\n",
      "16250/16250 [==============================] - 2s 146us/step - loss: 0.6884 - acc: 0.5298\n",
      "Epoch 5/8\n",
      "16250/16250 [==============================] - 3s 172us/step - loss: 0.6882 - acc: 0.5322\n",
      "Epoch 6/8\n",
      "16250/16250 [==============================] - 2s 146us/step - loss: 0.6881 - acc: 0.5358\n",
      "Epoch 7/8\n",
      "16250/16250 [==============================] - 3s 155us/step - loss: 0.6881 - acc: 0.5313\n",
      "Epoch 8/8\n",
      "16250/16250 [==============================] - 2s 142us/step - loss: 0.6881 - acc: 0.5338\n",
      "1805/1805 [==============================] - 1s 633us/step\n",
      "16250/16250 [==============================] - 1s 91us/step\n",
      "Epoch 1/8\n",
      "16250/16250 [==============================] - 5s 284us/step - loss: 0.6906 - acc: 0.5093\n",
      "Epoch 2/8\n",
      "16250/16250 [==============================] - 2s 145us/step - loss: 0.6883 - acc: 0.5306\n",
      "Epoch 3/8\n",
      "16250/16250 [==============================] - 2s 149us/step - loss: 0.6878 - acc: 0.5369\n",
      "Epoch 4/8\n",
      "16250/16250 [==============================] - 2s 142us/step - loss: 0.6873 - acc: 0.5409\n",
      "Epoch 5/8\n",
      "16250/16250 [==============================] - 2s 141us/step - loss: 0.6875 - acc: 0.5372\n",
      "Epoch 6/8\n",
      "16250/16250 [==============================] - 2s 139us/step - loss: 0.6874 - acc: 0.5401\n",
      "Epoch 7/8\n",
      "16250/16250 [==============================] - 2s 146us/step - loss: 0.6873 - acc: 0.5426\n",
      "Epoch 8/8\n",
      "16250/16250 [==============================] - 2s 141us/step - loss: 0.6870 - acc: 0.5407\n",
      "1805/1805 [==============================] - 1s 645us/step\n",
      "16250/16250 [==============================] - 1s 90us/step\n",
      "Epoch 1/8\n",
      "16250/16250 [==============================] - 5s 284us/step - loss: 0.6905 - acc: 0.5162\n",
      "Epoch 2/8\n",
      "16250/16250 [==============================] - 2s 147us/step - loss: 0.6888 - acc: 0.5297\n",
      "Epoch 3/8\n",
      "16250/16250 [==============================] - 2s 149us/step - loss: 0.6884 - acc: 0.5337\n",
      "Epoch 4/8\n",
      "16250/16250 [==============================] - 2s 144us/step - loss: 0.6880 - acc: 0.5339\n",
      "Epoch 5/8\n",
      "16250/16250 [==============================] - 2s 139us/step - loss: 0.6878 - acc: 0.5366\n",
      "Epoch 6/8\n",
      "16250/16250 [==============================] - 3s 155us/step - loss: 0.6875 - acc: 0.5381\n",
      "Epoch 7/8\n",
      "16250/16250 [==============================] - 3s 165us/step - loss: 0.6876 - acc: 0.5393\n",
      "Epoch 8/8\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6875 - acc: 0.5390\n",
      "1805/1805 [==============================] - 1s 669us/step\n",
      "16250/16250 [==============================] - 2s 96us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 5s 297us/step - loss: 0.6905 - acc: 0.5116\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 2s 150us/step - loss: 0.6884 - acc: 0.5252\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 2s 148us/step - loss: 0.6879 - acc: 0.5324\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 2s 151us/step - loss: 0.6879 - acc: 0.5355\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 2s 150us/step - loss: 0.6879 - acc: 0.5322\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 2s 150us/step - loss: 0.6878 - acc: 0.5320\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 2s 145us/step - loss: 0.6878 - acc: 0.5345\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 2s 145us/step - loss: 0.6877 - acc: 0.5337\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 2s 148us/step - loss: 0.6876 - acc: 0.5374\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 3s 170us/step - loss: 0.6877 - acc: 0.5312\n",
      "1806/1806 [==============================] - 1s 728us/step\n",
      "16249/16249 [==============================] - 1s 92us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 5s 309us/step - loss: 0.6914 - acc: 0.5095\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 3s 161us/step - loss: 0.6894 - acc: 0.5208\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 2s 143us/step - loss: 0.6889 - acc: 0.5282\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 2s 144us/step - loss: 0.6886 - acc: 0.5325\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 3s 170us/step - loss: 0.6885 - acc: 0.5351\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6883 - acc: 0.5326\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6879 - acc: 0.5342\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 2s 152us/step - loss: 0.6878 - acc: 0.5371\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 2s 149us/step - loss: 0.6880 - acc: 0.5384\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 2s 150us/step - loss: 0.6880 - acc: 0.5347\n",
      "1806/1806 [==============================] - 1s 666us/step\n",
      "16249/16249 [==============================] - 2s 103us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 5s 309us/step - loss: 0.6903 - acc: 0.5152\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6886 - acc: 0.5298\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6881 - acc: 0.5360\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 3s 165us/step - loss: 0.6876 - acc: 0.5382\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 3s 164us/step - loss: 0.6877 - acc: 0.5374\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 3s 177us/step - loss: 0.6879 - acc: 0.5398\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 3s 160us/step - loss: 0.6877 - acc: 0.5399\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 3s 160us/step - loss: 0.6876 - acc: 0.5392\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 3s 167us/step - loss: 0.6874 - acc: 0.5381\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 3s 158us/step - loss: 0.6873 - acc: 0.5402\n",
      "1806/1806 [==============================] - 1s 723us/step\n",
      "16249/16249 [==============================] - 2s 97us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 5s 310us/step - loss: 0.6904 - acc: 0.5128\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 3s 158us/step - loss: 0.6886 - acc: 0.5282\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6878 - acc: 0.5329\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6876 - acc: 0.5358\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6878 - acc: 0.5349\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 3s 159us/step - loss: 0.6875 - acc: 0.5379\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 3s 158us/step - loss: 0.6876 - acc: 0.5375\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6873 - acc: 0.5403\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6873 - acc: 0.5378\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 2s 154us/step - loss: 0.6873 - acc: 0.5394\n",
      "1806/1806 [==============================] - 1s 685us/step\n",
      "16249/16249 [==============================] - 2s 101us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 5s 314us/step - loss: 0.6903 - acc: 0.5144\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 2s 150us/step - loss: 0.6890 - acc: 0.5277\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6883 - acc: 0.5367\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 3s 195us/step - loss: 0.6882 - acc: 0.5331\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 2s 145us/step - loss: 0.6879 - acc: 0.5366\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 2s 144us/step - loss: 0.6878 - acc: 0.5405\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 2s 145us/step - loss: 0.6877 - acc: 0.5359\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 3s 165us/step - loss: 0.6878 - acc: 0.5422\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6874 - acc: 0.5395\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 2s 152us/step - loss: 0.6874 - acc: 0.5415\n",
      "1806/1806 [==============================] - 1s 702us/step\n",
      "16249/16249 [==============================] - 2s 98us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 5s 323us/step - loss: 0.6912 - acc: 0.5087\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6890 - acc: 0.5229\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 2s 149us/step - loss: 0.6885 - acc: 0.5313\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 2s 145us/step - loss: 0.6883 - acc: 0.5323\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 2s 150us/step - loss: 0.6882 - acc: 0.5345\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 3s 172us/step - loss: 0.6881 - acc: 0.5317\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 3s 166us/step - loss: 0.6882 - acc: 0.5341\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 2s 145us/step - loss: 0.6878 - acc: 0.5388\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 3s 166us/step - loss: 0.6878 - acc: 0.5374\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 2s 153us/step - loss: 0.6877 - acc: 0.5406\n",
      "1805/1805 [==============================] - 1s 693us/step\n",
      "16250/16250 [==============================] - 2s 99us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 5s 333us/step - loss: 0.6907 - acc: 0.5106\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 2s 153us/step - loss: 0.6888 - acc: 0.5258\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 3s 168us/step - loss: 0.6879 - acc: 0.5346\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 2s 149us/step - loss: 0.6880 - acc: 0.5374\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 2s 154us/step - loss: 0.6877 - acc: 0.5355\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 2s 153us/step - loss: 0.6877 - acc: 0.5377\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 2s 149us/step - loss: 0.6875 - acc: 0.5374\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6875 - acc: 0.5406\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 3s 164us/step - loss: 0.6875 - acc: 0.5376\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 2s 148us/step - loss: 0.6874 - acc: 0.5408\n",
      "1805/1805 [==============================] - 1s 744us/step\n",
      "16250/16250 [==============================] - 2s 108us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 5s 331us/step - loss: 0.6901 - acc: 0.5199\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 2s 150us/step - loss: 0.6888 - acc: 0.5320\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 3s 164us/step - loss: 0.6884 - acc: 0.5313\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 3s 165us/step - loss: 0.6882 - acc: 0.5310\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6881 - acc: 0.5368\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 3s 165us/step - loss: 0.6878 - acc: 0.5356\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 3s 172us/step - loss: 0.6877 - acc: 0.5368\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 3s 164us/step - loss: 0.6873 - acc: 0.5375\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6875 - acc: 0.5393\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 3s 155us/step - loss: 0.6875 - acc: 0.5371\n",
      "1805/1805 [==============================] - 1s 719us/step\n",
      "16250/16250 [==============================] - 2s 99us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 5s 315us/step - loss: 0.6906 - acc: 0.5098\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 2s 147us/step - loss: 0.6882 - acc: 0.5276\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 2s 146us/step - loss: 0.6882 - acc: 0.5321\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 2s 151us/step - loss: 0.6880 - acc: 0.5358\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 3s 155us/step - loss: 0.6876 - acc: 0.5362\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6876 - acc: 0.5362\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 2s 151us/step - loss: 0.6876 - acc: 0.5415\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 3s 155us/step - loss: 0.6871 - acc: 0.5390\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6872 - acc: 0.5414\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 3s 156us/step - loss: 0.6869 - acc: 0.5427\n",
      "1805/1805 [==============================] - 1s 721us/step\n",
      "16250/16250 [==============================] - 2s 104us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 5s 315us/step - loss: 0.6900 - acc: 0.5111\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 3s 160us/step - loss: 0.6884 - acc: 0.5321\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 3s 168us/step - loss: 0.6882 - acc: 0.5343\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 2s 147us/step - loss: 0.6879 - acc: 0.5357\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 2s 147us/step - loss: 0.6879 - acc: 0.5383\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 2s 149us/step - loss: 0.6879 - acc: 0.5370\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6877 - acc: 0.5404\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 3s 172us/step - loss: 0.6877 - acc: 0.5394\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 3s 154us/step - loss: 0.6876 - acc: 0.5403\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 3s 172us/step - loss: 0.6877 - acc: 0.5397\n",
      "1805/1805 [==============================] - 1s 784us/step\n",
      "16250/16250 [==============================] - 2s 128us/step\n",
      "Epoch 1/12\n",
      "16249/16249 [==============================] - 6s 376us/step - loss: 0.6903 - acc: 0.5168\n",
      "Epoch 2/12\n",
      "16249/16249 [==============================] - 3s 191us/step - loss: 0.6885 - acc: 0.5232\n",
      "Epoch 3/12\n",
      "16249/16249 [==============================] - 3s 199us/step - loss: 0.6877 - acc: 0.5315\n",
      "Epoch 4/12\n",
      "16249/16249 [==============================] - 3s 190us/step - loss: 0.6874 - acc: 0.5374\n",
      "Epoch 5/12\n",
      "16249/16249 [==============================] - 4s 221us/step - loss: 0.6874 - acc: 0.5387\n",
      "Epoch 6/12\n",
      "16249/16249 [==============================] - 3s 206us/step - loss: 0.6874 - acc: 0.5371\n",
      "Epoch 7/12\n",
      "16249/16249 [==============================] - 3s 172us/step - loss: 0.6873 - acc: 0.5370\n",
      "Epoch 8/12\n",
      "16249/16249 [==============================] - 3s 199us/step - loss: 0.6873 - acc: 0.5373\n",
      "Epoch 9/12\n",
      "16249/16249 [==============================] - 3s 191us/step - loss: 0.6872 - acc: 0.5423\n",
      "Epoch 10/12\n",
      "16249/16249 [==============================] - 3s 182us/step - loss: 0.6870 - acc: 0.5385\n",
      "Epoch 11/12\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6872 - acc: 0.5388\n",
      "Epoch 12/12\n",
      "16249/16249 [==============================] - 3s 165us/step - loss: 0.6872 - acc: 0.5367\n",
      "1806/1806 [==============================] - 1s 746us/step\n",
      "16249/16249 [==============================] - 2s 102us/step\n",
      "Epoch 1/12\n",
      "16249/16249 [==============================] - 5s 328us/step - loss: 0.6908 - acc: 0.5147\n",
      "Epoch 2/12\n",
      "16249/16249 [==============================] - 3s 158us/step - loss: 0.6893 - acc: 0.5242\n",
      "Epoch 3/12\n",
      "16249/16249 [==============================] - 2s 151us/step - loss: 0.6890 - acc: 0.5267\n",
      "Epoch 4/12\n",
      "16249/16249 [==============================] - 2s 149us/step - loss: 0.6888 - acc: 0.5304\n",
      "Epoch 5/12\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6888 - acc: 0.5309\n",
      "Epoch 6/12\n",
      "16249/16249 [==============================] - 3s 162us/step - loss: 0.6887 - acc: 0.5308\n",
      "Epoch 7/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6884 - acc: 0.5348\n",
      "Epoch 8/12\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6887 - acc: 0.5306\n",
      "Epoch 9/12\n",
      "16249/16249 [==============================] - 3s 157us/step - loss: 0.6883 - acc: 0.5328\n",
      "Epoch 10/12\n",
      "16249/16249 [==============================] - 2s 152us/step - loss: 0.6884 - acc: 0.5337\n",
      "Epoch 11/12\n",
      "16249/16249 [==============================] - 3s 161us/step - loss: 0.6883 - acc: 0.5326\n",
      "Epoch 12/12\n",
      "16249/16249 [==============================] - 3s 159us/step - loss: 0.6884 - acc: 0.5331\n",
      "1806/1806 [==============================] - 1s 776us/step\n",
      "16249/16249 [==============================] - 2s 97us/step\n",
      "Epoch 1/12\n",
      "16249/16249 [==============================] - 5s 319us/step - loss: 0.6898 - acc: 0.5171\n",
      "Epoch 2/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6888 - acc: 0.5315\n",
      "Epoch 3/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6880 - acc: 0.5341\n",
      "Epoch 4/12\n",
      "16249/16249 [==============================] - 3s 157us/step - loss: 0.6880 - acc: 0.5366\n",
      "Epoch 5/12\n",
      "16249/16249 [==============================] - 3s 163us/step - loss: 0.6879 - acc: 0.5406\n",
      "Epoch 6/12\n",
      "16249/16249 [==============================] - 3s 167us/step - loss: 0.6877 - acc: 0.5373\n",
      "Epoch 7/12\n",
      "16249/16249 [==============================] - 3s 158us/step - loss: 0.6879 - acc: 0.5369\n",
      "Epoch 8/12\n",
      "16249/16249 [==============================] - 3s 159us/step - loss: 0.6876 - acc: 0.5396\n",
      "Epoch 9/12\n",
      "16249/16249 [==============================] - 2s 152us/step - loss: 0.6878 - acc: 0.5391\n",
      "Epoch 10/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6877 - acc: 0.5383\n",
      "Epoch 11/12\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6875 - acc: 0.5400\n",
      "Epoch 12/12\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6877 - acc: 0.5400\n",
      "1806/1806 [==============================] - 1s 767us/step\n",
      "16249/16249 [==============================] - 2s 102us/step\n",
      "Epoch 1/12\n",
      "16249/16249 [==============================] - 5s 331us/step - loss: 0.6908 - acc: 0.5129\n",
      "Epoch 2/12\n",
      "16249/16249 [==============================] - 3s 158us/step - loss: 0.6883 - acc: 0.5324\n",
      "Epoch 3/12\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6883 - acc: 0.5307\n",
      "Epoch 4/12\n",
      "16249/16249 [==============================] - 2s 150us/step - loss: 0.6880 - acc: 0.5372\n",
      "Epoch 5/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6881 - acc: 0.5330\n",
      "Epoch 6/12\n",
      "16249/16249 [==============================] - 3s 161us/step - loss: 0.6880 - acc: 0.5332\n",
      "Epoch 7/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6881 - acc: 0.5363\n",
      "Epoch 8/12\n",
      "16249/16249 [==============================] - 3s 157us/step - loss: 0.6879 - acc: 0.5351\n",
      "Epoch 9/12\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6880 - acc: 0.5334\n",
      "Epoch 10/12\n",
      "16249/16249 [==============================] - 3s 155us/step - loss: 0.6877 - acc: 0.5386\n",
      "Epoch 11/12\n",
      "16249/16249 [==============================] - 3s 157us/step - loss: 0.6878 - acc: 0.5333\n",
      "Epoch 12/12\n",
      "16249/16249 [==============================] - 3s 154us/step - loss: 0.6878 - acc: 0.5345\n",
      "1806/1806 [==============================] - 1s 809us/step\n",
      "16249/16249 [==============================] - 2s 126us/step\n",
      "Epoch 1/12\n",
      "16249/16249 [==============================] - 6s 346us/step - loss: 0.6901 - acc: 0.5187\n",
      "Epoch 2/12\n",
      "16249/16249 [==============================] - 4s 237us/step - loss: 0.6888 - acc: 0.5285\n",
      "Epoch 3/12\n",
      "16249/16249 [==============================] - 3s 163us/step - loss: 0.6886 - acc: 0.5350\n",
      "Epoch 4/12\n",
      "16249/16249 [==============================] - 3s 169us/step - loss: 0.6883 - acc: 0.5340\n",
      "Epoch 5/12\n",
      "16249/16249 [==============================] - 3s 158us/step - loss: 0.6880 - acc: 0.5390\n",
      "Epoch 6/12\n",
      "16249/16249 [==============================] - 3s 157us/step - loss: 0.6880 - acc: 0.5362\n",
      "Epoch 7/12\n",
      "16249/16249 [==============================] - 3s 159us/step - loss: 0.6879 - acc: 0.5412\n",
      "Epoch 8/12\n",
      "16249/16249 [==============================] - 3s 156us/step - loss: 0.6879 - acc: 0.5406\n",
      "Epoch 9/12\n",
      "16249/16249 [==============================] - 2s 152us/step - loss: 0.6877 - acc: 0.5368\n",
      "Epoch 10/12\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6877 - acc: 0.5378\n",
      "Epoch 11/12\n",
      "16249/16249 [==============================] - 3s 161us/step - loss: 0.6875 - acc: 0.5386\n",
      "Epoch 12/12\n",
      "16249/16249 [==============================] - 2s 153us/step - loss: 0.6877 - acc: 0.5390\n",
      "1806/1806 [==============================] - 1s 810us/step\n",
      "16249/16249 [==============================] - 2s 111us/step\n",
      "Epoch 1/12\n",
      "16250/16250 [==============================] - 6s 343us/step - loss: 0.6905 - acc: 0.5081\n",
      "Epoch 2/12\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6888 - acc: 0.5273\n",
      "Epoch 3/12\n",
      "16250/16250 [==============================] - 3s 166us/step - loss: 0.6886 - acc: 0.5324\n",
      "Epoch 4/12\n",
      "16250/16250 [==============================] - 3s 178us/step - loss: 0.6886 - acc: 0.5310\n",
      "Epoch 5/12\n",
      "16250/16250 [==============================] - 2s 153us/step - loss: 0.6881 - acc: 0.5364\n",
      "Epoch 6/12\n",
      "16250/16250 [==============================] - 3s 167us/step - loss: 0.6880 - acc: 0.5382\n",
      "Epoch 7/12\n",
      "16250/16250 [==============================] - 3s 180us/step - loss: 0.6878 - acc: 0.5338\n",
      "Epoch 8/12\n",
      "16250/16250 [==============================] - 3s 162us/step - loss: 0.6879 - acc: 0.5367\n",
      "Epoch 9/12\n",
      "16250/16250 [==============================] - 3s 171us/step - loss: 0.6878 - acc: 0.5357\n",
      "Epoch 10/12\n",
      "16250/16250 [==============================] - 3s 184us/step - loss: 0.6878 - acc: 0.5370\n",
      "Epoch 11/12\n",
      "16250/16250 [==============================] - 3s 204us/step - loss: 0.6878 - acc: 0.5367\n",
      "Epoch 12/12\n",
      "16250/16250 [==============================] - 3s 171us/step - loss: 0.6877 - acc: 0.5364\n",
      "1805/1805 [==============================] - 1s 801us/step\n",
      "16250/16250 [==============================] - 2s 115us/step\n",
      "Epoch 1/12\n",
      "16250/16250 [==============================] - 6s 363us/step - loss: 0.6902 - acc: 0.5188\n",
      "Epoch 2/12\n",
      "16250/16250 [==============================] - 3s 190us/step - loss: 0.6884 - acc: 0.5291\n",
      "Epoch 3/12\n",
      "16250/16250 [==============================] - 3s 180us/step - loss: 0.6877 - acc: 0.5378\n",
      "Epoch 4/12\n",
      "16250/16250 [==============================] - 3s 165us/step - loss: 0.6875 - acc: 0.5378\n",
      "Epoch 5/12\n",
      "16250/16250 [==============================] - 3s 165us/step - loss: 0.6875 - acc: 0.5377\n",
      "Epoch 6/12\n",
      "16250/16250 [==============================] - 3s 171us/step - loss: 0.6873 - acc: 0.5414\n",
      "Epoch 7/12\n",
      "16250/16250 [==============================] - 3s 183us/step - loss: 0.6874 - acc: 0.5410\n",
      "Epoch 8/12\n",
      "16250/16250 [==============================] - 3s 178us/step - loss: 0.6870 - acc: 0.5386\n",
      "Epoch 9/12\n",
      "16250/16250 [==============================] - 2s 152us/step - loss: 0.6872 - acc: 0.5372\n",
      "Epoch 10/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6873 - acc: 0.5395\n",
      "Epoch 11/12\n",
      "16250/16250 [==============================] - 3s 156us/step - loss: 0.6869 - acc: 0.5412\n",
      "Epoch 12/12\n",
      "16250/16250 [==============================] - 3s 163us/step - loss: 0.6870 - acc: 0.5422\n",
      "1805/1805 [==============================] - 1s 784us/step\n",
      "16250/16250 [==============================] - 2s 115us/step\n",
      "Epoch 1/12\n",
      "16250/16250 [==============================] - 6s 357us/step - loss: 0.6905 - acc: 0.5130\n",
      "Epoch 2/12\n",
      "16250/16250 [==============================] - 3s 197us/step - loss: 0.6889 - acc: 0.5236\n",
      "Epoch 3/12\n",
      "16250/16250 [==============================] - 3s 200us/step - loss: 0.6882 - acc: 0.5299\n",
      "Epoch 4/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16250/16250 [==============================] - 3s 167us/step - loss: 0.6880 - acc: 0.5366\n",
      "Epoch 5/12\n",
      "16250/16250 [==============================] - 3s 166us/step - loss: 0.6878 - acc: 0.5364\n",
      "Epoch 6/12\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6877 - acc: 0.5385\n",
      "Epoch 7/12\n",
      "16250/16250 [==============================] - 3s 166us/step - loss: 0.6876 - acc: 0.5403\n",
      "Epoch 8/12\n",
      "16250/16250 [==============================] - 3s 157us/step - loss: 0.6875 - acc: 0.5368\n",
      "Epoch 9/12\n",
      "16250/16250 [==============================] - 3s 161us/step - loss: 0.6876 - acc: 0.5346\n",
      "Epoch 10/12\n",
      "16250/16250 [==============================] - 3s 163us/step - loss: 0.6876 - acc: 0.5367\n",
      "Epoch 11/12\n",
      "16250/16250 [==============================] - 3s 160us/step - loss: 0.6874 - acc: 0.5369\n",
      "Epoch 12/12\n",
      "16250/16250 [==============================] - 3s 164us/step - loss: 0.6872 - acc: 0.5396\n",
      "1805/1805 [==============================] - 1s 799us/step\n",
      "16250/16250 [==============================] - 2s 107us/step\n",
      "Epoch 1/12\n",
      "16250/16250 [==============================] - 6s 347us/step - loss: 0.6901 - acc: 0.5172\n",
      "Epoch 2/12\n",
      "16250/16250 [==============================] - 3s 162us/step - loss: 0.6884 - acc: 0.5317\n",
      "Epoch 3/12\n",
      "16250/16250 [==============================] - 3s 157us/step - loss: 0.6880 - acc: 0.5327\n",
      "Epoch 4/12\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6881 - acc: 0.5346\n",
      "Epoch 5/12\n",
      "16250/16250 [==============================] - 3s 157us/step - loss: 0.6880 - acc: 0.5348\n",
      "Epoch 6/12\n",
      "16250/16250 [==============================] - 3s 156us/step - loss: 0.6876 - acc: 0.5396\n",
      "Epoch 7/12\n",
      "16250/16250 [==============================] - 3s 163us/step - loss: 0.6880 - acc: 0.5378\n",
      "Epoch 8/12\n",
      "16250/16250 [==============================] - 3s 155us/step - loss: 0.6877 - acc: 0.5330\n",
      "Epoch 9/12\n",
      "16250/16250 [==============================] - 3s 157us/step - loss: 0.6878 - acc: 0.5365\n",
      "Epoch 10/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6876 - acc: 0.5350\n",
      "Epoch 11/12\n",
      "16250/16250 [==============================] - 3s 160us/step - loss: 0.6877 - acc: 0.5358\n",
      "Epoch 12/12\n",
      "16250/16250 [==============================] - 3s 159us/step - loss: 0.6877 - acc: 0.5357\n",
      "1805/1805 [==============================] - 1s 797us/step\n",
      "16250/16250 [==============================] - 2s 105us/step\n",
      "Epoch 1/12\n",
      "16250/16250 [==============================] - 6s 343us/step - loss: 0.6908 - acc: 0.5093\n",
      "Epoch 2/12\n",
      "16250/16250 [==============================] - 3s 160us/step - loss: 0.6890 - acc: 0.5196\n",
      "Epoch 3/12\n",
      "16250/16250 [==============================] - 3s 167us/step - loss: 0.6884 - acc: 0.5327\n",
      "Epoch 4/12\n",
      "16250/16250 [==============================] - 3s 163us/step - loss: 0.6880 - acc: 0.5389\n",
      "Epoch 5/12\n",
      "16250/16250 [==============================] - 3s 157us/step - loss: 0.6878 - acc: 0.5375\n",
      "Epoch 6/12\n",
      "16250/16250 [==============================] - 3s 160us/step - loss: 0.6879 - acc: 0.5387\n",
      "Epoch 7/12\n",
      "16250/16250 [==============================] - 3s 161us/step - loss: 0.6877 - acc: 0.5373\n",
      "Epoch 8/12\n",
      "16250/16250 [==============================] - 3s 180us/step - loss: 0.6876 - acc: 0.5388\n",
      "Epoch 9/12\n",
      "16250/16250 [==============================] - 3s 162us/step - loss: 0.6874 - acc: 0.5419\n",
      "Epoch 10/12\n",
      "16250/16250 [==============================] - 3s 183us/step - loss: 0.6875 - acc: 0.5386\n",
      "Epoch 11/12\n",
      "16250/16250 [==============================] - 3s 158us/step - loss: 0.6876 - acc: 0.5388\n",
      "Epoch 12/12\n",
      "16250/16250 [==============================] - 3s 156us/step - loss: 0.6875 - acc: 0.5392\n",
      "1805/1805 [==============================] - 1s 815us/step\n",
      "16250/16250 [==============================] - 2s 104us/step\n",
      "Epoch 1/10\n",
      "18055/18055 [==============================] - 7s 415us/step - loss: 0.6904 - acc: 0.5152\n",
      "Epoch 2/10\n",
      "18055/18055 [==============================] - 5s 278us/step - loss: 0.6887 - acc: 0.5292\n",
      "Epoch 3/10\n",
      "18055/18055 [==============================] - 5s 288us/step - loss: 0.6882 - acc: 0.5320\n",
      "Epoch 4/10\n",
      "18055/18055 [==============================] - 4s 235us/step - loss: 0.6880 - acc: 0.5389\n",
      "Epoch 5/10\n",
      "18055/18055 [==============================] - 4s 242us/step - loss: 0.6877 - acc: 0.5387\n",
      "Epoch 6/10\n",
      "18055/18055 [==============================] - 4s 234us/step - loss: 0.6876 - acc: 0.5365\n",
      "Epoch 7/10\n",
      "18055/18055 [==============================] - 4s 239us/step - loss: 0.6875 - acc: 0.5389\n",
      "Epoch 8/10\n",
      "18055/18055 [==============================] - 4s 240us/step - loss: 0.6875 - acc: 0.5401\n",
      "Epoch 9/10\n",
      "18055/18055 [==============================] - 4s 249us/step - loss: 0.6875 - acc: 0.5405\n",
      "Epoch 10/10\n",
      "18055/18055 [==============================] - 5s 259us/step - loss: 0.6875 - acc: 0.5427\n",
      "Best: 0.541401 using {'batch_size': 8, 'epochs': 10}\n",
      "0.536250 (0.011515) with: {'batch_size': 8, 'epochs': 8}\n",
      "0.541401 (0.011595) with: {'batch_size': 8, 'epochs': 10}\n",
      "0.539795 (0.013239) with: {'batch_size': 8, 'epochs': 12}\n",
      "0.535309 (0.014186) with: {'batch_size': 10, 'epochs': 8}\n",
      "0.534866 (0.009509) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.539407 (0.014235) with: {'batch_size': 10, 'epochs': 12}\n",
      "0.535641 (0.011561) with: {'batch_size': 12, 'epochs': 8}\n",
      "0.539130 (0.011882) with: {'batch_size': 12, 'epochs': 10}\n",
      "0.540626 (0.008976) with: {'batch_size': 12, 'epochs': 12}\n",
      "2923.258638867533\n"
     ]
    }
   ],
   "source": [
    "#Grid Search\n",
    "start = timer()\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [8,10,12]\n",
    "epochs = [8,10,12]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from that, we decide to use batch_size=8, epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stage  B365H  B365D  B365A  output\n",
       "0      1    6.5    4.0   1.50       0\n",
       "1      1    2.4    3.2   2.62       0\n",
       "2      1    2.7    3.0   2.80       1\n",
       "3      1    2.4    3.1   3.10       0\n",
       "4      1    2.4    3.1   3.10       0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['total']=df['home_team_goal']+df['away_team_goal']\n",
    "\n",
    "def betting(dl):\n",
    "    if dl > 2.5: return 1\n",
    "    else: return 0\n",
    "df[\"output\"] = df['total_goals'].map(betting)\n",
    "\n",
    "new_df=df[['stage','B365H', 'B365D', 'B365A', 'output']]\n",
    "new_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5127832412422946\n",
      "2.3470050868454564\n"
     ]
    }
   ],
   "source": [
    "start=timer()\n",
    "\n",
    "X=new_df.iloc[:,0:4]\n",
    "Y=new_df.iloc[:,4]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "seed = 7\n",
    "num_trees = 5\n",
    "max_features = 4\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "end=timer()\n",
    "print(end-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.514733 using {'n_estimators': 7}\n",
      "0.507643 (0.010870) with: {'n_estimators': 6}\n",
      "0.514733 (0.011811) with: {'n_estimators': 7}\n",
      "0.509194 (0.013246) with: {'n_estimators': 8}\n",
      "0.510878 (0.011737) with: {'n_estimators': 9}\n",
      "0.510878 (0.012263) with: {'n_estimators': 10}\n",
      "0.513403 (0.012899) with: {'n_estimators': 11}\n",
      "0.507422 (0.014542) with: {'n_estimators': 12}\n",
      "0.511055 (0.014030) with: {'n_estimators': 13}\n",
      "0.513226 (0.013342) with: {'n_estimators': 14}\n",
      "0.513137 (0.012044) with: {'n_estimators': 15}\n",
      "52.35487234368338\n"
     ]
    }
   ],
   "source": [
    "#Grid Search\n",
    "start = timer()\n",
    "\n",
    "# define the grid search parameters\n",
    "n_estimators=[6,7,8,9,10,11,12,13,14,15]\n",
    "param_grid = dict(n_estimators=n_estimators)\n",
    "\n",
    "seed=7\n",
    "num_trees=5\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "grid_result = grid.fit(X,Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## here we try to predict 1 X 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000026EBC14CC18>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26efa9b9278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['diff_goals']=df['home_team_goal']-df['away_team_goal']\n",
    "df.hist(column='diff_goals', bins=19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diff_goals'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diff_goals'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 means home team wins, 2 means it's a tie, 3 means away team wins\n",
    "\n",
    "def betting(dl):\n",
    "    if dl > 0.5: return 1\n",
    "    elif dl==0: return 2\n",
    "    else: return 3\n",
    "df[\"result\"] = df['diff_goals'].map(betting)\n",
    "df.head()\n",
    "\n",
    "x=np.array([df['stage'], df['B365H'], df['B365D'], df['B365A']])\n",
    "y=np.array([df['result']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the units\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x=scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team_api_id</th>\n",
       "      <th>away_team_api_id</th>\n",
       "      <th>stage</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8596</td>\n",
       "      <td>8548</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8597</td>\n",
       "      <td>10251</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9851</td>\n",
       "      <td>8592</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9829</td>\n",
       "      <td>9847</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9873</td>\n",
       "      <td>9853</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   home_team_api_id  away_team_api_id  stage  B365H  B365D  B365A  result\n",
       "0              8596              8548      1    6.5    4.0   1.50       3\n",
       "1              8597             10251      1    2.4    3.2   2.62       1\n",
       "2              9851              8592      1    2.7    3.0   2.80       2\n",
       "3              9829              9847      1    2.4    3.1   3.10       1\n",
       "4              9873              9853      1    2.4    3.1   3.10       1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df=df[['home_team_api_id','away_team_api_id','stage','B365H', 'B365D', 'B365A', 'result']]\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(new_df, test_size=0.2)\n",
    "x_train=train.iloc[:, 2:6]\n",
    "x_test=test.iloc[:, 2:6]\n",
    "y_train=train.iloc[:, 6]\n",
    "y_test=test.iloc[:, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16248/16248 [==============================] - 9s 573us/step - loss: -0.0370 - acc: 0.3227\n",
      "Epoch 2/10\n",
      "16248/16248 [==============================] - 5s 306us/step - loss: -0.5364 - acc: 0.3587\n",
      "Epoch 3/10\n",
      "16248/16248 [==============================] - 5s 300us/step - loss: -0.6431 - acc: 0.3474\n",
      "Epoch 4/10\n",
      "16248/16248 [==============================] - 5s 319us/step - loss: -0.6942 - acc: 0.3490\n",
      "Epoch 5/10\n",
      "16248/16248 [==============================] - 5s 313us/step - loss: -0.7187 - acc: 0.3474\n",
      "Epoch 6/10\n",
      "16248/16248 [==============================] - 5s 305us/step - loss: -0.7350 - acc: 0.3481\n",
      "Epoch 7/10\n",
      "16248/16248 [==============================] - 5s 308us/step - loss: -0.7452 - acc: 0.3464\n",
      "Epoch 8/10\n",
      "16248/16248 [==============================] - 5s 305us/step - loss: -0.7502 - acc: 0.3448\n",
      "Epoch 9/10\n",
      "16248/16248 [==============================] - 5s 293us/step - loss: -0.7545 - acc: 0.3472\n",
      "Epoch 10/10\n",
      "16248/16248 [==============================] - 5s 319us/step - loss: -0.7595 - acc: 0.3474\n",
      "1807/1807 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "16248/16248 [==============================] - 9s 577us/step - loss: -0.1318 - acc: 0.3292\n",
      "Epoch 2/10\n",
      "16248/16248 [==============================] - 5s 313us/step - loss: -0.6225 - acc: 0.3515\n",
      "Epoch 3/10\n",
      "16248/16248 [==============================] - 4s 268us/step - loss: -0.6973 - acc: 0.3471\n",
      "Epoch 4/10\n",
      "16248/16248 [==============================] - 5s 283us/step - loss: -0.7345 - acc: 0.3461\n",
      "Epoch 5/10\n",
      "16248/16248 [==============================] - 4s 269us/step - loss: -0.7580 - acc: 0.3465\n",
      "Epoch 6/10\n",
      "16248/16248 [==============================] - 4s 269us/step - loss: -0.7627 - acc: 0.3471\n",
      "Epoch 7/10\n",
      "16248/16248 [==============================] - 5s 289us/step - loss: -0.7743 - acc: 0.3461\n",
      "Epoch 8/10\n",
      "16248/16248 [==============================] - 5s 287us/step - loss: -0.7759 - acc: 0.3456\n",
      "Epoch 9/10\n",
      "16248/16248 [==============================] - 5s 279us/step - loss: -0.7810 - acc: 0.3477\n",
      "Epoch 10/10\n",
      "16248/16248 [==============================] - 5s 326us/step - loss: -0.7885 - acc: 0.3463\n",
      "1807/1807 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "16248/16248 [==============================] - 9s 560us/step - loss: -0.1740 - acc: 0.2776\n",
      "Epoch 2/10\n",
      "16248/16248 [==============================] - 5s 277us/step - loss: -0.6442 - acc: 0.3749\n",
      "Epoch 3/10\n",
      "16248/16248 [==============================] - 5s 279us/step - loss: -0.7071 - acc: 0.3611\n",
      "Epoch 4/10\n",
      "16248/16248 [==============================] - 4s 277us/step - loss: -0.7393 - acc: 0.3564\n",
      "Epoch 5/10\n",
      "16248/16248 [==============================] - 5s 277us/step - loss: -0.7574 - acc: 0.3588\n",
      "Epoch 6/10\n",
      "16248/16248 [==============================] - 5s 278us/step - loss: -0.7674 - acc: 0.3560\n",
      "Epoch 7/10\n",
      "16248/16248 [==============================] - 5s 279us/step - loss: -0.7706 - acc: 0.3532\n",
      "Epoch 8/10\n",
      "16248/16248 [==============================] - 5s 278us/step - loss: -0.7722 - acc: 0.3540\n",
      "Epoch 9/10\n",
      "16248/16248 [==============================] - 5s 279us/step - loss: -0.7760 - acc: 0.3527\n",
      "Epoch 10/10\n",
      "16248/16248 [==============================] - 5s 278us/step - loss: -0.7905 - acc: 0.3539\n",
      "1807/1807 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 9s 530us/step - loss: -0.0602 - acc: 0.3230\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 5s 277us/step - loss: -0.3881 - acc: 0.3499\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 4s 277us/step - loss: -0.4223 - acc: 0.3488\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 5s 277us/step - loss: -0.4541 - acc: 0.3497\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 5s 278us/step - loss: -0.4787 - acc: 0.3482\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 5s 278us/step - loss: -0.5032 - acc: 0.3526\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 5s 283us/step - loss: -0.5232 - acc: 0.3529\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 5s 278us/step - loss: -0.5469 - acc: 0.3541\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 5s 280us/step - loss: -0.5665 - acc: 0.3555\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 5s 279us/step - loss: -0.5832 - acc: 0.3581\n",
      "1806/1806 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 9s 536us/step - loss: -0.0835 - acc: 0.3282\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 5s 278us/step - loss: -0.5643 - acc: 0.3473\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 5s 279us/step - loss: -0.6450 - acc: 0.3485\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 5s 281us/step - loss: -0.6884 - acc: 0.3488\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 5s 278us/step - loss: -0.7137 - acc: 0.3504\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 5s 280us/step - loss: -0.7356 - acc: 0.3460\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 5s 281us/step - loss: -0.7446 - acc: 0.3473\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 5s 278us/step - loss: -0.7470 - acc: 0.3487\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 5s 279us/step - loss: -0.7540 - acc: 0.3457\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 5s 278us/step - loss: -0.7625 - acc: 0.3470\n",
      "1805/1805 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 8s 515us/step - loss: -0.0994 - acc: 0.3292\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 4s 257us/step - loss: -0.5306 - acc: 0.3512\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 5s 297us/step - loss: -0.6294 - acc: 0.3508\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 5s 310us/step - loss: -0.6770 - acc: 0.3484\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 4s 275us/step - loss: -0.7102 - acc: 0.3506\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 4s 271us/step - loss: -0.7321 - acc: 0.3496\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 4s 269us/step - loss: -0.7487 - acc: 0.3482\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 5s 279us/step - loss: -0.7534 - acc: 0.3505\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 4s 271us/step - loss: -0.7610 - acc: 0.3492\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 4s 272us/step - loss: -0.7678 - acc: 0.3497\n",
      "1805/1805 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 9s 533us/step - loss: -0.1078 - acc: 0.3282\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 4s 271us/step - loss: -0.5716 - acc: 0.3543\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 4s 272us/step - loss: -0.6612 - acc: 0.3524\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 4s 271us/step - loss: -0.7079 - acc: 0.3478\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 4s 271us/step - loss: -0.7302 - acc: 0.3484\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 4s 270us/step - loss: -0.7448 - acc: 0.3457\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 4s 271us/step - loss: -0.7588 - acc: 0.3484\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 4s 269us/step - loss: -0.7594 - acc: 0.3502\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 4s 272us/step - loss: -0.7653 - acc: 0.3501\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 5s 296us/step - loss: -0.7695 - acc: 0.3503\n",
      "1805/1805 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 9s 531us/step - loss: -0.1082 - acc: 0.3254\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 4s 270us/step - loss: -0.6127 - acc: 0.3591\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 4s 272us/step - loss: -0.6944 - acc: 0.3552\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 4s 273us/step - loss: -0.7374 - acc: 0.3594\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 4s 276us/step - loss: -0.7511 - acc: 0.3618\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 4s 273us/step - loss: -0.7672 - acc: 0.3610\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 4s 276us/step - loss: -0.7771 - acc: 0.3622\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 4s 271us/step - loss: -0.7837 - acc: 0.3606\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 4s 271us/step - loss: -0.7878 - acc: 0.3607\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 4s 272us/step - loss: -0.7987 - acc: 0.3598\n",
      "1805/1805 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "16251/16251 [==============================] - 9s 536us/step - loss: -0.1982 - acc: 0.2866\n",
      "Epoch 2/10\n",
      "16251/16251 [==============================] - 4s 271us/step - loss: -0.6401 - acc: 0.3587\n",
      "Epoch 3/10\n",
      "16251/16251 [==============================] - 4s 276us/step - loss: -0.6920 - acc: 0.3547\n",
      "Epoch 4/10\n",
      "16251/16251 [==============================] - 4s 272us/step - loss: -0.7215 - acc: 0.3575\n",
      "Epoch 5/10\n",
      "16251/16251 [==============================] - 4s 272us/step - loss: -0.7359 - acc: 0.3540\n",
      "Epoch 6/10\n",
      "16251/16251 [==============================] - 4s 272us/step - loss: -0.7376 - acc: 0.3542\n",
      "Epoch 7/10\n",
      "16251/16251 [==============================] - 4s 275us/step - loss: -0.7484 - acc: 0.3554\n",
      "Epoch 8/10\n",
      "16251/16251 [==============================] - 4s 272us/step - loss: -0.7461 - acc: 0.3538\n",
      "Epoch 9/10\n",
      "16251/16251 [==============================] - 4s 272us/step - loss: -0.7485 - acc: 0.3541\n",
      "Epoch 10/10\n",
      "16251/16251 [==============================] - 4s 272us/step - loss: -0.7486 - acc: 0.3549\n",
      "1804/1804 [==============================] - 2s 1ms/step\n",
      "Epoch 1/10\n",
      "16251/16251 [==============================] - 9s 545us/step - loss: -0.1978 - acc: 0.3330\n",
      "Epoch 2/10\n",
      "16251/16251 [==============================] - 4s 276us/step - loss: -0.6018 - acc: 0.3511\n",
      "Epoch 3/10\n",
      "16251/16251 [==============================] - 5s 278us/step - loss: -0.6839 - acc: 0.3494\n",
      "Epoch 4/10\n",
      "16251/16251 [==============================] - 4s 275us/step - loss: -0.7193 - acc: 0.3489\n",
      "Epoch 5/10\n",
      "16251/16251 [==============================] - 4s 274us/step - loss: -0.7402 - acc: 0.3476\n",
      "Epoch 6/10\n",
      "16251/16251 [==============================] - 4s 273us/step - loss: -0.7539 - acc: 0.3481\n",
      "Epoch 7/10\n",
      "16251/16251 [==============================] - 4s 273us/step - loss: -0.7622 - acc: 0.3494\n",
      "Epoch 8/10\n",
      "16251/16251 [==============================] - 4s 275us/step - loss: -0.7637 - acc: 0.3488\n",
      "Epoch 9/10\n",
      "16251/16251 [==============================] - 4s 273us/step - loss: -0.7645 - acc: 0.3485\n",
      "Epoch 10/10\n",
      "16251/16251 [==============================] - 4s 276us/step - loss: -0.7718 - acc: 0.3487\n",
      "1804/1804 [==============================] - 2s 1ms/step\n",
      "0.35347685217896857\n",
      "523.9516791629658\n"
     ]
    }
   ],
   "source": [
    "start=timer()\n",
    "\n",
    "def create_model(optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=4, activation='relu', kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=\"uniform\"))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=8, verbose=1)\n",
    "\n",
    "# evaluate using 10-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, x_train, y_train, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "end = timer()\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 10s 607us/step - loss: -0.2950 - acc: 0.3425\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 5s 311us/step - loss: -0.6013 - acc: 0.3502\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 5s 314us/step - loss: -0.6443 - acc: 0.3421\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 5s 325us/step - loss: -0.6717 - acc: 0.3370\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 5s 316us/step - loss: -0.6671 - acc: 0.3360\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 5s 317us/step - loss: -0.6883 - acc: 0.3333\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 5s 319us/step - loss: -0.6737 - acc: 0.3380\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 5s 314us/step - loss: -0.6835 - acc: 0.3367\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 5s 314us/step - loss: -0.6807 - acc: 0.3351\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 5s 314us/step - loss: -0.6685 - acc: 0.3344\n",
      "1806/1806 [==============================] - 3s 1ms/step\n",
      "16249/16249 [==============================] - 4s 223us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 10s 606us/step - loss: -0.2611 - acc: 0.3345\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 5s 307us/step - loss: -0.5943 - acc: 0.3433\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 5s 302us/step - loss: -0.5995 - acc: 0.3397\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 5s 338us/step - loss: -0.6182 - acc: 0.3390\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 344us/step - loss: -0.6377 - acc: 0.3392\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 340us/step - loss: -0.6573 - acc: 0.3366\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 343us/step - loss: -0.6697 - acc: 0.3331\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 349us/step - loss: -0.6655 - acc: 0.3352\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 351us/step - loss: -0.6545 - acc: 0.3382\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 343us/step - loss: -0.6692 - acc: 0.3391\n",
      "1806/1806 [==============================] - 3s 1ms/step\n",
      "16249/16249 [==============================] - 4s 250us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 10s 641us/step - loss: -0.2920 - acc: 0.3406\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 343us/step - loss: -0.6158 - acc: 0.3449\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 344us/step - loss: -0.6667 - acc: 0.3480\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 341us/step - loss: -0.6863 - acc: 0.3379\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 341us/step - loss: -0.6602 - acc: 0.3389\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 341us/step - loss: -0.6899 - acc: 0.3384\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 341us/step - loss: -0.7103 - acc: 0.3365\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 340us/step - loss: -0.7287 - acc: 0.3360\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 341us/step - loss: -0.6730 - acc: 0.3355\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 340us/step - loss: -0.6600 - acc: 0.3363\n",
      "1806/1806 [==============================] - 3s 1ms/step\n",
      "16249/16249 [==============================] - 4s 246us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 10s 642us/step - loss: -0.2549 - acc: 0.2527\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 342us/step - loss: -0.5449 - acc: 0.3244\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 341us/step - loss: -0.6053 - acc: 0.2741\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 344us/step - loss: -0.6027 - acc: 0.2527\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 345us/step - loss: -0.6049 - acc: 0.2752\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 344us/step - loss: -0.6248 - acc: 0.2827\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 343us/step - loss: -0.6330 - acc: 0.3305\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 345us/step - loss: -0.6333 - acc: 0.2828\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 346us/step - loss: -0.6486 - acc: 0.2527\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 348us/step - loss: -0.6296 - acc: 0.2527\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 250us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 11s 649us/step - loss: -0.3072 - acc: 0.3448\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 346us/step - loss: -0.5896 - acc: 0.3499\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 346us/step - loss: -0.6367 - acc: 0.3435\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 348us/step - loss: -0.6581 - acc: 0.3418\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 347us/step - loss: -0.6562 - acc: 0.3423\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 358us/step - loss: -0.6541 - acc: 0.3413\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 346us/step - loss: -0.6878 - acc: 0.3434\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 345us/step - loss: -0.7021 - acc: 0.3374\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 350us/step - loss: -0.6749 - acc: 0.3419\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 347us/step - loss: -0.6978 - acc: 0.3428\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 257us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 11s 652us/step - loss: -0.3183 - acc: 0.3469\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 350us/step - loss: -0.6129 - acc: 0.3525\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 349us/step - loss: -0.6508 - acc: 0.3479\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 349us/step - loss: -0.6579 - acc: 0.3445\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 352us/step - loss: -0.7044 - acc: 0.3454\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 367us/step - loss: -0.6846 - acc: 0.3402\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 351us/step - loss: -0.7044 - acc: 0.3388\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 350us/step - loss: -0.6908 - acc: 0.3409\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 349us/step - loss: -0.7019 - acc: 0.3406\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 353us/step - loss: -0.6943 - acc: 0.3425\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 253us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 11s 668us/step - loss: -0.3257 - acc: 0.3357\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 352us/step - loss: -0.5904 - acc: 0.3464\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 350us/step - loss: -0.6273 - acc: 0.3426\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 352us/step - loss: -0.6549 - acc: 0.3391\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.6708 - acc: 0.3398\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 352us/step - loss: -0.6863 - acc: 0.3372\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 350us/step - loss: -0.7121 - acc: 0.3383\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 353us/step - loss: -0.7053 - acc: 0.3387\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 352us/step - loss: -0.7092 - acc: 0.3366\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 352us/step - loss: -0.6896 - acc: 0.3399\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 254us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 11s 688us/step - loss: -0.2704 - acc: 0.3390\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 362us/step - loss: -0.5779 - acc: 0.3476\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16250/16250 [==============================] - 6s 340us/step - loss: -0.6417 - acc: 0.3423\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 5s 338us/step - loss: -0.6270 - acc: 0.3424\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 5s 337us/step - loss: -0.6346 - acc: 0.3407\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 339us/step - loss: -0.6718 - acc: 0.3365\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 339us/step - loss: -0.6893 - acc: 0.3362\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 367us/step - loss: -0.6487 - acc: 0.3346\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 339us/step - loss: -0.7106 - acc: 0.3356\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 342us/step - loss: -0.6909 - acc: 0.3380\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 244us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 10s 641us/step - loss: -0.3049 - acc: 0.3465\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 5s 338us/step - loss: -0.6274 - acc: 0.3498\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 5s 335us/step - loss: -0.6558 - acc: 0.3451\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 5s 336us/step - loss: -0.6826 - acc: 0.3407\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 5s 335us/step - loss: -0.6905 - acc: 0.3409\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 5s 335us/step - loss: -0.6692 - acc: 0.3385\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 5s 335us/step - loss: -0.6617 - acc: 0.3412\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 5s 337us/step - loss: -0.7059 - acc: 0.3378\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 5s 337us/step - loss: -0.6785 - acc: 0.3397\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 5s 335us/step - loss: -0.7158 - acc: 0.3377\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 246us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 10s 644us/step - loss: -0.3080 - acc: 0.3278\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 5s 338us/step - loss: -0.5760 - acc: 0.3567\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 5s 337us/step - loss: -0.6239 - acc: 0.3418\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 339us/step - loss: -0.6487 - acc: 0.3401\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 5s 337us/step - loss: -0.6493 - acc: 0.3387\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 339us/step - loss: -0.6689 - acc: 0.3369\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 5s 338us/step - loss: -0.6652 - acc: 0.3393\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 5s 338us/step - loss: -0.6584 - acc: 0.3420\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 340us/step - loss: -0.6569 - acc: 0.3417\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 341us/step - loss: -0.6895 - acc: 0.3398\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 244us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 11s 662us/step - loss: -0.1076 - acc: 0.3308\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 350us/step - loss: -0.6235 - acc: 0.3614\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 353us/step - loss: -0.7054 - acc: 0.3562\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 353us/step - loss: -0.7326 - acc: 0.3518\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 353us/step - loss: -0.7552 - acc: 0.3509\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 351us/step - loss: -0.7552 - acc: 0.3511\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 352us/step - loss: -0.7610 - acc: 0.3538\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 352us/step - loss: -0.7637 - acc: 0.3529\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 352us/step - loss: -0.7727 - acc: 0.3555\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 352us/step - loss: -0.7742 - acc: 0.3580\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 248us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 11s 693us/step - loss: 0.0825 - acc: 0.3161\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 347us/step - loss: -0.4002 - acc: 0.3510\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 345us/step - loss: -0.5424 - acc: 0.3535\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 347us/step - loss: -0.6123 - acc: 0.3505\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 346us/step - loss: -0.6582 - acc: 0.3493\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 347us/step - loss: -0.6851 - acc: 0.3509\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 346us/step - loss: -0.7016 - acc: 0.3508\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 344us/step - loss: -0.7189 - acc: 0.3499\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 345us/step - loss: -0.7267 - acc: 0.3517\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 348us/step - loss: -0.7332 - acc: 0.3508\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 249us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 11s 666us/step - loss: -0.0303 - acc: 0.3190\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 352us/step - loss: -0.6035 - acc: 0.3542\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 353us/step - loss: -0.7026 - acc: 0.3515\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 354us/step - loss: -0.7380 - acc: 0.34750s - loss: -0.7297 -\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 356us/step - loss: -0.7535 - acc: 0.3461\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 353us/step - loss: -0.7663 - acc: 0.3473\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 357us/step - loss: -0.7657 - acc: 0.3452\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 354us/step - loss: -0.7764 - acc: 0.3471\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 355us/step - loss: -0.7861 - acc: 0.3451\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 356us/step - loss: -0.7808 - acc: 0.3440\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 248us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 11s 666us/step - loss: -0.0079 - acc: 0.3235\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 356us/step - loss: -0.5598 - acc: 0.3587\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 365us/step - loss: -0.6600 - acc: 0.3546\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 356us/step - loss: -0.7068 - acc: 0.3501\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 358us/step - loss: -0.7140 - acc: 0.3497\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 359us/step - loss: -0.7253 - acc: 0.3486\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 357us/step - loss: -0.7323 - acc: 0.3467\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 358us/step - loss: -0.7382 - acc: 0.3501\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 356us/step - loss: -0.7416 - acc: 0.3471\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 359us/step - loss: -0.7459 - acc: 0.3471\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 249us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 11s 671us/step - loss: 0.0074 - acc: 0.3182\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 353us/step - loss: -0.4722 - acc: 0.3545\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 368us/step - loss: -0.6170 - acc: 0.3516\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 353us/step - loss: -0.6739 - acc: 0.3503\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16249/16249 [==============================] - 6s 342us/step - loss: -0.7125 - acc: 0.3532\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 345us/step - loss: -0.7384 - acc: 0.3517\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 345us/step - loss: -0.7485 - acc: 0.3502\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 343us/step - loss: -0.7660 - acc: 0.3526\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 346us/step - loss: -0.7731 - acc: 0.3509\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 344us/step - loss: -0.7681 - acc: 0.3502\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 246us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 11s 671us/step - loss: -0.0797 - acc: 0.3287\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 352us/step - loss: -0.6180 - acc: 0.3670\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 352us/step - loss: -0.7014 - acc: 0.3604\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 352us/step - loss: -0.7413 - acc: 0.3594\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 353us/step - loss: -0.7626 - acc: 0.3582\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 352us/step - loss: -0.7710 - acc: 0.3628\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 355us/step - loss: -0.7701 - acc: 0.3599\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 353us/step - loss: -0.7741 - acc: 0.3629\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.7766 - acc: 0.3622\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 362us/step - loss: -0.7808 - acc: 0.3604\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 248us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 11s 676us/step - loss: -0.0800 - acc: 0.3254\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 355us/step - loss: -0.5835 - acc: 0.3540\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 358us/step - loss: -0.6872 - acc: 0.3516\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 355us/step - loss: -0.7279 - acc: 0.3533\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 356us/step - loss: -0.7503 - acc: 0.3488\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 371us/step - loss: -0.7623 - acc: 0.3492\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 358us/step - loss: -0.7697 - acc: 0.3518\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 362us/step - loss: -0.7741 - acc: 0.3473\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 356us/step - loss: -0.7816 - acc: 0.3485\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 355us/step - loss: -0.7835 - acc: 0.3483\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 249us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 11s 673us/step - loss: -0.0358 - acc: 0.3222\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 350us/step - loss: -0.5841 - acc: 0.3619\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 350us/step - loss: -0.6860 - acc: 0.3522\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 350us/step - loss: -0.7283 - acc: 0.3488\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 351us/step - loss: -0.7386 - acc: 0.3493\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 349us/step - loss: -0.7488 - acc: 0.3499\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 359us/step - loss: -0.7583 - acc: 0.3475\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 350us/step - loss: -0.7621 - acc: 0.3500\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 352us/step - loss: -0.7640 - acc: 0.3490\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 351us/step - loss: -0.7647 - acc: 0.3557\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 253us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 11s 679us/step - loss: 0.0413 - acc: 0.3193\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.3790 - acc: 0.3516\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 353us/step - loss: -0.4267 - acc: 0.3538\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.4506 - acc: 0.3557\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 358us/step - loss: -0.4753 - acc: 0.3531\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 356us/step - loss: -0.4993 - acc: 0.3553\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 355us/step - loss: -0.5172 - acc: 0.3543\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.5427 - acc: 0.3552\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.5597 - acc: 0.3559\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 380us/step - loss: -0.5822 - acc: 0.3582\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 254us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 11s 679us/step - loss: -0.0288 - acc: 0.3237\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.4863 - acc: 0.3525\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 353us/step - loss: -0.6126 - acc: 0.3525\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 353us/step - loss: -0.6591 - acc: 0.3537\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.6946 - acc: 0.3527\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.7124 - acc: 0.3548\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 353us/step - loss: -0.7288 - acc: 0.3527\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 356us/step - loss: -0.7334 - acc: 0.3513\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 355us/step - loss: -0.7381 - acc: 0.3532\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.7462 - acc: 0.3514\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 254us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 11s 680us/step - loss: 0.1128 - acc: 0.3141\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 357us/step - loss: -0.2162 - acc: 0.3411\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 362us/step - loss: -0.3388 - acc: 0.3433\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 366us/step - loss: -0.3945 - acc: 0.3468\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 365us/step - loss: -0.4240 - acc: 0.3478\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 365us/step - loss: -0.4446 - acc: 0.3481\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 365us/step - loss: -0.4595 - acc: 0.3476\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 364us/step - loss: -0.4710 - acc: 0.3494\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 364us/step - loss: -0.4811 - acc: 0.3518\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 365us/step - loss: -0.4893 - acc: 0.3495\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 258us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 11s 686us/step - loss: 0.2509 - acc: 0.2529\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 360us/step - loss: -0.0417 - acc: 0.2529\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 358us/step - loss: -0.2251 - acc: 0.2529\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 358us/step - loss: -0.3364 - acc: 0.2529\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 358us/step - loss: -0.4042 - acc: 0.2529\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 357us/step - loss: -0.4509 - acc: 0.2529\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 346us/step - loss: -0.4859 - acc: 0.3403\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 348us/step - loss: -0.5086 - acc: 0.3791\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 347us/step - loss: -0.5281 - acc: 0.3837\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 355us/step - loss: -0.5432 - acc: 0.3829\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 250us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 11s 683us/step - loss: 0.0099 - acc: 0.3163\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 351us/step - loss: -0.3179 - acc: 0.3494\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 353us/step - loss: -0.4252 - acc: 0.3522\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 354us/step - loss: -0.4868 - acc: 0.3521\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 352us/step - loss: -0.5279 - acc: 0.3502\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 351us/step - loss: -0.5561 - acc: 0.3490\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 353us/step - loss: -0.5765 - acc: 0.3488\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 353us/step - loss: -0.5930 - acc: 0.3462\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 356us/step - loss: -0.6062 - acc: 0.3477\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 383us/step - loss: -0.6172 - acc: 0.3488\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 254us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 11s 692us/step - loss: 0.2014 - acc: 0.3043\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 362us/step - loss: -0.0438 - acc: 0.3336\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 364us/step - loss: -0.1628 - acc: 0.3391\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 360us/step - loss: -0.2322 - acc: 0.3429\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 362us/step - loss: -0.2742 - acc: 0.3454\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 360us/step - loss: -0.3021 - acc: 0.3473\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 362us/step - loss: -0.3210 - acc: 0.3446\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 364us/step - loss: -0.3344 - acc: 0.3483\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 366us/step - loss: -0.3447 - acc: 0.3480\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 362us/step - loss: -0.3524 - acc: 0.3478\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 260us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 11s 689us/step - loss: 0.1481 - acc: 0.2539\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 359us/step - loss: -0.2124 - acc: 0.2539\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 363us/step - loss: -0.3735 - acc: 0.2539\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 373us/step - loss: -0.4550 - acc: 0.2539\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 365us/step - loss: -0.5041 - acc: 0.3228\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 366us/step - loss: -0.5367 - acc: 0.3773\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 363us/step - loss: -0.5591 - acc: 0.3803\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 364us/step - loss: -0.5757 - acc: 0.3847\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 366us/step - loss: -0.5887 - acc: 0.3837\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 366us/step - loss: -0.5999 - acc: 0.3835\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 258us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 11s 690us/step - loss: 0.1187 - acc: 0.3180\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 357us/step - loss: -0.1669 - acc: 0.3396\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 357us/step - loss: -0.2796 - acc: 0.3456\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 358us/step - loss: -0.3405 - acc: 0.3492\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 356us/step - loss: -0.3824 - acc: 0.3489\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 358us/step - loss: -0.4085 - acc: 0.3477\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 359us/step - loss: -0.4269 - acc: 0.3482\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 358us/step - loss: -0.4419 - acc: 0.3477\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 358us/step - loss: -0.4544 - acc: 0.3490\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 359us/step - loss: -0.4647 - acc: 0.3481\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 258us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 11s 697us/step - loss: 0.0552 - acc: 0.3145\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 358us/step - loss: -0.3186 - acc: 0.3584\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 358us/step - loss: -0.4489 - acc: 0.3670\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 358us/step - loss: -0.5170 - acc: 0.3693\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 359us/step - loss: -0.5599 - acc: 0.3669\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 360us/step - loss: -0.5880 - acc: 0.3662\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 359us/step - loss: -0.6086 - acc: 0.3640\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 359us/step - loss: -0.6244 - acc: 0.3594\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 359us/step - loss: -0.6375 - acc: 0.3605\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 358us/step - loss: -0.6479 - acc: 0.3572\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 262us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 11s 698us/step - loss: 0.1962 - acc: 0.3102\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 359us/step - loss: -0.0259 - acc: 0.3357\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 360us/step - loss: -0.1370 - acc: 0.3398\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 361us/step - loss: -0.2078 - acc: 0.3433\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 360us/step - loss: -0.2540 - acc: 0.3447\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 365us/step - loss: -0.2851 - acc: 0.3458\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 362us/step - loss: -0.3082 - acc: 0.3463\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 362us/step - loss: -0.3249 - acc: 0.3472\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 361us/step - loss: -0.3374 - acc: 0.3465\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 360us/step - loss: -0.3470 - acc: 0.3466\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 263us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 12s 712us/step - loss: 0.0955 - acc: 0.3164\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 374us/step - loss: -0.1954 - acc: 0.3407\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 371us/step - loss: -0.3054 - acc: 0.3460\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 371us/step - loss: -0.3582 - acc: 0.3518\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 371us/step - loss: -0.3896 - acc: 0.3514\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 374us/step - loss: -0.4149 - acc: 0.3498\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 371us/step - loss: -0.4353 - acc: 0.3487\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 369us/step - loss: -0.4495 - acc: 0.3492\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16250/16250 [==============================] - 6s 362us/step - loss: -0.4602 - acc: 0.3486\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 361us/step - loss: -0.4696 - acc: 0.3502\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 258us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 11s 698us/step - loss: 0.1294 - acc: 0.3134\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 355us/step - loss: -0.1572 - acc: 0.3367\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 356us/step - loss: -0.2724 - acc: 0.3454\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 357us/step - loss: -0.3318 - acc: 0.3487\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 357us/step - loss: -0.3712 - acc: 0.3483\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 358us/step - loss: -0.3965 - acc: 0.3474\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 359us/step - loss: -0.4144 - acc: 0.3482\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 358us/step - loss: -0.4284 - acc: 0.3483\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 360us/step - loss: -0.4391 - acc: 0.3492\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 357us/step - loss: -0.4481 - acc: 0.3484\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 260us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 12s 709us/step - loss: -0.2523 - acc: 0.3368\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 373us/step - loss: -0.4725 - acc: 0.3507\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 364us/step - loss: -0.5440 - acc: 0.3531\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 366us/step - loss: -0.5993 - acc: 0.3520\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 366us/step - loss: -0.6436 - acc: 0.3528\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 365us/step - loss: -0.6743 - acc: 0.3543\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 366us/step - loss: -0.6948 - acc: 0.3560\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 366us/step - loss: -0.7120 - acc: 0.3587\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 366us/step - loss: -0.7204 - acc: 0.3591\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 365us/step - loss: -0.7333 - acc: 0.3575\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 261us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 12s 715us/step - loss: -0.2338 - acc: 0.3440\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 398us/step - loss: -0.3993 - acc: 0.3498\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 369us/step - loss: -0.4453 - acc: 0.3503\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 367us/step - loss: -0.5033 - acc: 0.3520\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 371us/step - loss: -0.5538 - acc: 0.3529\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 381us/step - loss: -0.5991 - acc: 0.3522\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 371us/step - loss: -0.6309 - acc: 0.3526\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 369us/step - loss: -0.6607 - acc: 0.3537\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 370us/step - loss: -0.6835 - acc: 0.3563\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 369us/step - loss: -0.6937 - acc: 0.3560\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 265us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 12s 719us/step - loss: -0.5209 - acc: 0.3549\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 370us/step - loss: -0.7205 - acc: 0.3584\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 371us/step - loss: -0.7514 - acc: 0.3568\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 371us/step - loss: -0.7625 - acc: 0.3564\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 371us/step - loss: -0.7748 - acc: 0.3582\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 7s 412us/step - loss: -0.7762 - acc: 0.3578\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 372us/step - loss: -0.7829 - acc: 0.3580\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 379us/step - loss: -0.7866 - acc: 0.3565\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 372us/step - loss: -0.7915 - acc: 0.3580\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 371us/step - loss: -0.7905 - acc: 0.3589\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 266us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 12s 730us/step - loss: -0.4159 - acc: 0.3457\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 379us/step - loss: -0.6655 - acc: 0.3642\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 377us/step - loss: -0.7072 - acc: 0.3638\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 378us/step - loss: -0.7181 - acc: 0.3651\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 380us/step - loss: -0.7285 - acc: 0.3665\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 380us/step - loss: -0.7387 - acc: 0.3669\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 388us/step - loss: -0.7465 - acc: 0.3669\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 380us/step - loss: -0.7461 - acc: 0.3670\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 370us/step - loss: -0.7517 - acc: 0.3651\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 373us/step - loss: -0.7510 - acc: 0.3641\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 255us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 12s 748us/step - loss: -0.4866 - acc: 0.3493\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 399us/step - loss: -0.6941 - acc: 0.3498\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 7s 410us/step - loss: -0.7239 - acc: 0.3487\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 7s 406us/step - loss: -0.7428 - acc: 0.3497\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 7s 402us/step - loss: -0.7536 - acc: 0.3474\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 7s 404us/step - loss: -0.7623 - acc: 0.3477\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 7s 402us/step - loss: -0.7696 - acc: 0.3462\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 7s 403us/step - loss: -0.7763 - acc: 0.3463\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 7s 404us/step - loss: -0.7736 - acc: 0.3478\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 7s 404us/step - loss: -0.7836 - acc: 0.3483\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 257us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 12s 716us/step - loss: -0.3349 - acc: 0.3393\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 371us/step - loss: -0.6066 - acc: 0.3513\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 368us/step - loss: -0.6767 - acc: 0.3527\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 370us/step - loss: -0.7195 - acc: 0.3514\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 371us/step - loss: -0.7404 - acc: 0.3521\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 370us/step - loss: -0.7520 - acc: 0.3515\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 372us/step - loss: -0.7615 - acc: 0.3522\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 369us/step - loss: -0.7695 - acc: 0.3527\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 370us/step - loss: -0.7752 - acc: 0.3530\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 369us/step - loss: -0.7811 - acc: 0.3534\n",
      "1805/1805 [==============================] - 4s 2ms/step\n",
      "16250/16250 [==============================] - 10s 611us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 13s 788us/step - loss: -0.4237 - acc: 0.3487\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 10s 594us/step - loss: -0.6957 - acc: 0.3528\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 387us/step - loss: -0.7372 - acc: 0.3489\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 362us/step - loss: -0.7497 - acc: 0.3499\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 393us/step - loss: -0.7656 - acc: 0.3496\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 7s 419us/step - loss: -0.7718 - acc: 0.3488\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 353us/step - loss: -0.7778 - acc: 0.3517\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 359us/step - loss: -0.7797 - acc: 0.3506\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 349us/step - loss: -0.7847 - acc: 0.3514\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 346us/step - loss: -0.7895 - acc: 0.3519\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 241us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 11s 706us/step - loss: -0.3477 - acc: 0.3532\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 342us/step - loss: -0.6410 - acc: 0.3618\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 342us/step - loss: -0.6920 - acc: 0.3601\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 344us/step - loss: -0.7207 - acc: 0.3583\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 341us/step - loss: -0.7347 - acc: 0.3582\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 343us/step - loss: -0.7459 - acc: 0.3537\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 345us/step - loss: -0.7522 - acc: 0.3553\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 341us/step - loss: -0.7580 - acc: 0.3542\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 344us/step - loss: -0.7619 - acc: 0.3564\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 342us/step - loss: -0.7683 - acc: 0.3577\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 244us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 12s 711us/step - loss: -0.4784 - acc: 0.3445\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 356us/step - loss: -0.7276 - acc: 0.3626\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 7s 412us/step - loss: -0.7537 - acc: 0.3630\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 384us/step - loss: -0.7781 - acc: 0.3586\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 392us/step - loss: -0.7877 - acc: 0.3543\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 366us/step - loss: -0.7867 - acc: 0.3547\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.7904 - acc: 0.3559\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 353us/step - loss: -0.7948 - acc: 0.3577\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 350us/step - loss: -0.7965 - acc: 0.3574\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 350us/step - loss: -0.7984 - acc: 0.3587\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 241us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 12s 709us/step - loss: -0.2366 - acc: 0.3404\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 364us/step - loss: -0.5368 - acc: 0.3537\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 352us/step - loss: -0.6168 - acc: 0.3510\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 344us/step - loss: -0.6661 - acc: 0.3549\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 349us/step - loss: -0.7017 - acc: 0.3511\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 346us/step - loss: -0.7209 - acc: 0.3519\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 351us/step - loss: -0.7314 - acc: 0.3509\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 350us/step - loss: -0.7366 - acc: 0.3542\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 343us/step - loss: -0.7406 - acc: 0.3501\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 346us/step - loss: -0.7478 - acc: 0.3521\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 242us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 12s 717us/step - loss: -0.2692 - acc: 0.3382\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 349us/step - loss: -0.6385 - acc: 0.3497\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 349us/step - loss: -0.7149 - acc: 0.3516\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 348us/step - loss: -0.7379 - acc: 0.3550\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 365us/step - loss: -0.7541 - acc: 0.3512\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 7s 427us/step - loss: -0.7540 - acc: 0.3473\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 384us/step - loss: -0.7664 - acc: 0.3480\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 386us/step - loss: -0.7628 - acc: 0.3478\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 391us/step - loss: -0.7629 - acc: 0.3501\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 384us/step - loss: -0.7665 - acc: 0.3434\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 5s 280us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 12s 732us/step - loss: -0.3340 - acc: 0.3186\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 354us/step - loss: -0.6810 - acc: 0.3651\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 355us/step - loss: -0.7211 - acc: 0.3650\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 356us/step - loss: -0.7310 - acc: 0.3623\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 354us/step - loss: -0.7482 - acc: 0.3596\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 355us/step - loss: -0.7481 - acc: 0.3565\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 355us/step - loss: -0.7467 - acc: 0.3536\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 387us/step - loss: -0.7469 - acc: 0.3524\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 7s 409us/step - loss: -0.7610 - acc: 0.3545\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 394us/step - loss: -0.7516 - acc: 0.3537\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 5s 285us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 12s 757us/step - loss: -0.3290 - acc: 0.3409\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 357us/step - loss: -0.6974 - acc: 0.3559\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 369us/step - loss: -0.7470 - acc: 0.3595\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 354us/step - loss: -0.7674 - acc: 0.3634\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 353us/step - loss: -0.7787 - acc: 0.3619\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 357us/step - loss: -0.7748 - acc: 0.3616\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 354us/step - loss: -0.7899 - acc: 0.3595\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 359us/step - loss: -0.7905 - acc: 0.3584\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 357us/step - loss: -0.7721 - acc: 0.3566\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 357us/step - loss: -0.7832 - acc: 0.3590\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 249us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16249/16249 [==============================] - 12s 729us/step - loss: -0.2569 - acc: 0.3384\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 356us/step - loss: -0.5620 - acc: 0.3503\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 355us/step - loss: -0.6387 - acc: 0.3495\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 364us/step - loss: -0.6859 - acc: 0.3522\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 355us/step - loss: -0.7062 - acc: 0.3534\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 358us/step - loss: -0.7221 - acc: 0.3511\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 358us/step - loss: -0.7256 - acc: 0.3554\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 356us/step - loss: -0.7315 - acc: 0.3542\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 356us/step - loss: -0.7380 - acc: 0.3538\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 355us/step - loss: -0.7360 - acc: 0.3528\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 247us/step\n",
      "Epoch 1/10\n",
      "16249/16249 [==============================] - 12s 725us/step - loss: -0.3544 - acc: 0.3400\n",
      "Epoch 2/10\n",
      "16249/16249 [==============================] - 6s 350us/step - loss: -0.6833 - acc: 0.3496\n",
      "Epoch 3/10\n",
      "16249/16249 [==============================] - 6s 352us/step - loss: -0.7373 - acc: 0.3473\n",
      "Epoch 4/10\n",
      "16249/16249 [==============================] - 6s 352us/step - loss: -0.7543 - acc: 0.3484\n",
      "Epoch 5/10\n",
      "16249/16249 [==============================] - 6s 353us/step - loss: -0.7622 - acc: 0.3481\n",
      "Epoch 6/10\n",
      "16249/16249 [==============================] - 6s 353us/step - loss: -0.7770 - acc: 0.3489\n",
      "Epoch 7/10\n",
      "16249/16249 [==============================] - 6s 352us/step - loss: -0.7804 - acc: 0.3510\n",
      "Epoch 8/10\n",
      "16249/16249 [==============================] - 6s 352us/step - loss: -0.7873 - acc: 0.3552\n",
      "Epoch 9/10\n",
      "16249/16249 [==============================] - 6s 352us/step - loss: -0.7849 - acc: 0.3592\n",
      "Epoch 10/10\n",
      "16249/16249 [==============================] - 6s 350us/step - loss: -0.7924 - acc: 0.3558\n",
      "1806/1806 [==============================] - 3s 2ms/step\n",
      "16249/16249 [==============================] - 4s 246us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 12s 727us/step - loss: -0.3670 - acc: 0.3396\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 353us/step - loss: -0.6978 - acc: 0.3490\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.7438 - acc: 0.3478\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 356us/step - loss: -0.7567 - acc: 0.3457\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 356us/step - loss: -0.7696 - acc: 0.3468\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 352us/step - loss: -0.7645 - acc: 0.3445\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 368us/step - loss: -0.7756 - acc: 0.3476\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.7779 - acc: 0.3516\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.7847 - acc: 0.3531\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 353us/step - loss: -0.7892 - acc: 0.3578\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 248us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 12s 737us/step - loss: -0.3207 - acc: 0.3403\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 358us/step - loss: -0.6710 - acc: 0.3535\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 359us/step - loss: -0.7427 - acc: 0.3493\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 359us/step - loss: -0.7590 - acc: 0.3461\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 361us/step - loss: -0.7650 - acc: 0.3456\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 7s 441us/step - loss: -0.7722 - acc: 0.3468\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 7s 435us/step - loss: -0.7816 - acc: 0.3449\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 7s 411us/step - loss: -0.7793 - acc: 0.3476\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 7s 426us/step - loss: -0.7913 - acc: 0.3455\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 356us/step - loss: -0.7863 - acc: 0.3455\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 264us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 13s 799us/step - loss: -0.2431 - acc: 0.3336\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 11s 697us/step - loss: -0.6499 - acc: 0.3478\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 13s 799us/step - loss: -0.7119 - acc: 0.3452\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 14s 891us/step - loss: -0.7424 - acc: 0.3454\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 362us/step - loss: -0.7637 - acc: 0.3443\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 361us/step - loss: -0.7670 - acc: 0.3452\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 365us/step - loss: -0.7675 - acc: 0.3461\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 362us/step - loss: -0.7646 - acc: 0.3449\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 364us/step - loss: -0.7762 - acc: 0.3456\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 361us/step - loss: -0.7793 - acc: 0.3448\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 252us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 12s 739us/step - loss: -0.1614 - acc: 0.3349\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 355us/step - loss: -0.4309 - acc: 0.3507\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 355us/step - loss: -0.4729 - acc: 0.3513\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.5120 - acc: 0.3522\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 356us/step - loss: -0.5517 - acc: 0.3541\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.5754 - acc: 0.3573\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 354us/step - loss: -0.5991 - acc: 0.3569\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 7s 419us/step - loss: -0.6191 - acc: 0.3626\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 377us/step - loss: -0.6289 - acc: 0.3619\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 369us/step - loss: -0.6334 - acc: 0.3633\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 253us/step\n",
      "Epoch 1/10\n",
      "16250/16250 [==============================] - 12s 742us/step - loss: -0.3678 - acc: 0.3380\n",
      "Epoch 2/10\n",
      "16250/16250 [==============================] - 6s 365us/step - loss: -0.6510 - acc: 0.3486\n",
      "Epoch 3/10\n",
      "16250/16250 [==============================] - 6s 355us/step - loss: -0.7089 - acc: 0.3505\n",
      "Epoch 4/10\n",
      "16250/16250 [==============================] - 6s 355us/step - loss: -0.7320 - acc: 0.3562\n",
      "Epoch 5/10\n",
      "16250/16250 [==============================] - 6s 356us/step - loss: -0.7378 - acc: 0.3522\n",
      "Epoch 6/10\n",
      "16250/16250 [==============================] - 6s 357us/step - loss: -0.7545 - acc: 0.3509\n",
      "Epoch 7/10\n",
      "16250/16250 [==============================] - 6s 359us/step - loss: -0.7508 - acc: 0.3472\n",
      "Epoch 8/10\n",
      "16250/16250 [==============================] - 6s 360us/step - loss: -0.7585 - acc: 0.3490\n",
      "Epoch 9/10\n",
      "16250/16250 [==============================] - 6s 356us/step - loss: -0.7529 - acc: 0.3559\n",
      "Epoch 10/10\n",
      "16250/16250 [==============================] - 6s 357us/step - loss: -0.7565 - acc: 0.3540\n",
      "1805/1805 [==============================] - 3s 2ms/step\n",
      "16250/16250 [==============================] - 4s 248us/step\n",
      "Epoch 1/10\n",
      "18055/18055 [==============================] - 12s 690us/step - loss: 0.1799 - acc: 0.2527\n",
      "Epoch 2/10\n",
      "18055/18055 [==============================] - 6s 346us/step - loss: -0.1687 - acc: 0.2527\n",
      "Epoch 3/10\n",
      "18055/18055 [==============================] - 6s 352us/step - loss: -0.3484 - acc: 0.2527\n",
      "Epoch 4/10\n",
      "18055/18055 [==============================] - 6s 345us/step - loss: -0.4395 - acc: 0.2527\n",
      "Epoch 5/10\n",
      "18055/18055 [==============================] - 6s 347us/step - loss: -0.4949 - acc: 0.2527\n",
      "Epoch 6/10\n",
      "18055/18055 [==============================] - 6s 345us/step - loss: -0.5295 - acc: 0.3759\n",
      "Epoch 7/10\n",
      "18055/18055 [==============================] - 6s 345us/step - loss: -0.5542 - acc: 0.3889\n",
      "Epoch 8/10\n",
      "18055/18055 [==============================] - 6s 346us/step - loss: -0.5721 - acc: 0.3903\n",
      "Epoch 9/10\n",
      "18055/18055 [==============================] - 6s 346us/step - loss: -0.5877 - acc: 0.3934\n",
      "Epoch 10/10\n",
      "18055/18055 [==============================] - 6s 344us/step - loss: -0.5980 - acc: 0.3911\n",
      "Best: 0.358405 using {'optimizer': 'Adagrad'}\n",
      "0.315979 (0.027683) with: {'optimizer': 'SGD'}\n",
      "0.351980 (0.014430) with: {'optimizer': 'RMSprop'}\n",
      "0.358405 (0.018059) with: {'optimizer': 'Adagrad'}\n",
      "0.352202 (0.010718) with: {'optimizer': 'Adadelta'}\n",
      "0.353531 (0.014776) with: {'optimizer': 'Nadam'}\n",
      "3649.0756631000277\n"
     ]
    }
   ],
   "source": [
    "#Grid Search\n",
    "start = timer()\n",
    "\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from now on, we will use Adagrad optimizer since it gave better \n",
    "# results than adam and other optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(new_df, test_size=0.2)\n",
    "x_train=train.iloc[:, 2:6]\n",
    "x_test=test.iloc[:, 2:6]\n",
    "y_train=train.iloc[:, 6]\n",
    "y_test=test.iloc[:, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12035/12035 [==============================] - 11s 949us/step - loss: 13.3498 - acc: 0.4600\n",
      "Epoch 2/5\n",
      "12035/12035 [==============================] - 5s 436us/step - loss: 13.3498 - acc: 0.4600\n",
      "Epoch 3/5\n",
      "12035/12035 [==============================] - 5s 423us/step - loss: 13.3498 - acc: 0.4600\n",
      "Epoch 4/5\n",
      "12035/12035 [==============================] - 5s 425us/step - loss: 13.3498 - acc: 0.4600\n",
      "Epoch 5/5\n",
      "12035/12035 [==============================] - 5s 390us/step - loss: 13.3498 - acc: 0.4600\n",
      "6020/6020 [==============================] - 5s 765us/step\n",
      "Epoch 1/5\n",
      "12037/12037 [==============================] - 11s 918us/step - loss: 0.2053 - acc: 0.3230\n",
      "Epoch 2/5\n",
      "12037/12037 [==============================] - 4s 365us/step - loss: -0.0097 - acc: 0.3016\n",
      "Epoch 3/5\n",
      "12037/12037 [==============================] - 5s 387us/step - loss: -0.2447 - acc: 0.3247\n",
      "Epoch 4/5\n",
      "12037/12037 [==============================] - 5s 381us/step - loss: -0.2753 - acc: 0.3370\n",
      "Epoch 5/5\n",
      "12037/12037 [==============================] - 5s 381us/step - loss: -0.2816 - acc: 0.3268\n",
      "6018/6018 [==============================] - 5s 772us/step\n",
      "Epoch 1/5\n",
      "12038/12038 [==============================] - 11s 920us/step - loss: 0.6307 - acc: 0.3009\n",
      "Epoch 2/5\n",
      "12038/12038 [==============================] - 5s 388us/step - loss: 0.1709 - acc: 0.3094\n",
      "Epoch 3/5\n",
      "12038/12038 [==============================] - 5s 375us/step - loss: 0.4871 - acc: 0.2899\n",
      "Epoch 4/5\n",
      "12038/12038 [==============================] - 4s 363us/step - loss: -0.1031 - acc: 0.3293\n",
      "Epoch 5/5\n",
      "12038/12038 [==============================] - 5s 378us/step - loss: -0.1559 - acc: 0.3134\n",
      "6017/6017 [==============================] - 5s 777us/step\n",
      "0.3714074823504729\n",
      "104.98537111955375\n"
     ]
    }
   ],
   "source": [
    "start=timer()\n",
    "\n",
    "def create_model(optimizer='Adagrad', activation='relu', hidden_layers=1):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=4, activation='relu', kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(8, activation='relu', kernel_initializer=\"uniform\"))\n",
    "\n",
    "    for i in range(hidden_layers):\n",
    "        #add one hidden layer\n",
    "        model.add(Dense(1, activation=activation))\n",
    "        \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adagrad', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=5, batch_size=8, verbose=1)\n",
    "\n",
    "#evaluate using 10-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, x_train, y_train, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "end = timer()\n",
    "print (end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the block above, my first try was layer1 activation=relu and layer2 activation=sigmoid.\n",
    "# It seems like doing relu for layer 1 and sigmoid for layer 2 gave lower results (33%) than using relu on both(37%), so\n",
    "# I decided to use relu on both layers and proceeded with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16249/16249 [==============================] - 13s 819us/step - loss: 13.3228 - acc: 0.4599\n",
      "Epoch 2/5\n",
      "16249/16249 [==============================] - 7s 420us/step - loss: 13.3228 - acc: 0.4599\n",
      "Epoch 3/5\n",
      "16249/16249 [==============================] - 7s 424us/step - loss: 13.3228 - acc: 0.4599\n",
      "Epoch 4/5\n",
      "16249/16249 [==============================] - 7s 422us/step - loss: 13.3228 - acc: 0.4599\n",
      "Epoch 5/5\n",
      "16249/16249 [==============================] - 7s 423us/step - loss: 13.3228 - acc: 0.4599\n",
      "1806/1806 [==============================] - 4s 2ms/step\n",
      "16249/16249 [==============================] - 5s 311us/step\n",
      "Epoch 1/5\n",
      "16249/16249 [==============================] - 13s 808us/step - loss: 13.3962 - acc: 0.4583\n",
      "Epoch 2/5\n",
      "16249/16249 [==============================] - 6s 384us/step - loss: 13.3962 - acc: 0.4583\n",
      "Epoch 3/5\n",
      "16249/16249 [==============================] - 8s 492us/step - loss: 13.3962 - acc: 0.4583\n",
      "Epoch 4/5\n",
      "16249/16249 [==============================] - 7s 448us/step - loss: 13.3962 - acc: 0.4583\n",
      "Epoch 5/5\n",
      "16249/16249 [==============================] - 8s 488us/step - loss: 13.3962 - acc: 0.4583\n",
      "1806/1806 [==============================] - 4s 2ms/step\n",
      "16249/16249 [==============================] - 5s 335us/step\n",
      "Epoch 1/5\n",
      "16249/16249 [==============================] - 15s 927us/step - loss: 0.2120 - acc: 0.3283\n",
      "Epoch 2/5\n",
      "16249/16249 [==============================] - 6s 395us/step - loss: 0.6295 - acc: 0.3082\n",
      "Epoch 3/5\n",
      "16249/16249 [==============================] - 7s 417us/step - loss: 0.6241 - acc: 0.3107\n",
      "Epoch 4/5\n",
      "16249/16249 [==============================] - 7s 449us/step - loss: -0.0690 - acc: 0.3329\n",
      "Epoch 5/5\n",
      "16249/16249 [==============================] - 6s 373us/step - loss: -0.1497 - acc: 0.3319\n",
      "1806/1806 [==============================] - 4s 2ms/step\n",
      "16249/16249 [==============================] - 5s 328us/step\n",
      "Epoch 1/5\n",
      "16249/16249 [==============================] - 14s 838us/step - loss: 13.3079 - acc: 0.4617\n",
      "Epoch 2/5\n",
      "16249/16249 [==============================] - 6s 386us/step - loss: 13.3079 - acc: 0.4617\n",
      "Epoch 3/5\n",
      "16249/16249 [==============================] - 6s 396us/step - loss: 13.3079 - acc: 0.4617\n",
      "Epoch 4/5\n",
      "16249/16249 [==============================] - 6s 377us/step - loss: 13.3079 - acc: 0.4617\n",
      "Epoch 5/5\n",
      "16249/16249 [==============================] - 6s 386us/step - loss: 13.3079 - acc: 0.4617\n",
      "1806/1806 [==============================] - 4s 2ms/step\n",
      "16249/16249 [==============================] - 5s 317us/step\n",
      "Epoch 1/5\n",
      "16249/16249 [==============================] - 14s 862us/step - loss: 13.3516 - acc: 0.4602\n",
      "Epoch 2/5\n",
      "16249/16249 [==============================] - 7s 400us/step - loss: 13.3516 - acc: 0.4602\n",
      "Epoch 3/5\n",
      "16249/16249 [==============================] - 6s 392us/step - loss: 13.3516 - acc: 0.4602\n",
      "Epoch 4/5\n",
      "16249/16249 [==============================] - 6s 384us/step - loss: 13.3516 - acc: 0.4602\n",
      "Epoch 5/5\n",
      "16249/16249 [==============================] - 7s 414us/step - loss: 13.3516 - acc: 0.4602\n",
      "1806/1806 [==============================] - 4s 2ms/step\n",
      "16249/16249 [==============================] - 6s 369us/step\n",
      "Epoch 1/5\n",
      "16250/16250 [==============================] - 14s 878us/step - loss: 0.5853 - acc: 0.3193\n",
      "Epoch 2/5\n",
      "16250/16250 [==============================] - 7s 435us/step - loss: 0.4880 - acc: 0.3183\n",
      "Epoch 3/5\n",
      "16250/16250 [==============================] - 7s 452us/step - loss: 0.0727 - acc: 0.3482\n",
      "Epoch 4/5\n",
      "16250/16250 [==============================] - 7s 437us/step - loss: 0.1091 - acc: 0.3375\n",
      "Epoch 5/5\n",
      "16250/16250 [==============================] - 7s 437us/step - loss: 0.7259 - acc: 0.4326\n",
      "1805/1805 [==============================] - 4s 2ms/step\n",
      "16250/16250 [==============================] - 6s 345us/step\n",
      "Epoch 1/5\n",
      "16250/16250 [==============================] - 14s 874us/step - loss: 2.1528 - acc: 0.2724\n",
      "Epoch 2/5\n",
      "16250/16250 [==============================] - 7s 426us/step - loss: 0.9488 - acc: 0.3072\n",
      "Epoch 3/5\n",
      "16250/16250 [==============================] - 7s 427us/step - loss: 0.4353 - acc: 0.3655\n",
      "Epoch 4/5\n",
      "16250/16250 [==============================] - 7s 427us/step - loss: 0.3150 - acc: 0.3500\n",
      "Epoch 5/5\n",
      "16250/16250 [==============================] - 7s 434us/step - loss: 0.1925 - acc: 0.3352\n",
      "1805/1805 [==============================] - 4s 2ms/step\n",
      "16250/16250 [==============================] - 5s 336us/step\n",
      "Epoch 1/5\n",
      "16250/16250 [==============================] - 14s 851us/step - loss: 0.4587 - acc: 0.3204\n",
      "Epoch 2/5\n",
      "16250/16250 [==============================] - 7s 439us/step - loss: 0.2095 - acc: 0.3071\n",
      "Epoch 3/5\n",
      "16250/16250 [==============================] - 7s 440us/step - loss: 0.1996 - acc: 0.3174\n",
      "Epoch 4/5\n",
      "16250/16250 [==============================] - 7s 431us/step - loss: 0.1714 - acc: 0.3145\n",
      "Epoch 5/5\n",
      "16250/16250 [==============================] - 7s 449us/step - loss: 0.1533 - acc: 0.3125\n",
      "1805/1805 [==============================] - 4s 2ms/step\n",
      "16250/16250 [==============================] - 5s 331us/step\n",
      "Epoch 1/5\n",
      "16250/16250 [==============================] - 14s 888us/step - loss: 13.2793 - acc: 0.4633\n",
      "Epoch 2/5\n",
      "16250/16250 [==============================] - 7s 443us/step - loss: 13.2793 - acc: 0.4633\n",
      "Epoch 3/5\n",
      "16250/16250 [==============================] - 7s 448us/step - loss: 13.2793 - acc: 0.4633\n",
      "Epoch 4/5\n",
      "16250/16250 [==============================] - 7s 446us/step - loss: 13.2793 - acc: 0.4633\n",
      "Epoch 5/5\n",
      "16250/16250 [==============================] - 7s 444us/step - loss: 13.2793 - acc: 0.4633\n",
      "1805/1805 [==============================] - 4s 2ms/step\n",
      "16250/16250 [==============================] - 5s 334us/step\n",
      "Epoch 1/5\n",
      "16250/16250 [==============================] - 14s 856us/step - loss: 1.3398 - acc: 0.2975\n",
      "Epoch 2/5\n",
      "16250/16250 [==============================] - 7s 443us/step - loss: 1.7618 - acc: 0.2842\n",
      "Epoch 3/5\n",
      "16250/16250 [==============================] - 7s 449us/step - loss: 1.3854 - acc: 0.2884\n",
      "Epoch 4/5\n",
      "16250/16250 [==============================] - 7s 449us/step - loss: 0.8885 - acc: 0.2993\n",
      "Epoch 5/5\n",
      "16250/16250 [==============================] - 7s 454us/step - loss: -0.0846 - acc: 0.3586\n",
      "1805/1805 [==============================] - 4s 2ms/step\n",
      "16250/16250 [==============================] - 5s 327us/step\n",
      "Epoch 1/5\n",
      "16249/16249 [==============================] - 14s 872us/step - loss: 0.6697 - acc: 0.3221\n",
      "Epoch 2/5\n",
      "16249/16249 [==============================] - 7s 446us/step - loss: 0.9688 - acc: 0.2928\n",
      "Epoch 3/5\n",
      "16249/16249 [==============================] - 8s 462us/step - loss: 0.3182 - acc: 0.3230\n",
      "Epoch 4/5\n",
      "16249/16249 [==============================] - 8s 476us/step - loss: 0.2550 - acc: 0.3331\n",
      "Epoch 5/5\n",
      "16249/16249 [==============================] - 7s 459us/step - loss: 0.1627 - acc: 0.3296\n",
      "1806/1806 [==============================] - 4s 2ms/step\n",
      "16249/16249 [==============================] - 6s 352us/step\n",
      "Epoch 1/5\n",
      "16249/16249 [==============================] - 15s 911us/step - loss: 13.3962 - acc: 0.4583\n",
      "Epoch 2/5\n",
      "16249/16249 [==============================] - 8s 479us/step - loss: 13.3962 - acc: 0.4583\n",
      "Epoch 3/5\n",
      "16249/16249 [==============================] - 8s 474us/step - loss: 13.3962 - acc: 0.4583\n",
      "Epoch 4/5\n",
      "16249/16249 [==============================] - 7s 442us/step - loss: 13.3962 - acc: 0.4583\n",
      "Epoch 5/5\n",
      "16249/16249 [==============================] - 7s 439us/step - loss: 13.3962 - acc: 0.4583\n",
      "1806/1806 [==============================] - 4s 2ms/step\n",
      "16249/16249 [==============================] - 5s 322us/step\n",
      "Epoch 1/5\n",
      "16249/16249 [==============================] - 14s 858us/step - loss: 13.3615 - acc: 0.4593\n",
      "Epoch 2/5\n",
      "16249/16249 [==============================] - 8s 489us/step - loss: 13.3615 - acc: 0.4593\n",
      "Epoch 3/5\n",
      "16249/16249 [==============================] - 8s 466us/step - loss: 13.3615 - acc: 0.4593\n",
      "Epoch 4/5\n",
      "16249/16249 [==============================] - 6s 387us/step - loss: 13.3615 - acc: 0.4593\n",
      "Epoch 5/5\n",
      "16249/16249 [==============================] - 7s 412us/step - loss: 13.3615 - acc: 0.4593\n",
      "1806/1806 [==============================] - 4s 2ms/step\n",
      "16249/16249 [==============================] - 5s 286us/step\n",
      "Epoch 1/5\n",
      "16249/16249 [==============================] - 14s 870us/step - loss: 0.3279 - acc: 0.3275\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16249/16249 [==============================] - 7s 425us/step - loss: -0.0723 - acc: 0.3104\n",
      "Epoch 3/5\n",
      "16249/16249 [==============================] - 7s 408us/step - loss: -0.1061 - acc: 0.3123\n",
      "Epoch 4/5\n",
      "16249/16249 [==============================] - 6s 396us/step - loss: -0.1858 - acc: 0.3113\n",
      "Epoch 5/5\n",
      "16249/16249 [==============================] - 7s 400us/step - loss: -0.0706 - acc: 0.3035\n",
      "1806/1806 [==============================] - 4s 2ms/step\n",
      "16249/16249 [==============================] - 5s 316us/step\n",
      "Epoch 1/5\n",
      "16249/16249 [==============================] - 14s 878us/step - loss: 0.5714 - acc: 0.3114\n",
      "Epoch 2/5\n",
      "16249/16249 [==============================] - 7s 451us/step - loss: 0.1445 - acc: 0.3291\n",
      "Epoch 3/5\n",
      "16249/16249 [==============================] - 7s 441us/step - loss: 0.4525 - acc: 0.3971\n",
      "Epoch 4/5\n",
      "16249/16249 [==============================] - 7s 439us/step - loss: 0.6112 - acc: 0.4251\n",
      "Epoch 5/5\n",
      "16249/16249 [==============================] - 7s 438us/step - loss: 0.5831 - acc: 0.4199\n",
      "1806/1806 [==============================] - 4s 2ms/step\n",
      "16249/16249 [==============================] - 5s 331us/step\n",
      "Epoch 1/5\n",
      "16250/16250 [==============================] - 14s 865us/step - loss: 0.9306 - acc: 0.3492\n",
      "Epoch 2/5\n",
      "16250/16250 [==============================] - 7s 442us/step - loss: 0.2857 - acc: 0.3340\n",
      "Epoch 3/5\n",
      "16250/16250 [==============================] - 7s 448us/step - loss: 0.2260 - acc: 0.3292\n",
      "Epoch 4/5\n",
      "16250/16250 [==============================] - 7s 449us/step - loss: 0.2476 - acc: 0.3310\n",
      "Epoch 5/5\n",
      "16250/16250 [==============================] - 7s 451us/step - loss: 0.4519 - acc: 0.3674\n",
      "1805/1805 [==============================] - 4s 2ms/step\n",
      "16250/16250 [==============================] - 6s 345us/step\n",
      "Epoch 1/5\n",
      "16250/16250 [==============================] - 16s 970us/step - loss: -0.0212 - acc: 0.3208\n",
      "Epoch 2/5\n",
      "16250/16250 [==============================] - 8s 483us/step - loss: -0.3540 - acc: 0.3644\n",
      "Epoch 3/5\n",
      "16250/16250 [==============================] - 8s 480us/step - loss: -0.3335 - acc: 0.3674\n",
      "Epoch 4/5\n",
      "16250/16250 [==============================] - 8s 466us/step - loss: -0.5325 - acc: 0.3240\n",
      "Epoch 5/5\n",
      "16250/16250 [==============================] - 8s 490us/step - loss: -0.4680 - acc: 0.3308\n",
      "1805/1805 [==============================] - 4s 2ms/step\n",
      "16250/16250 [==============================] - 6s 362us/step\n",
      "Epoch 1/5\n",
      "16250/16250 [==============================] - 15s 942us/step - loss: 13.3795 - acc: 0.4589\n",
      "Epoch 2/5\n",
      "16250/16250 [==============================] - 7s 452us/step - loss: 13.3795 - acc: 0.4589\n",
      "Epoch 3/5\n",
      "16250/16250 [==============================] - 8s 469us/step - loss: 13.3795 - acc: 0.4589\n",
      "Epoch 4/5\n",
      "16250/16250 [==============================] - 7s 457us/step - loss: 13.3795 - acc: 0.4589\n",
      "Epoch 5/5\n",
      "16250/16250 [==============================] - 8s 466us/step - loss: 13.3795 - acc: 0.4589\n",
      "1805/1805 [==============================] - 4s 2ms/step\n",
      "16250/16250 [==============================] - 6s 351us/step\n",
      "Epoch 1/5\n",
      "16250/16250 [==============================] - 15s 916us/step - loss: 0.0375 - acc: 0.2805\n",
      "Epoch 2/5\n",
      "16250/16250 [==============================] - 8s 463us/step - loss: -0.3694 - acc: 0.2826\n",
      "Epoch 3/5\n",
      "16250/16250 [==============================] - 7s 443us/step - loss: -0.4428 - acc: 0.2786\n",
      "Epoch 4/5\n",
      "16250/16250 [==============================] - 7s 444us/step - loss: -0.4193 - acc: 0.2921\n",
      "Epoch 5/5\n",
      "16250/16250 [==============================] - 7s 457us/step - loss: -0.3330 - acc: 0.3018\n",
      "1805/1805 [==============================] - 4s 2ms/step\n",
      "16250/16250 [==============================] - 6s 341us/step\n",
      "Epoch 1/5\n",
      "16250/16250 [==============================] - 15s 902us/step - loss: 13.3855 - acc: 0.4586\n",
      "Epoch 2/5\n",
      "16250/16250 [==============================] - 7s 455us/step - loss: 13.3855 - acc: 0.4586\n",
      "Epoch 3/5\n",
      "16250/16250 [==============================] - 8s 473us/step - loss: 13.3855 - acc: 0.4586\n",
      "Epoch 4/5\n",
      "16250/16250 [==============================] - 8s 469us/step - loss: 13.3855 - acc: 0.4586\n",
      "Epoch 5/5\n",
      "16250/16250 [==============================] - 8s 480us/step - loss: 13.3855 - acc: 0.4586\n",
      "1805/1805 [==============================] - 4s 2ms/step\n",
      "16250/16250 [==============================] - 6s 363us/step\n",
      "Epoch 1/5\n",
      "16249/16249 [==============================] - 15s 936us/step - loss: 13.3228 - acc: 0.4599\n",
      "Epoch 2/5\n",
      "16249/16249 [==============================] - 8s 472us/step - loss: 13.3228 - acc: 0.4599\n",
      "Epoch 3/5\n",
      "16249/16249 [==============================] - 8s 473us/step - loss: 13.3228 - acc: 0.4599\n",
      "Epoch 4/5\n",
      "16249/16249 [==============================] - 8s 479us/step - loss: 13.3228 - acc: 0.4599\n",
      "Epoch 5/5\n",
      "16249/16249 [==============================] - 8s 493us/step - loss: 13.3228 - acc: 0.4599\n",
      "1806/1806 [==============================] - 4s 2ms/step\n",
      "16249/16249 [==============================] - 6s 344us/step\n",
      "Epoch 1/5\n",
      "16249/16249 [==============================] - 15s 932us/step - loss: 13.3962 - acc: 0.4583\n",
      "Epoch 2/5\n",
      "16249/16249 [==============================] - 8s 491us/step - loss: 13.3962 - acc: 0.4583\n",
      "Epoch 3/5\n",
      "16249/16249 [==============================] - 8s 481us/step - loss: 13.3962 - acc: 0.4583\n",
      "Epoch 4/5\n",
      "16249/16249 [==============================] - 8s 490us/step - loss: 13.3962 - acc: 0.4583\n",
      "Epoch 5/5\n",
      "16249/16249 [==============================] - 8s 481us/step - loss: 13.3962 - acc: 0.4583\n",
      "1806/1806 [==============================] - 4s 2ms/step\n",
      "16249/16249 [==============================] - 6s 354us/step\n",
      "Epoch 1/5\n",
      "16249/16249 [==============================] - 16s 987us/step - loss: 0.3848 - acc: 0.3141\n",
      "Epoch 2/5\n",
      "16249/16249 [==============================] - 8s 502us/step - loss: 0.4293 - acc: 0.3534\n",
      "Epoch 3/5\n",
      "16249/16249 [==============================] - 8s 500us/step - loss: 0.2757 - acc: 0.3211\n",
      "Epoch 4/5\n",
      "16249/16249 [==============================] - 8s 492us/step - loss: 0.5015 - acc: 0.2689\n",
      "Epoch 5/5\n",
      "16249/16249 [==============================] - 8s 482us/step - loss: 0.3067 - acc: 0.2751\n",
      "1806/1806 [==============================] - 4s 2ms/step\n",
      "16249/16249 [==============================] - 6s 366us/step\n",
      "Epoch 1/5\n",
      "16249/16249 [==============================] - 15s 944us/step - loss: 13.3079 - acc: 0.4617\n",
      "Epoch 2/5\n",
      "16249/16249 [==============================] - 8s 480us/step - loss: 13.3079 - acc: 0.4617\n",
      "Epoch 3/5\n",
      "16249/16249 [==============================] - 8s 485us/step - loss: 13.3079 - acc: 0.4617\n",
      "Epoch 4/5\n",
      "16249/16249 [==============================] - 8s 478us/step - loss: 13.3079 - acc: 0.4617\n",
      "Epoch 5/5\n",
      "16249/16249 [==============================] - 8s 478us/step - loss: 13.3079 - acc: 0.4617\n",
      "1806/1806 [==============================] - 4s 2ms/step\n",
      "16249/16249 [==============================] - 6s 362us/step\n",
      "Epoch 1/5\n",
      "16249/16249 [==============================] - 15s 923us/step - loss: 0.3601 - acc: 0.3171\n",
      "Epoch 2/5\n",
      "16249/16249 [==============================] - 8s 476us/step - loss: 0.1221 - acc: 0.3054\n",
      "Epoch 3/5\n",
      "16249/16249 [==============================] - 8s 473us/step - loss: -0.2778 - acc: 0.3143\n",
      "Epoch 4/5\n",
      "16249/16249 [==============================] - 8s 475us/step - loss: 0.2420 - acc: 0.3157\n",
      "Epoch 5/5\n",
      "16249/16249 [==============================] - 8s 475us/step - loss: -0.2380 - acc: 0.3332\n",
      "1806/1806 [==============================] - 4s 2ms/step\n",
      "16249/16249 [==============================] - 6s 358us/step\n",
      "Epoch 1/5\n",
      "16250/16250 [==============================] - 15s 940us/step - loss: 13.3785 - acc: 0.4596\n",
      "Epoch 2/5\n",
      "16250/16250 [==============================] - 8s 487us/step - loss: 13.3785 - acc: 0.4596\n",
      "Epoch 3/5\n",
      "16250/16250 [==============================] - 8s 492us/step - loss: 13.3785 - acc: 0.4596\n",
      "Epoch 4/5\n",
      "16250/16250 [==============================] - 8s 487us/step - loss: 13.3785 - acc: 0.4596\n",
      "Epoch 5/5\n",
      "16250/16250 [==============================] - 8s 496us/step - loss: 13.3785 - acc: 0.4596\n",
      "1805/1805 [==============================] - 4s 2ms/step\n",
      "16250/16250 [==============================] - 6s 381us/step\n",
      "Epoch 1/5\n",
      "16250/16250 [==============================] - 15s 944us/step - loss: 13.3349 - acc: 0.4600\n",
      "Epoch 2/5\n",
      "16250/16250 [==============================] - 8s 487us/step - loss: 13.3349 - acc: 0.4600\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16250/16250 [==============================] - 8s 467us/step - loss: 13.3349 - acc: 0.4600\n",
      "Epoch 4/5\n",
      "16250/16250 [==============================] - 7s 460us/step - loss: 13.3349 - acc: 0.4600\n",
      "Epoch 5/5\n",
      "16250/16250 [==============================] - 7s 460us/step - loss: 13.3349 - acc: 0.4600\n",
      "1805/1805 [==============================] - 4s 2ms/step\n",
      "16250/16250 [==============================] - 5s 331us/step\n",
      "Epoch 1/5\n",
      "16250/16250 [==============================] - 15s 948us/step - loss: 13.3795 - acc: 0.4589\n",
      "Epoch 2/5\n",
      "16250/16250 [==============================] - 8s 471us/step - loss: 13.3795 - acc: 0.4589\n",
      "Epoch 3/5\n",
      "16250/16250 [==============================] - 8s 464us/step - loss: 13.3795 - acc: 0.4589\n",
      "Epoch 4/5\n",
      "16250/16250 [==============================] - 8s 478us/step - loss: 13.3795 - acc: 0.4589\n",
      "Epoch 5/5\n",
      "16250/16250 [==============================] - 7s 461us/step - loss: 13.3795 - acc: 0.4589\n",
      "1805/1805 [==============================] - 4s 2ms/step\n",
      "16250/16250 [==============================] - 6s 340us/step\n",
      "Epoch 1/5\n",
      "16250/16250 [==============================] - 15s 916us/step - loss: 13.2793 - acc: 0.4633\n",
      "Epoch 2/5\n",
      "16250/16250 [==============================] - 8s 471us/step - loss: 13.2793 - acc: 0.4633\n",
      "Epoch 3/5\n",
      "16250/16250 [==============================] - 7s 458us/step - loss: 13.2793 - acc: 0.4633\n",
      "Epoch 4/5\n",
      "16250/16250 [==============================] - 7s 410us/step - loss: 13.2793 - acc: 0.4633\n",
      "Epoch 5/5\n",
      "16250/16250 [==============================] - 7s 404us/step - loss: 13.2793 - acc: 0.4633\n",
      "1805/1805 [==============================] - 4s 2ms/step\n",
      "16250/16250 [==============================] - 5s 286us/step\n",
      "Epoch 1/5\n",
      "16250/16250 [==============================] - 14s 868us/step - loss: 13.3855 - acc: 0.4586\n",
      "Epoch 2/5\n",
      "16250/16250 [==============================] - 7s 408us/step - loss: 13.3855 - acc: 0.4586\n",
      "Epoch 3/5\n",
      "16250/16250 [==============================] - 7s 409us/step - loss: 13.3855 - acc: 0.4586\n",
      "Epoch 4/5\n",
      "16250/16250 [==============================] - 7s 414us/step - loss: 13.3855 - acc: 0.4586\n",
      "Epoch 5/5\n",
      "16250/16250 [==============================] - 7s 418us/step - loss: 13.3855 - acc: 0.4586\n",
      "1805/1805 [==============================] - 4s 2ms/step\n",
      "16250/16250 [==============================] - 5s 297us/step\n",
      "Epoch 1/5\n",
      "18055/18055 [==============================] - 15s 827us/step - loss: 13.3498 - acc: 0.4600\n",
      "Epoch 2/5\n",
      "18055/18055 [==============================] - 8s 417us/step - loss: 13.3498 - acc: 0.4600\n",
      "Epoch 3/5\n",
      "18055/18055 [==============================] - 8s 423us/step - loss: 13.3498 - acc: 0.4600\n",
      "Epoch 4/5\n",
      "18055/18055 [==============================] - 7s 405us/step - loss: 13.3498 - acc: 0.4600\n",
      "Epoch 5/5\n",
      "18055/18055 [==============================] - 7s 403us/step - loss: 13.3498 - acc: 0.4600\n",
      "Best: 0.429521 using {'hidden_layers': 3}\n",
      "0.404985 (0.062811) with: {'hidden_layers': 1}\n",
      "0.396732 (0.067387) with: {'hidden_layers': 2}\n",
      "0.429521 (0.063973) with: {'hidden_layers': 3}\n",
      "1651.3479483739284\n"
     ]
    }
   ],
   "source": [
    "#Grid Search\n",
    "start = timer()\n",
    "\n",
    "# define the grid search parameters\n",
    "hidden_layers=[1,2,3]\n",
    "param_grid = dict(hidden_layers=hidden_layers)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we found 3 layers was optimal out of the options 1,2,3, let us perform\n",
    "# another grid search, this time with 4 or 5 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12036/12036 [==============================] - 15s 1ms/step - loss: 13.3594 - acc: 0.4580\n",
      "Epoch 2/5\n",
      "12036/12036 [==============================] - 6s 531us/step - loss: 13.3594 - acc: 0.4580\n",
      "Epoch 3/5\n",
      "12036/12036 [==============================] - 6s 533us/step - loss: 13.3594 - acc: 0.4580\n",
      "Epoch 4/5\n",
      "12036/12036 [==============================] - 7s 563us/step - loss: 13.3594 - acc: 0.4580\n",
      "Epoch 5/5\n",
      "12036/12036 [==============================] - 7s 606us/step - loss: 13.3594 - acc: 0.4580\n",
      "6019/6019 [==============================] - 6s 1ms/step\n",
      "12036/12036 [==============================] - 4s 366us/step\n",
      "Epoch 1/5\n",
      "12037/12037 [==============================] - 15s 1ms/step - loss: 13.3784 - acc: 0.4597\n",
      "Epoch 2/5\n",
      "12037/12037 [==============================] - 6s 508us/step - loss: 13.3784 - acc: 0.4597\n",
      "Epoch 3/5\n",
      "12037/12037 [==============================] - 6s 496us/step - loss: 13.3784 - acc: 0.4597\n",
      "Epoch 4/5\n",
      "12037/12037 [==============================] - 6s 497us/step - loss: 13.3784 - acc: 0.4597\n",
      "Epoch 5/5\n",
      "12037/12037 [==============================] - 6s 499us/step - loss: 13.3784 - acc: 0.4597\n",
      "6018/6018 [==============================] - 6s 1ms/step\n",
      "12037/12037 [==============================] - 5s 399us/step\n",
      "Epoch 1/5\n",
      "12037/12037 [==============================] - 15s 1ms/step - loss: 13.3115 - acc: 0.4622\n",
      "Epoch 2/5\n",
      "12037/12037 [==============================] - 7s 572us/step - loss: 13.3115 - acc: 0.4622\n",
      "Epoch 3/5\n",
      "12037/12037 [==============================] - 6s 519us/step - loss: 13.3115 - acc: 0.4622\n",
      "Epoch 4/5\n",
      "12037/12037 [==============================] - 6s 515us/step - loss: 13.3115 - acc: 0.4622\n",
      "Epoch 5/5\n",
      "12037/12037 [==============================] - 6s 521us/step - loss: 13.3115 - acc: 0.4622\n",
      "6018/6018 [==============================] - 6s 1ms/step\n",
      "12037/12037 [==============================] - 5s 378us/step\n",
      "Epoch 1/5\n",
      "12036/12036 [==============================] - 16s 1ms/step - loss: 13.3594 - acc: 0.4580\n",
      "Epoch 2/5\n",
      "12036/12036 [==============================] - 7s 549us/step - loss: 13.3594 - acc: 0.4580\n",
      "Epoch 3/5\n",
      "12036/12036 [==============================] - 6s 530us/step - loss: 13.3594 - acc: 0.4580\n",
      "Epoch 4/5\n",
      "12036/12036 [==============================] - 7s 574us/step - loss: 13.3594 - acc: 0.4580\n",
      "Epoch 5/5\n",
      "12036/12036 [==============================] - 7s 548us/step - loss: 13.3594 - acc: 0.4580\n",
      "6019/6019 [==============================] - 6s 1ms/step\n",
      "12036/12036 [==============================] - 5s 378us/step\n",
      "Epoch 1/5\n",
      "12037/12037 [==============================] - 16s 1ms/step - loss: 13.3784 - acc: 0.4597\n",
      "Epoch 2/5\n",
      "12037/12037 [==============================] - 6s 539us/step - loss: 13.3784 - acc: 0.4597\n",
      "Epoch 3/5\n",
      "12037/12037 [==============================] - 7s 551us/step - loss: 13.3784 - acc: 0.4597\n",
      "Epoch 4/5\n",
      "12037/12037 [==============================] - 6s 539us/step - loss: 13.3784 - acc: 0.4597\n",
      "Epoch 5/5\n",
      "12037/12037 [==============================] - 7s 550us/step - loss: 13.3784 - acc: 0.4597\n",
      "6018/6018 [==============================] - 7s 1ms/step\n",
      "12037/12037 [==============================] - 5s 413us/step\n",
      "Epoch 1/5\n",
      "12037/12037 [==============================] - 16s 1ms/step - loss: 13.3115 - acc: 0.4622\n",
      "Epoch 2/5\n",
      "12037/12037 [==============================] - 6s 532us/step - loss: 13.3115 - acc: 0.4622\n",
      "Epoch 3/5\n",
      "12037/12037 [==============================] - 6s 526us/step - loss: 13.3115 - acc: 0.4622\n",
      "Epoch 4/5\n",
      "12037/12037 [==============================] - 6s 523us/step - loss: 13.3115 - acc: 0.4622\n",
      "Epoch 5/5\n",
      "12037/12037 [==============================] - 6s 533us/step - loss: 13.3115 - acc: 0.4622\n",
      "6018/6018 [==============================] - 7s 1ms/step\n",
      "12037/12037 [==============================] - 4s 359us/step\n",
      "Epoch 1/5\n",
      "18055/18055 [==============================] - 19s 1ms/step - loss: 13.3498 - acc: 0.4600\n",
      "Epoch 2/5\n",
      "18055/18055 [==============================] - 11s 611us/step - loss: 13.3498 - acc: 0.4600\n",
      "Epoch 3/5\n",
      "18055/18055 [==============================] - 11s 584us/step - loss: 13.3498 - acc: 0.4600\n",
      "Epoch 4/5\n",
      "18055/18055 [==============================] - 11s 619us/step - loss: 13.3498 - acc: 0.4600\n",
      "Epoch 5/5\n",
      "18055/18055 [==============================] - 11s 636us/step - loss: 13.3498 - acc: 0.4600\n",
      "Best: 0.459983 using {'hidden_layers': 6}\n",
      "0.459983 (0.003512) with: {'hidden_layers': 6}\n",
      "0.459983 (0.003512) with: {'hidden_layers': 7}\n",
      "380.76803908250076\n"
     ]
    }
   ],
   "source": [
    "#Grid Search\n",
    "start = timer()\n",
    "\n",
    "# define the grid search parameters\n",
    "hidden_layers=[6,7]\n",
    "param_grid = dict(hidden_layers=hidden_layers)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3)\n",
    "grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems like we got the same accuracy for 6 layers as we did for 5 and 7 as well, so we might as well keep only 5 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below, we use random forest classifier to predict 1x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stage  B365H  B365D  B365A  result\n",
       "0      1    6.5    4.0   1.50       3\n",
       "1      1    2.4    3.2   2.62       1\n",
       "2      1    2.7    3.0   2.80       2\n",
       "3      1    2.4    3.1   3.10       1\n",
       "4      1    2.4    3.1   3.10       1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict who wins, using random forest\n",
    "\n",
    "\n",
    "df['diff_goals']=df['home_team_goal']-df['away_team_goal']\n",
    "\n",
    "def betting(dl):\n",
    "    if dl > 0.5: return 1\n",
    "    elif dl==0: return 2\n",
    "    else: return 3\n",
    "df[\"result\"] = df['diff_goals'].map(betting)\n",
    "\n",
    "new_df=df[['stage','B365H', 'B365D', 'B365A', 'result']]\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44126899050662394\n",
      "2.2103511528439412\n"
     ]
    }
   ],
   "source": [
    "start=timer()\n",
    "\n",
    "X=new_df.iloc[:,0:4]\n",
    "Y=new_df.iloc[:,4]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "seed = 7\n",
    "num_trees = 5\n",
    "max_features = 4\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "end=timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.443662 using {'n_estimators': 12}\n",
      "0.440073 (0.008037) with: {'n_estimators': 6}\n",
      "0.439231 (0.010125) with: {'n_estimators': 7}\n",
      "0.440294 (0.008165) with: {'n_estimators': 8}\n",
      "0.441402 (0.009930) with: {'n_estimators': 9}\n",
      "0.443086 (0.008100) with: {'n_estimators': 10}\n",
      "0.439851 (0.010180) with: {'n_estimators': 11}\n",
      "0.443662 (0.009230) with: {'n_estimators': 12}\n",
      "0.440206 (0.008288) with: {'n_estimators': 13}\n",
      "0.440161 (0.009841) with: {'n_estimators': 14}\n",
      "0.439674 (0.009405) with: {'n_estimators': 15}\n",
      "52.569825169997785\n"
     ]
    }
   ],
   "source": [
    "#Grid Search\n",
    "start = timer()\n",
    "\n",
    "# define the grid search parameters\n",
    "n_estimators=[6,7,8,9,10,11,12,13,14,15]\n",
    "param_grid = dict(n_estimators=n_estimators)\n",
    "\n",
    "seed=7\n",
    "num_trees=5\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "grid_result = grid.fit(X,Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, we try to predict whether the home team will win or not (4 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5835883712453296\n",
      "2.294004668852722\n"
     ]
    }
   ],
   "source": [
    "start=timer()\n",
    "\n",
    "df = pandas.read_csv('edited match table.csv')\n",
    "df['other_column']=df['home_team_goal']-df['away_team_goal']\n",
    "def betting(dl):\n",
    "    if dl > 0.5: return 1\n",
    "    else: return 0\n",
    "df[\"Code\"] = df['other_column'].map(betting)\n",
    "\n",
    "home_wins=df[['stage','B365H', 'B365D', 'B365A', 'Code']]\n",
    "\n",
    "\n",
    "X=home_wins.iloc[:,0:4]\n",
    "Y=home_wins.iloc[:,4]\n",
    "\n",
    "seed = 7\n",
    "num_trees = 5\n",
    "max_features = 4\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "end=timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.586512 using {'n_estimators': 8}\n",
      "0.581683 (0.007800) with: {'n_estimators': 6}\n",
      "0.581594 (0.007710) with: {'n_estimators': 7}\n",
      "0.586512 (0.009369) with: {'n_estimators': 8}\n",
      "0.583632 (0.011125) with: {'n_estimators': 9}\n",
      "0.582170 (0.009601) with: {'n_estimators': 10}\n",
      "0.583544 (0.009887) with: {'n_estimators': 11}\n",
      "0.584652 (0.007727) with: {'n_estimators': 12}\n",
      "0.582436 (0.007810) with: {'n_estimators': 13}\n",
      "0.583677 (0.009610) with: {'n_estimators': 14}\n",
      "0.583411 (0.008471) with: {'n_estimators': 15}\n",
      "50.83285764668835\n"
     ]
    }
   ],
   "source": [
    "#Grid Search\n",
    "start = timer()\n",
    "\n",
    "# define the grid search parameters\n",
    "n_estimators=[6,7,8,9,10,11,12,13,14,15]\n",
    "param_grid = dict(n_estimators=n_estimators)\n",
    "\n",
    "seed=7\n",
    "num_trees=5\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "grid_result = grid.fit(X,Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below we only use 3 features for the prediction (excluding Stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6239523727599242\n",
      "2.6925565225828905\n"
     ]
    }
   ],
   "source": [
    "start=timer()\n",
    "df = pandas.read_csv('edited match table.csv')\n",
    "df['other_column']=df['home_team_goal']-df['away_team_goal']\n",
    "def betting(dl):\n",
    "    if dl > 0.5: return 1\n",
    "    else: return 0\n",
    "df[\"Code\"] = df['other_column'].map(betting)\n",
    "\n",
    "new_df=df[['B365H', 'B365D', 'B365A', 'Code']]\n",
    "\n",
    "X=new_df.iloc[:,0:3]\n",
    "Y=new_df.iloc[:,3]\n",
    "\n",
    "seed = 7\n",
    "num_trees = 10\n",
    "max_features = 3\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "end=timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.626479 using {'n_estimators': 15}\n",
      "0.622491 (0.013733) with: {'n_estimators': 6}\n",
      "0.623820 (0.011736) with: {'n_estimators': 7}\n",
      "0.624396 (0.010155) with: {'n_estimators': 8}\n",
      "0.624308 (0.012236) with: {'n_estimators': 9}\n",
      "0.624441 (0.013517) with: {'n_estimators': 10}\n",
      "0.624928 (0.012917) with: {'n_estimators': 11}\n",
      "0.622934 (0.015465) with: {'n_estimators': 12}\n",
      "0.624884 (0.014080) with: {'n_estimators': 13}\n",
      "0.624441 (0.013400) with: {'n_estimators': 14}\n",
      "0.626479 (0.015335) with: {'n_estimators': 15}\n",
      "31.65665469907981\n"
     ]
    }
   ],
   "source": [
    "#Grid Search\n",
    "start = timer()\n",
    "\n",
    "# define the grid search parameters\n",
    "n_estimators=[6,7,8,9,10,11,12,13,14,15]\n",
    "param_grid = dict(n_estimators=n_estimators)\n",
    "\n",
    "seed=7\n",
    "num_trees = 10\n",
    "max_features = 3\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "grid_result = grid.fit(X,Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.627143 using {'n_estimators': 25}\n",
      "0.624529 (0.014747) with: {'n_estimators': 20}\n",
      "0.627143 (0.014655) with: {'n_estimators': 25}\n",
      "0.626124 (0.015483) with: {'n_estimators': 30}\n",
      "22.409402920737193\n"
     ]
    }
   ],
   "source": [
    "#Grid Search\n",
    "start = timer()\n",
    "\n",
    "# define the grid search parameters\n",
    "n_estimators=[20,25,30]\n",
    "param_grid = dict(n_estimators=n_estimators)\n",
    "\n",
    "seed=7\n",
    "num_trees = 10\n",
    "max_features = 3\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "grid_result = grid.fit(X,Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6514696790442344\n",
      "3.7498843050452706\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost Classification\n",
    "start=timer()\n",
    "seed = 7\n",
    "num_trees = 25\n",
    "max_features = 3\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "end=timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.651469 using {'n_estimators': 15}\n",
      "0.651469 (0.009735) with: {'n_estimators': 15}\n",
      "0.651469 (0.009735) with: {'n_estimators': 20}\n",
      "0.651469 (0.009735) with: {'n_estimators': 25}\n",
      "0.651469 (0.009735) with: {'n_estimators': 30}\n",
      "0.651469 (0.009735) with: {'n_estimators': 35}\n",
      "25.607447022906854\n"
     ]
    }
   ],
   "source": [
    "#Grid Search\n",
    "start = timer()\n",
    "\n",
    "# define the grid search parameters\n",
    "n_estimators=[15,20,25,30,35]\n",
    "param_grid = dict(n_estimators=n_estimators)\n",
    "\n",
    "seed=7\n",
    "num_trees = 25\n",
    "max_features = 3\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "grid_result = grid.fit(X,Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6510708410712771\n",
      "2.1135294051782694\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Boosting Classification\n",
    "start=timer()\n",
    "seed = 7\n",
    "num_trees = 15\n",
    "max_features = 3\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "end=timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.651956 using {'n_estimators': 35}\n",
      "0.651469 (0.009735) with: {'n_estimators': 10}\n",
      "0.650317 (0.008261) with: {'n_estimators': 15}\n",
      "0.650405 (0.008209) with: {'n_estimators': 20}\n",
      "0.651070 (0.008579) with: {'n_estimators': 25}\n",
      "0.651912 (0.008989) with: {'n_estimators': 30}\n",
      "0.651956 (0.009491) with: {'n_estimators': 35}\n",
      "17.342872724355402\n"
     ]
    }
   ],
   "source": [
    "#Grid Search\n",
    "start = timer()\n",
    "\n",
    "# define the grid search parameters\n",
    "n_estimators=[10,15,20,25,30,35]\n",
    "param_grid = dict(n_estimators=n_estimators)\n",
    "\n",
    "seed=7\n",
    "num_trees = 25\n",
    "max_features = 3\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "grid_result = grid.fit(X,Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.652621 using {'n_estimators': 41}\n",
      "0.651956 (0.009491) with: {'n_estimators': 35}\n",
      "0.652133 (0.009549) with: {'n_estimators': 37}\n",
      "0.652399 (0.009394) with: {'n_estimators': 39}\n",
      "0.652621 (0.008831) with: {'n_estimators': 41}\n",
      "0.652399 (0.008583) with: {'n_estimators': 43}\n",
      "0.652532 (0.008692) with: {'n_estimators': 45}\n",
      "28.64511132840198\n"
     ]
    }
   ],
   "source": [
    "#Grid Search\n",
    "start = timer()\n",
    "\n",
    "# define the grid search parameters\n",
    "n_estimators=[35, 37, 39, 41, 43, 45]\n",
    "param_grid = dict(n_estimators=n_estimators)\n",
    "\n",
    "seed=7\n",
    "num_trees = 25\n",
    "max_features = 3\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "grid_result = grid.fit(X,Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6529759856647719\n",
      "282.7305002687099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Voting Ensemble for Classification\n",
    "start=timer()\n",
    "\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "results = model_selection.cross_val_score(ensemble, X, Y, cv=kfold)\n",
    "print(results.mean())\n",
    "\n",
    "end=timer()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting the best formation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is an issue linking the tables together. There is no common identifier for the matches / teams.\n",
    "# Even if you connect on dates,you will not be able to know which team is which,because the dates and scores are only \n",
    "# provided on one table (and it's the same table that has both). The other table has other numbers identifying the same team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
